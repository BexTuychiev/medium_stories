{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner's Guide to XGBoost for Classification Problems\n",
    "## Utilize the hottest ML library for state-of-the-art performance\n",
    "<img src='images/pexels.jpg'></img>\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@dom-gould-105501?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Dom Gould</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/rear-view-of-silhouette-man-against-sky-during-sunset-325790/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is XGBoost and why is it so popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me introduce you to the hottest Machine Learning library in the ML community - XGBoost. In recent years, it has been the main driving force behind the algorithms that win massive ML competitions. Its speed and performance is unparalleled and it consistently outperforms any other algorithms aimed at supervised learning tasks.\n",
    "\n",
    "The library is parallelizable which means the core algorithm can run on clusters of GPUs or even across a network of computers. This makes it feasible to solve ML tasks by training on hundreds of millions of training examples with high performance. \n",
    "\n",
    "Originally, it was written in C++ as a command line application. After winning a huge competition in the field of physics, it started being widely adopted by the ML community. As a result, now the library has its APIs in several other languages including Python, R and Julia. \n",
    "\n",
    "In this post, we will learn the fundamentals of XGBoost by solving classification tasks. ## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refresher on Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to code examples of XGBoost, let's refresh on some of the terms we will be using throughout the post. \n",
    "\n",
    "**Classification task**: a supervised machine learning task in which one should predict if an instance is in some category by studying the item's features. For example, by looking at the body measurements, patient history and glucose levels of a person, you can predict whether a person belongs to 'Has diabetes' or 'Does not have diabetes' group.\n",
    "\n",
    "**Binary classification**: One type of classification where the target instance can only belong to either one of two classes. For example, predicting whether an email is spam or not, whether a customer purchases some product or not, etc.\n",
    "\n",
    "**Multi-class classification**: Another type of classification problems where the target can belong to one of many categories. For example, predicting the species of a bird, guessing someones bloody type, etc.\n",
    "\n",
    "If you find yourself confused by other terminology, I have written a small ML dictionary for beginners:\n",
    "\n",
    "https://towardsdatascience.com/codeless-machine-learning-dictionary-for-dummies-fa912cc7bdfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to prepocess your datasets for XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from basic data cleaning operations, there are some requirements for XGBoost to achieve top performance. Mainly:\n",
    "- Numeric features should be scaled\n",
    "- Categorical features should be encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To show how these steps are done, we will be using the [Rain in Australia](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package) dataset from Kaggle where we will predict whether it will rain today or not based on some weather measurements. In this section, we will focus on preprocessing by utilizing Scikit-Learn Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rain = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "rain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains weather measures of 10 years from multiple weather stations in Australia. You can either predict whether it will rain tomorrow or today, so there are two features in the dataset named `RainToday`, `RainTomorrow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will only be predicting for `RainToday`, we will drop the other one along with some other features that won't be necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Date\", \"Location\", \"RainTomorrow\"]\n",
    "\n",
    "rain.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's deal with missing values starting by looking at their proportions in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinTemp          0.010209\n",
       "MaxTemp          0.008669\n",
       "Rainfall         0.022419\n",
       "Evaporation      0.431665\n",
       "Sunshine         0.480098\n",
       "WindGustDir      0.070989\n",
       "WindGustSpeed    0.070555\n",
       "WindDir9am       0.072639\n",
       "WindDir3pm       0.029066\n",
       "WindSpeed9am     0.012148\n",
       "WindSpeed3pm     0.021050\n",
       "Humidity9am      0.018246\n",
       "Humidity3pm      0.030984\n",
       "Pressure9am      0.103568\n",
       "Pressure3pm      0.103314\n",
       "Cloud9am         0.384216\n",
       "Cloud3pm         0.408071\n",
       "Temp9am          0.012148\n",
       "Temp3pm          0.024811\n",
       "RainToday        0.022419\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_props = rain.isna().mean(axis=0)\n",
    "\n",
    "missing_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the proportion is higher than 40% we will drop the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaporation    0.431665\n",
       "Sunshine       0.480098\n",
       "Cloud3pm       0.408071\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_threshold = missing_props[missing_props >= 0.4]\n",
    "\n",
    "over_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three columns contain more than 40% missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain.drop(over_threshold.index, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, there are both categorical and numeric features. We will build two separate pipelines and combine them later. \n",
    "\n",
    "> The next code examples will heavily use Sklearn-Pipelines. If you are not familiar with them, check out my separate article for the [complete guide](https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d) on them.\n",
    "\n",
    "For the categorical features, we will impute the missing values with the mode of the column and encode them with One-Hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "    ('oh-encode', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the numeric features, I will choose the mean as an imputer and `StandardScaler` so that the features has 0 mean and a variance of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scale', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will combine the two pipelines with a column transformer. To specify which columns the pipelines are designed for, we should first isolate the categorical and numeric feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = rain.select_dtypes(exclude='number')\n",
    "num_cols = rain.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will input these along with their corresponding pipelines into a `ColumnTransFormer` instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_processor = ColumnTransformer(transformers=[\n",
    "    ('numeric', numeric_pipeline, num_cols),\n",
    "    ('categorical', categorical_pipeline, cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full pipeline is finally ready. The only thing missing is the XGBoost classifier, which we will add in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### An Example of XGBoost For a Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Powers XGBoost Under the Hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation OR Hyperparameter Tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
