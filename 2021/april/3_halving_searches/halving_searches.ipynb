{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Sklearn's HalvingGridSearchCV and HalvingRandomizedSearchCV?\n",
    "## Even faster hyperparameter tuning for massive models\n",
    "<img src='images/tune.jpg'></img>\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@karolina-grabowska?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Karolina Grabowska</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/person-holding-tuning-pegs-4472108/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's make sure we are all on the same page on some of the terms I will be using today.\n",
    "\n",
    "**1. Hyperparameters**: a model's internal settings that should be set by the user. The model cannot learn these from training data. An example is the learning rate in `xgboost` estimators.\n",
    "\n",
    "**2. Parameter Grid**: a dictionary with parameter names as keys and a list of possible hyperparameters as values. Here is a sample parameter grid for `XGBClassifier`:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"scale_pos_weight\": [1, 3, 5]\n",
    "}\n",
    "```\n",
    "A parameter grid's size or all possible combinations are calculated by multiplying the number of possible values of each parameter. So, the above grid has 4 * 3 * 3 = 36 possible combinations. Generally, parameter grids will be much larger than that.\n",
    "\n",
    "**3. Candidate**: a single combination from all possible sets of hyperparameters in a parameter grid.\n",
    "\n",
    "**4. Resources or samples**: another name for the data at hand. One sample refers to a single row in training data.\n",
    "\n",
    "**5. Iteration**: any single round in which a single set of hyperparameters is used on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Overview of `GridSearchCV` and `RanomizedSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the main ideas of the new classes are related to GridSearch and RandomSearch, let me briefly give an overview of how they work.\n",
    "\n",
    "GridSearch is an exhaustive, brute-force estimator. This means that all combinations of hyperparameters will be trained using cross-validation. If there are 100 possible candidates and you are doing 5-fold cross-validation, the given model will be trained 500 times (500 iterations) . Surely, this will take excruciatingly long time for heavy models.\n",
    "\n",
    "RandomizedSearch tries to control the number of iterations by making 'smarter' choices about which set of parameters to choose in each iteration. It has an additional `n_iter` parameter which directly controls this process. If there are 1000 candidates and `n_iter` is set to 100, the search will stop after 100th iteration and returns the best results from those 100. This random choosing process results in a much shorter training time but its performance won't be as good as GridSearch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about them and see them in action check out my separate article on the topic:\n",
    "https://towardsdatascience.com/automatic-hyperparameter-tuning-with-sklearn-gridsearchcv-and-randomizedsearchcv-e94f53a518ee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is Successive Halving?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "While both GridSearch and RandomizedSearch train the candidates on all of the training data, HalvingGridSearch and HalvingRandomSearch take a smarter approach called *successive halving*. Let's see what it means in terms of HalvingGridSearch (HGS).\n",
    "\n",
    "HGS is like a competition among all candidates (hyperparameter combinations). In the first iteration, HGS trains all candidates on a small proportion of the training data. In the next iteration, only the candidates which performed best are chosen and they will be given more resources to compete. So, with each passing iteration, the 'surviving' candidates will be given more and more resources (training samples) until there is only two sets of best hyperparameters standing. Lastly, these two are trained on the full data and the best one is found. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get more granular. The above process can be controlled by two arguments - `factor` and `min_samples`. `min_samples` takes an integer to specify the number of samples of the training data to use in the first iteration. All candidates are trained on this data and in the next iteration `min_samples` grows by `factor` and the number of candidates decreases by `factor`. All next rounds continue in this manner until the best candidate is found. \n",
    "\n",
    "To let the idea sink in with an example, let's say we have 1000 samples and 20 candidates in the parameter grid. If we set `min_samples` to 20 and choose a `factor` of 2, here is how the iterations will unfold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_candidates</th>\n",
       "      <th>*factor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iteration</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n_samples  n_candidates  *factor\n",
       "iteration                                  \n",
       "1                 20            20        2\n",
       "2                 40            10        2\n",
       "3                 80             5        2\n",
       "4                160             2        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"iteration\": [1, 2, 3, 4],\n",
    "        \"n_samples\": [20, 40, 80, 160],\n",
    "        \"n_candidates\": [20, 10, 5, 2],\n",
    "        \"*factor\": [2, 2, 2, 2],\n",
    "    }\n",
    ").set_index(\"iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the `min_resources` to 20 with 20 candidates, we are only able to run 4 iterations because we will run out of candidates before exhausting all samples. This means the rest of the training data (1000 - 160 = 840) will be wasted and the best candidate is only found by training only on 160 rows of data. \n",
    "\n",
    "Similarly, we may also run out of samples before all candidates are tried out. For example, let's say we have 1000 samples and 300 candidates. We set `min_samples` to 50 and choose a factor of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_candidates</th>\n",
       "      <th>*factor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iteration</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>800</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n_samples  n_candidates  *factor\n",
       "iteration                                  \n",
       "1                 50           300        2\n",
       "2                100           150        2\n",
       "3                200            75        2\n",
       "4                400            37        2\n",
       "5                800            18        2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"iteration\": [1, 2, 3, 4, 5],\n",
    "        \"n_samples\": [50, 100, 200, 400, 800],\n",
    "        \"n_candidates\": [300, 150, 75, 37, 18],\n",
    "        \"*factor\": [2, 2, 2, 2, 2],\n",
    "    }\n",
    ").set_index(\"iteration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, at the 5th iteration, we don't have enough resources to double further and we are left with 18 final candidates. These final candidates have no choice but to be trained on the full dataset which is no different than plain old GridSearch. This problem is even more evident with real world datasets. \n",
    "\n",
    "For example, the dataset we will be using today has 145k samples. So, we need to make sure that we choose the perfect combination of `factor` and `min_samples` depending on the size of our parameter grid that we will end up with as much unwasted resources as possible with the least amount of best candidates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That sure sounds a lot of work but fortunately you can pass `exhaust` to `min_samples` so that the minimum number of resources will be automatically determined to create the best possible combination with `factor` and number of candidates. For example, for 1000 samples and a factor of 2, setting the `min_samples` to `exhaust` will set it to 250 which will become 250, 500, 1000 samples as we go through each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The official guide says that exhausting the number of samples will definitely lead to a more robust selection of parameters but might be a bit more time-consuming. In the next sections, we will explore just how much better the new classes are than their counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of HalvingGridSearchCV to old GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the two classes, I will be using the [Rain in Australia](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package) dataset to predict whether it rains today or not. To focus only on the topic at hand, I created `prep.py` file which contains all necessary preprocessing steps required: handling missing values, scaling numeric features and encoding categorical variables (you can get the file in [this GitHub gist](https://gist.github.com/BexTuychiev/64f68715c6e5a0cafe2a7ce595a03eb3))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rain = pd.read_csv(\"data/weatherAUS.csv\")\n",
    "rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "rain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the `preprocess` function returns a cleaned, processed feature and target arrays which we will save under traditional names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prep import preprocess\n",
    "\n",
    "# Get the preprocessed feature and target arrays\n",
    "X, y = preprocess(rain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is `RainToday` and as a base estimator, we will use XGBoostClassifier. Let's first establish base score by fitting it with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Init the classifier\n",
    "xgb_cl = xgb.XGBClassifier(objective=\"binary:logistic\", verbose=None, seed=1121218)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:44:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1121218, stratify=y\n",
    ")\n",
    "\n",
    "# Fit\n",
    "_ = xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "preds = xgb_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the ROC_AUC score, the target and predictions should be encoded which they are not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([['No'],\n",
       "        ['No'],\n",
       "        ['No'],\n",
       "        ...,\n",
       "        ['No'],\n",
       "        ['No'],\n",
       "        ['No']], dtype=object),\n",
       " array(['No', 'No', 'No', ..., 'No', 'No', 'No'], dtype=object))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7345459498475863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Encode target and preds\n",
    "def encode(target_array, predictions):\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    y_true = le.fit_transform(target_array)\n",
    "    preds = le.fit_transform(predictions)\n",
    "\n",
    "    return y_true, preds\n",
    "\n",
    "\n",
    "y_test_encoded, preds_encoded = encode(y_test, preds)\n",
    "\n",
    "# Score\n",
    "roc_auc_score(y_test_encoded, preds_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a base score of 0.73. Now, we will try to improve on this by tuning only 4 of the hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],  # Fix subsample\n",
    "    \"colsample_bytree\": [0.5],  # Fix colsample_bytree\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_candidates = 1\n",
    "\n",
    "for params in param_grid.values():\n",
    "    n_candidates *= len(params)\n",
    "\n",
    "n_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of candidates is 108. First, we will do exhaustive GridSearch with 5-fold cross-validation which is the default in both classes. The metric is still `roc_auc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 6min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Init the estimator\n",
    "grid_cv = GridSearchCV(xgb_cl, param_grid, scoring=\"roc_auc\", n_jobs=-1, cv=3)\n",
    "\n",
    "# Fit\n",
    "_ = grid_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7290428559466373"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid_cv.best_estimator_\n",
    "_ = model.fit(X_train, y_train_encoded)\n",
    "preds = model.predict(X_test)\n",
    "roc_auc_score(y_test_encoded, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8634518251165503"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After more than an hour, we found the best params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 1,\n",
       " 'max_depth': 5,\n",
       " 'reg_lambda': 10,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the `roc_auc` score actually went down and I am guessing, we did not provide good enough parameter grid. However, for the sake of comparison, let's perform the same tuning using `HalvingGridSearchCV`. It is also imported from `sklearn.model_selection` but you should also import `enable_halving_search_cv` because it is still an experimental feature.\n",
    "\n",
    "As I said, we will set `min_resources` to `exhaust` and choose a factor of 3 which Scikit-learn recommends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:49:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 4min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "halving_cv = HalvingGridSearchCV(\n",
    "    xgb_cl, param_grid, scoring=\"roc_auc\", n_jobs=-1, min_resources=\"exhaust\", factor=3\n",
    ")\n",
    "\n",
    "_ = halving_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8625500412188662"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halving_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Phenomenal decrease in runtime - almost 11 times faster than GridSearch. Let's look at the performance now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.25,\n",
       " 'max_depth': 4,\n",
       " 'reg_lambda': 10,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halving_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though both have a slight decrease in performance than the default model, HGS performed equally well while taking 11 times less training time! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating HalvingRandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's create a bigger grid with better possible hyperparameters. \n",
    "\n",
    "First of all, XGBoost documentation says that to account for class imbalance, we should adjust `scale_pos_weight`. It is shown that to find the optimal value, we should divide the sum of negative classes by the sum of positives. Let's do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     113580\n",
       "Yes     31880\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.Series(y.flatten()).value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5627352572145545"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_pos_weight = counts['No'] / counts['Yes']\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the `scale_pos_weight`. Now, we were also fixing the `subsample` and `colsample_bytree` values to avoid overfitting. However, let's provide higher values this time because the model might have been too constrained. \n",
    "\n",
    "Last time, `gamma`'s best value was found to be 1 which is the end of its range, so we should extend its range too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_2 = {\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"gamma\": [5, 30, 50],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3, 0.5],\n",
    "    \"min_child_weight\": [1, 3, 5],\n",
    "    \"reg_lambda\": [50, 100, 300],\n",
    "    \"scale_pos_weight\": [scale_pos_weight], # Fix scale_pos_weight\n",
    "    \"subsample\": [.7, .8, .9], \n",
    "    \"colsample_bytree\": [.7, .8, .9], \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have got a pretty massive grid, the one with almost 3000 candidates. Let's see what `HalvingRandomSearchCV` makes of this. Exhausting all the available resources in this class is done by setting `n_candidates` to `exhaust`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I am not even bothering to compare `HalvingRandomSearchCV` to plain-old `RandomizedSearchCV` after seeing the seeing HGS crush the GridSearch. Clearly, successive halving is way better than both of the old methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:08:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 10min 16s\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"689709d8-7c90-4f39-8915-986953bb0c6b\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"689709d8-7c90-4f39-8915-986953bb0c6b\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell execution has finished!\", \"only_in_background\": false};\n",
       "\n",
       "                // We have a notification but the window is active\n",
       "                if (notificationPayload.only_in_background && !window.jupyterNotifyIsInBackground) {\n",
       "                    appendUniqueDiv();\n",
       "                    return;\n",
       "                }\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify\n",
    "%%time\n",
    "\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "\n",
    "halving_random_cv = HalvingRandomSearchCV(\n",
    "    xgb_cl, param_grid_2, scoring=\"roc_auc\", n_jobs=-1, n_candidates=\"exhaust\", factor=4\n",
    ")\n",
    "\n",
    "_ = halving_random_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7934276560521571"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_encoded, preds_encoded = encode(y_test, preds)\n",
    "roc_auc_score(y_test_encoded, preds_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a pretty massive grid, it took only 10 minutes to find the best score. Besides, this time we saw a 6% increase in `roc_auc` score which we could not do with both HGS and GridSearch. \n",
    "\n",
    "Are you impressed yet?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
