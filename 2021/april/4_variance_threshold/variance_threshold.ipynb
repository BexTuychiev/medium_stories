{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use Variance Threshold Properly\n",
    "## There is more to it than just choosing a threshold\n",
    "<img src='images/pexels.jpg'></img>\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@billelmoula?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Billel Moula</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/black-and-teal-mountain-540518/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, it is common for datasets to have hundreds if not thousands of features. On the surface, this might seem like a good thing - more features give more information about each sample. But more often that not, these additional features don't provide that much value and introduce unnecessary complexity.\n",
    "\n",
    "The biggest challenge of Machine Learning is to create models that have robust predictive power by using as few features as possible. But given the massive sizes of today's datasets, it is easy to lose the oversight of which features are important and which ones aren't. \n",
    "\n",
    "That's why, there is an entire skill to be learned in the ML field - **feature selection**. Feature selection is the process of choosing a subset of the most important features while trying to retain as much information as possible. \n",
    "\n",
    "As an example, let's say we have a dataset of body measurements such as weight, height, BMI, etc. Basic feature selection techniques should be able to drop BMI by finding out that BMI can be represented by weight and height.\n",
    "\n",
    "In this article, we will explore one such feature selection technique called Variance Thresholding. This technique is a quick and light-weight way of eliminating features with very low variance, i. e. features with not much useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those who are not familiar, *variance*, as the name suggests, shows the variability in a distribution in a single metric. It shows how spread out the distribution is and shows the average squared distance from the mean:"
   ]
  },
  {
   "attachments": {
    "8675e508-b7aa-46e0-80f9-681a704eb413.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:8675e508-b7aa-46e0-80f9-681a704eb413.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, distributions with bigger values yield a bigger variance because each difference is squared. But the main thing we care about in ML is that the distribution actually contains useful information. For example, consider this distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_1 = [2, 2, 2, 2, 2, 2, 2, 2]\n",
    "\n",
    "np.std(dist_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the variance with Numpy shows us that the distribution has 0 variance or in other words completely useless. Using a feature with zero-variance only adds to model complexity not to its predictive power. Consider another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28747978728803447"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_2 = [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6]\n",
    "\n",
    "np.std(dist_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, this one is almost made up of a single constant. Distributions that go around a single constant with a few exceptions are also useless. In other words, any feature or distribution with close to 0 variance should be dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Use Scikit-learn's VarianceThreshold Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Manually computing variances and thresholding them can be a lot of work. Fortunately, Scikit-learn provides `VarianceThreshold` estimator which can do all the work for us. Just pass a threshold cut-off and all features below that threshold will be dropped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate `VarianceThreshold`, we will be working with Ansur dataset. This dataset records measurements of the human body in every imaginable way. Both male and female datasets contain 108 features or measurements of almost 6000 (4000 male, 2000 female) US Army Personnel. We will will be focusing on the male dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>...</th>\n",
       "      <th>Branch</th>\n",
       "      <th>PrimaryMOS</th>\n",
       "      <th>SubjectsBirthLocation</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "      <th>WritingPreference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>266</td>\n",
       "      <td>1467</td>\n",
       "      <td>337</td>\n",
       "      <td>222</td>\n",
       "      <td>1347</td>\n",
       "      <td>253</td>\n",
       "      <td>202</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Arms</td>\n",
       "      <td>19D</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>180</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>1395</td>\n",
       "      <td>326</td>\n",
       "      <td>220</td>\n",
       "      <td>1293</td>\n",
       "      <td>245</td>\n",
       "      <td>193</td>\n",
       "      <td>394</td>\n",
       "      <td>338</td>\n",
       "      <td>257</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>160</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>287</td>\n",
       "      <td>1430</td>\n",
       "      <td>341</td>\n",
       "      <td>230</td>\n",
       "      <td>1327</td>\n",
       "      <td>256</td>\n",
       "      <td>196</td>\n",
       "      <td>427</td>\n",
       "      <td>408</td>\n",
       "      <td>261</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Support</td>\n",
       "      <td>68W</td>\n",
       "      <td>New York</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>205</td>\n",
       "      <td>Left hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234</td>\n",
       "      <td>1347</td>\n",
       "      <td>310</td>\n",
       "      <td>230</td>\n",
       "      <td>1239</td>\n",
       "      <td>262</td>\n",
       "      <td>199</td>\n",
       "      <td>401</td>\n",
       "      <td>359</td>\n",
       "      <td>262</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>88M</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>66</td>\n",
       "      <td>175</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>1585</td>\n",
       "      <td>372</td>\n",
       "      <td>247</td>\n",
       "      <td>1478</td>\n",
       "      <td>267</td>\n",
       "      <td>224</td>\n",
       "      <td>435</td>\n",
       "      <td>356</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>Combat Service Support</td>\n",
       "      <td>92G</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>213</td>\n",
       "      <td>Right hand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdominalextensiondepthsitting  acromialheight  acromionradialelength  \\\n",
       "0                             266            1467                    337   \n",
       "1                             233            1395                    326   \n",
       "2                             287            1430                    341   \n",
       "3                             234            1347                    310   \n",
       "4                             250            1585                    372   \n",
       "\n",
       "   anklecircumference  axillaheight  balloffootcircumference  \\\n",
       "0                 222          1347                      253   \n",
       "1                 220          1293                      245   \n",
       "2                 230          1327                      256   \n",
       "3                 230          1239                      262   \n",
       "4                 247          1478                      267   \n",
       "\n",
       "   balloffootlength  biacromialbreadth  bicepscircumferenceflexed  \\\n",
       "0               202                401                        369   \n",
       "1               193                394                        338   \n",
       "2               196                427                        408   \n",
       "3               199                401                        359   \n",
       "4               224                435                        356   \n",
       "\n",
       "   bicristalbreadth  ...                  Branch  PrimaryMOS  \\\n",
       "0               274  ...             Combat Arms         19D   \n",
       "1               257  ...          Combat Support         68W   \n",
       "2               261  ...          Combat Support         68W   \n",
       "3               262  ...  Combat Service Support         88M   \n",
       "4               263  ...  Combat Service Support         92G   \n",
       "\n",
       "   SubjectsBirthLocation  SubjectNumericRace  Ethnicity  DODRace  Age  \\\n",
       "0           North Dakota                   1        NaN        1   41   \n",
       "1               New York                   1        NaN        1   35   \n",
       "2               New York                   2        NaN        2   42   \n",
       "3              Wisconsin                   1        NaN        1   31   \n",
       "4         North Carolina                   2        NaN        2   21   \n",
       "\n",
       "   Heightin  Weightlbs  WritingPreference  \n",
       "0        71        180         Right hand  \n",
       "1        68        160          Left hand  \n",
       "2        68        205          Left hand  \n",
       "3        66        175         Right hand  \n",
       "4        77        213         Right hand  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansur_male = pd.read_csv('data/ansur_male.csv', encoding='latin').drop('subjectid', axis=1)\n",
    "ansur_male.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get rid of the features with zero-variance. We will import `VarianceThreshold` from `sklearn.feature_selection`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "vt = VarianceThreshold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize it just like any other Scikit-learn estimator. The default value for the threshold is always 0. Also, the estimator only works with numeric data obviously and it will raise an error if there are categorical features present in the dataframe. That's why, for now, we will subset the numeric features into another dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4082, 98)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansur_male_num = ansur_male.select_dtypes(include='number')\n",
    "ansur_male_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have got 98 numeric features. Let's now fit the estimator to the data and get its results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 266, 1467,  337, ...,   41,   71,  180],\n",
       "       [ 233, 1395,  326, ...,   35,   68,  160],\n",
       "       [ 287, 1430,  341, ...,   42,   68,  205],\n",
       "       ...,\n",
       "       [ 264, 1394,  313, ...,   23,   67,  186],\n",
       "       [ 203, 1417,  327, ...,   22,   69,  165],\n",
       "       [ 327, 1523,  358, ...,   38,   73,  218]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = vt.fit_transform(ansur_male_num)\n",
    "transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directly calling `fit_transform` will return the dataframe as a `numpy` array with features dropped. But sometimes, we don't want the result in that format because the column names will be removed. Consider the alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vt.fit(ansur_male_num)\n",
    "\n",
    "mask = vt.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, we fit the estimator to data and call its `get_support()` method. It returns a boolean mask with `True` values for columns which are not dropped. We can then use this mask to subset our DataFrame like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansur_male_num = ansur_male_num.loc[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape of the DataFrame to see if there were any constant columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4082, 98)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ansur_male_num.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, we still have the same number of features. Now, let's drop features with variances close to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4082, 97)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=1)\n",
    "\n",
    "# Fit\n",
    "_ = vt.fit(ansur_male_num)\n",
    "# Get the boolean mask\n",
    "mask = vt.get_support()\n",
    "\n",
    "ansur_reduced = ansur_male_num.loc[:, mask]\n",
    "ansur_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `threshold` of 1, only 1 feature got dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairer Comparison of Variance With Feature Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, it is not fair to compare the variance of a feature to another. The reason is that as the values in a distribution gets bigger, the variance grows exponentially. In other words, the variances will not be on the same scale. Consider this example:\n",
    "\n",
    "<img src='images/1.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above features all have different medians, quartiles and ranges - completely different distributions. We cannot compare these features to each other. \n",
    "\n",
    "One method we can use is normalizing all features by dividing them by their mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abdominalextensiondepthsitting</th>\n",
       "      <th>acromialheight</th>\n",
       "      <th>acromionradialelength</th>\n",
       "      <th>anklecircumference</th>\n",
       "      <th>axillaheight</th>\n",
       "      <th>balloffootcircumference</th>\n",
       "      <th>balloffootlength</th>\n",
       "      <th>biacromialbreadth</th>\n",
       "      <th>bicepscircumferenceflexed</th>\n",
       "      <th>bicristalbreadth</th>\n",
       "      <th>...</th>\n",
       "      <th>waistfrontlengthsitting</th>\n",
       "      <th>waistheightomphalion</th>\n",
       "      <th>weightkg</th>\n",
       "      <th>wristcircumference</th>\n",
       "      <th>wristheight</th>\n",
       "      <th>SubjectNumericRace</th>\n",
       "      <th>DODRace</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heightin</th>\n",
       "      <th>Weightlbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.044567</td>\n",
       "      <td>1.018229</td>\n",
       "      <td>1.005237</td>\n",
       "      <td>0.967978</td>\n",
       "      <td>1.013481</td>\n",
       "      <td>1.003900</td>\n",
       "      <td>1.005300</td>\n",
       "      <td>0.964694</td>\n",
       "      <td>1.030336</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>...</td>\n",
       "      <td>1.135066</td>\n",
       "      <td>0.997648</td>\n",
       "      <td>0.952949</td>\n",
       "      <td>0.994789</td>\n",
       "      <td>1.006476</td>\n",
       "      <td>0.111439</td>\n",
       "      <td>0.651868</td>\n",
       "      <td>1.359462</td>\n",
       "      <td>1.013768</td>\n",
       "      <td>0.957422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.914978</td>\n",
       "      <td>0.968255</td>\n",
       "      <td>0.972425</td>\n",
       "      <td>0.959258</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.972156</td>\n",
       "      <td>0.960509</td>\n",
       "      <td>0.947854</td>\n",
       "      <td>0.943776</td>\n",
       "      <td>0.933075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957067</td>\n",
       "      <td>0.997648</td>\n",
       "      <td>0.848885</td>\n",
       "      <td>0.949313</td>\n",
       "      <td>0.961639</td>\n",
       "      <td>0.111439</td>\n",
       "      <td>0.651868</td>\n",
       "      <td>1.160516</td>\n",
       "      <td>0.970932</td>\n",
       "      <td>0.851042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.127033</td>\n",
       "      <td>0.992548</td>\n",
       "      <td>1.017168</td>\n",
       "      <td>1.002861</td>\n",
       "      <td>0.998433</td>\n",
       "      <td>1.015804</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>1.027243</td>\n",
       "      <td>1.139233</td>\n",
       "      <td>0.947598</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060254</td>\n",
       "      <td>0.985343</td>\n",
       "      <td>1.086245</td>\n",
       "      <td>1.023212</td>\n",
       "      <td>0.980518</td>\n",
       "      <td>0.222877</td>\n",
       "      <td>1.303737</td>\n",
       "      <td>1.392620</td>\n",
       "      <td>0.970932</td>\n",
       "      <td>1.090397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.918905</td>\n",
       "      <td>0.934938</td>\n",
       "      <td>0.924698</td>\n",
       "      <td>1.002861</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>1.039612</td>\n",
       "      <td>0.990370</td>\n",
       "      <td>0.964694</td>\n",
       "      <td>1.002413</td>\n",
       "      <td>0.951228</td>\n",
       "      <td>...</td>\n",
       "      <td>1.029298</td>\n",
       "      <td>0.916246</td>\n",
       "      <td>0.928395</td>\n",
       "      <td>1.000473</td>\n",
       "      <td>0.935681</td>\n",
       "      <td>0.111439</td>\n",
       "      <td>0.651868</td>\n",
       "      <td>1.027886</td>\n",
       "      <td>0.942376</td>\n",
       "      <td>0.930827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.981736</td>\n",
       "      <td>1.100131</td>\n",
       "      <td>1.109638</td>\n",
       "      <td>1.076985</td>\n",
       "      <td>1.112046</td>\n",
       "      <td>1.059452</td>\n",
       "      <td>1.114788</td>\n",
       "      <td>1.046489</td>\n",
       "      <td>0.994037</td>\n",
       "      <td>0.954859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977704</td>\n",
       "      <td>1.178436</td>\n",
       "      <td>1.106123</td>\n",
       "      <td>1.068688</td>\n",
       "      <td>1.125648</td>\n",
       "      <td>0.222877</td>\n",
       "      <td>1.303737</td>\n",
       "      <td>0.696310</td>\n",
       "      <td>1.099438</td>\n",
       "      <td>1.132949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abdominalextensiondepthsitting  acromialheight  acromionradialelength  \\\n",
       "0                        1.044567        1.018229               1.005237   \n",
       "1                        0.914978        0.968255               0.972425   \n",
       "2                        1.127033        0.992548               1.017168   \n",
       "3                        0.918905        0.934938               0.924698   \n",
       "4                        0.981736        1.100131               1.109638   \n",
       "\n",
       "   anklecircumference  axillaheight  balloffootcircumference  \\\n",
       "0            0.967978      1.013481                 1.003900   \n",
       "1            0.959258      0.972852                 0.972156   \n",
       "2            1.002861      0.998433                 1.015804   \n",
       "3            1.002861      0.932222                 1.039612   \n",
       "4            1.076985      1.112046                 1.059452   \n",
       "\n",
       "   balloffootlength  biacromialbreadth  bicepscircumferenceflexed  \\\n",
       "0          1.005300           0.964694                   1.030336   \n",
       "1          0.960509           0.947854                   0.943776   \n",
       "2          0.975439           1.027243                   1.139233   \n",
       "3          0.990370           0.964694                   1.002413   \n",
       "4          1.114788           1.046489                   0.994037   \n",
       "\n",
       "   bicristalbreadth  ...  waistfrontlengthsitting  waistheightomphalion  \\\n",
       "0          0.994796  ...                 1.135066              0.997648   \n",
       "1          0.933075  ...                 0.957067              0.997648   \n",
       "2          0.947598  ...                 1.060254              0.985343   \n",
       "3          0.951228  ...                 1.029298              0.916246   \n",
       "4          0.954859  ...                 0.977704              1.178436   \n",
       "\n",
       "   weightkg  wristcircumference  wristheight  SubjectNumericRace   DODRace  \\\n",
       "0  0.952949            0.994789     1.006476            0.111439  0.651868   \n",
       "1  0.848885            0.949313     0.961639            0.111439  0.651868   \n",
       "2  1.086245            1.023212     0.980518            0.222877  1.303737   \n",
       "3  0.928395            1.000473     0.935681            0.111439  0.651868   \n",
       "4  1.106123            1.068688     1.125648            0.222877  1.303737   \n",
       "\n",
       "        Age  Heightin  Weightlbs  \n",
       "0  1.359462  1.013768   0.957422  \n",
       "1  1.160516  0.970932   0.851042  \n",
       "2  1.392620  0.970932   1.090397  \n",
       "3  1.027886  0.942376   0.930827  \n",
       "4  0.696310  1.099438   1.132949  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df = ansur_male_num / ansur_male_num.mean()\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method ensures that all varainces are on the same scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abdominalextensiondepthsitting     0.021486\n",
       "acromialheight                     0.001930\n",
       "acromionradialelength              0.002720\n",
       "anklecircumference                 0.004080\n",
       "axillaheight                       0.002005\n",
       "                                    ...    \n",
       "SubjectNumericRace                85.577697\n",
       "DODRace                            0.390651\n",
       "Age                                0.085336\n",
       "Heightin                           0.001771\n",
       "Weightlbs                          0.025364\n",
       "Length: 98, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the estimator with a lower threshold like 0.005 or 0.003:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4082, 48)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold=.003)\n",
    "\n",
    "# Fit\n",
    "_ = vt.fit(normalized_df)\n",
    "# Get the mask\n",
    "mask = vt.get_support()\n",
    "# Subset the DataFrame\n",
    "ansur_final = ansur_male_num.loc[:, mask]\n",
    "ansur_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we were able to drop 50 features from the dataset. Now, let's test if we did the right thing by dropping so many features. \n",
    "\n",
    "We will check this by training two RandomForestRegressor to predict a person's weight in pounds: first one on the final, feature selected dataset and the second one on the full, numeric-feature only dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.988528867222243\n",
      "Test Score: 0.9511616691995844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Build feature, target arrays\n",
    "X, y = ansur_final.iloc[:, :-1], ansur_final.iloc[:, -1]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1121218)\n",
    "\n",
    "# Init, fit, score\n",
    "forest = RandomForestRegressor(random_state=1121218)\n",
    "\n",
    "_ = forest.fit(X_train, y_train)\n",
    "\n",
    "# Training Score\n",
    "print(f\"Training Score: {forest.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {forest.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both training and test score suggest a really high performance without overfitting. Now, let's train the same model on the full numeric-only dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9886396641558658\n",
      "Test Score: 0.9495977505935259\n"
     ]
    }
   ],
   "source": [
    "# Build feature, target arrays\n",
    "X, y = ansur_male_num.iloc[:, :-1], ansur_male_num.iloc[:, -1]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1121218)\n",
    "\n",
    "# Init, fit, score\n",
    "forest = RandomForestRegressor(random_state=1121218)\n",
    "\n",
    "_ = forest.fit(X_train, y_train)\n",
    "\n",
    "# Training Score\n",
    "print(f\"Training Score: {forest.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: {forest.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, even by dropping 50 features we were able to build a pretty powerful model. In fact, the first RandomForestRegressor is 1% better than the second."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
