{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27 Pandas Functions You Didn't Know Existed | P(Guarantee) = 0.9\n",
    "## Making Pandas Even More Awesome\n",
    "![](https://images.pexels.com/photos/5199661/pexels-photo-5199661.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@introspectivedsgn?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Erik Mclean</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/unrecognizable-man-in-panda-head-sitting-near-car-5199661/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels.</a> All images are by the author unless specified otherwise.\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ExcelWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ExcelWriter` is a generic class for creating excel files (with sheets!) and writing DataFrames to them. Let's say we have these 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "with pd.ExcelWriter(\"data/data.xlsx\") as writer:\n",
    "    diamonds.to_excel(writer, sheet_name=\"diamonds\")\n",
    "    tips.to_excel(writer, sheet_name=\"tips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has additional attributes to specify the datetime format to be used, whether you want to create a new excel file or modify an existing one, what happens when a sheet exists, etc. Check out the details from the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.ExcelWriter.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. factorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is a pandas alternative to Sklearn's `LabelEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 1, 3, 2, 2, 2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes, unique = pd.factorize(diamonds[\"cut\"], sort=True)\n",
    "\n",
    "codes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalIndex(['Ideal', 'Premium', 'Very Good', 'Good', 'Fair'], categories=['Ideal', 'Premium', 'Very Good', 'Good', 'Fair'], ordered=False, dtype='category')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to how the function returns the categories as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46228    0\n",
       "10292    3\n",
       "50925    1\n",
       "38309    1\n",
       "1775     0\n",
       "Name: cut_enc, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds[\"cut_enc\"] = pd.factorize(diamonds[\"cut\"])[0]\n",
    "diamonds[\"cut_enc\"].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. bdate_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A short-hand function to create TimeSeries indices with business-day frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.bdate_range(\"2021-01-01\", \"2021-01-31\")  # A period of one month\n",
    "len(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business-day frequencies are common in the financial world. So, this function may come in handy when reindexing existing time-series with `reindex` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. hasnans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers a quick method to check if a given series contains any nulls with `hasnans` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.Series([2, 4, 6, \"sadf\", np.nan])\n",
    "series.hasnans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to its [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.hasnans.html), it enables various performance increases. Note that the attribute is pd.Series-only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. convert_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all know that pandas has an annoying tendency to mark some columns as `object` data type. Instead of manually specifying their types, you can use `convert_dtypes` method which infers the best data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationId      object\n",
       "CO            float64\n",
       "O3            float64\n",
       "AQI_Bucket     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\n",
    "    \"data/station_day.csv\",\n",
    "    usecols=[\"StationId\", \"CO\", \"O3\", \"AQI_Bucket\"],\n",
    ")\n",
    "sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StationId      string\n",
       "CO            float64\n",
       "O3            float64\n",
       "AQI_Bucket     string\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.convert_dtypes().dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it can't pares dates due to the caveats of different date time formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. `at` and `iat`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two accessors are much faster alternatives to `loc` and `iloc` with a disadvantage. They only allow selecting or replacing a single value at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ideal'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.at[234, \"cut\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.iat[1564, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 16541th row of the price column\n",
    "diamonds.at[16541, \"price\"] = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. `min` and `max` along the columns axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though `min` and `max` functions are well-known, they have another useful property for some edge-cases. Consider this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>CatBoost</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>Sklearn GB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diamonds</th>\n",
       "      <td>99.733903</td>\n",
       "      <td>96.540712</td>\n",
       "      <td>91.725201</td>\n",
       "      <td>93.640438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titanic</th>\n",
       "      <td>93.130239</td>\n",
       "      <td>99.838026</td>\n",
       "      <td>93.586711</td>\n",
       "      <td>95.963391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris</th>\n",
       "      <td>97.153966</td>\n",
       "      <td>98.354851</td>\n",
       "      <td>90.585250</td>\n",
       "      <td>93.693119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heart Disease</th>\n",
       "      <td>92.590182</td>\n",
       "      <td>94.402339</td>\n",
       "      <td>93.373349</td>\n",
       "      <td>93.399484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loan Default</th>\n",
       "      <td>98.359192</td>\n",
       "      <td>91.073934</td>\n",
       "      <td>90.595855</td>\n",
       "      <td>92.900320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 XGBoost   CatBoost   LightGBM  Sklearn GB\n",
       "Diamonds       99.733903  96.540712  91.725201   93.640438\n",
       "Titanic        93.130239  99.838026  93.586711   95.963391\n",
       "Iris           97.153966  98.354851  90.585250   93.693119\n",
       "Heart Disease  92.590182  94.402339  93.373349   93.399484\n",
       "Loan Default   98.359192  91.073934  90.595855   92.900320"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [\"Diamonds\", \"Titanic\", \"Iris\", \"Heart Disease\", \"Loan Default\"]\n",
    "libraries = [\"XGBoost\", \"CatBoost\", \"LightGBM\", \"Sklearn GB\"]\n",
    "df = pd.DataFrame(\n",
    "    {lib: np.random.uniform(90, 100, 5) for lib in libraries}, index=index\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above fake DataFrame is a point-performance of 4 different gradient boosting libraries on 5 datasets. We want to find the library that performed best at each dataset non-manually. Here is how you do it with `max`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diamonds         99.733903\n",
       "Titanic          99.838026\n",
       "Iris             98.354851\n",
       "Heart Disease    94.402339\n",
       "Loan Default     98.359192\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just change the axis to 1 and you get a row-wise max/min. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one of the best functions for doing data cleaning in a concise, compact manner. `pipe` function allows you to chain multiple custom functions into a single operation.\n",
    "\n",
    "For example, let's say you have custom functions to `drop_duplicates`, `remove_outliers`, `encode_categoricals` that accept their own custom arguments. Here is how you apply all three in a single operation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df_preprocessed = (diamonds.pipe(drop_duplicates).\n",
    "                            pipe(remove_outliers, ['price', 'carat', 'depth']).\n",
    "                            pipe(encode_categoricals, ['cut', 'color', 'clarity'])\n",
    "                  )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like how this function resembles [Sklearn pipelines](https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d). There is more you can do with the function, so check out the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pipe.html) or this [helpful article](https://towardsdatascience.com/a-better-way-for-data-preprocessing-pandas-pipe-a08336a012bc)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
