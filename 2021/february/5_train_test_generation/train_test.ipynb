{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Master The Subtle Art of Train And Test Set Generation\n",
    "## There is more to it than vanilla `train_test_split` function\n",
    "<img src='images/jump.jpg'></img>\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@mary-taylor?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Mary Taylor</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/active-man-jumping-from-brick-wall-6009265/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Base libraries\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from empiricaldist import Cdf, Pmf\n",
    "\n",
    "# Visual libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import missingno as msno  # Visualize missing values\n",
    "\n",
    "# Helper libraries\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from colorama import Fore, Back, Style\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visual setup\n",
    "import matplotlib.ticker as ticker\n",
    "plt.style.use('ggplot')\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['figure.figsize'] = [12, 9]\n",
    "rcParams['font.size'] = 16\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "custom_colors = ['#74a09e','#86c1b2','#98e2c6','#f3c969','#f2a553', '#d96548', '#c14953']\n",
    "sns.set_palette(custom_colors)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Pandas options\n",
    "pd.set_option('max_colwidth', 40)\n",
    "pd.options.display.max_columns = None  # Possible to limit\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Seed value for numpy.random\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably, the first function you learned from Scikit-learn is `train_test_split`. It performs the most basic yet a crucial task: diving the data into train and test sets. You fit the relevant model to the training set and test its accuracy on the test set. Sounds simple. But let me tell you, it is not simple. Not simple at all.\n",
    "\n",
    "Scikit-learn provides a whopping amount of [15 different functions](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) to split your data depending on different use-cases. Some of them you never heard of, some of them are used daily. But don't worry, we won't cover all of them here. Instead, we will only focus on the most common and important ones used by scientists ranging from beginner to Kaggle Grandmasters. Specifically, you will learn the most important parameter of `train_test_split` for classification tasks, in other words - stratifying and how to perform cross-validation using `cross_validate`, `cross_val_score` and `StratifiedKFold`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still need a clarification for `train_test_split`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complete starters, let me elaborate more on the `train_test_split`. Suppose we want to predict the price of a diamond depending on its several attributes like carat and the length of its dimensions. As sample data, we will load the `diamonds` dataset from Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = sns.load_dataset('diamonds')\n",
    "diamonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has several numerical and three categorical features. Since we want to predict continuous values, we can choose any regression algorithm, like `RandomForestRegressor` for the task.\n",
    "\n",
    "For all ML algorithms, there is a single, clearly defined process: divide the data into training and testing sets, fit the model on the training set and test accuracy on the test set. The reason models are not trained on all of the data is that we mostly care about how a model performs on unseen data. And almost always, you won't have enough brand-new, real-world data to test. So, the only option is to put aside some of the available data for testing. Read more about training and testing process [here](https://towardsdatascience.com/codeless-machine-learning-dictionary-for-dummies-fa912cc7bdfe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The splitting task can be done using Scikit-learn's `train_test_split` function. Below, we choose the variables to be used to predict the diamond prices as features (*X* array) and the prices itself as the target (*y* array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create features and target arrays\n",
    "X = diamonds[['carat', 'table', 'depth']]\n",
    "y = diamonds.price\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1121218)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is imported from `sklearn.model_selection`. For the first 2 arguments, we pass the feature array first and then, target array. The size of the test set is specified with `test_size` argument - here we are setting aside 30% of the data for testing. `random_state` is seeded so we get consistent results every time we run the function with the same arguments.\n",
    "\n",
    "We unpack the output into 4 variables. I want you to note the order of the outputs because it is easy to mix them.\n",
    "\n",
    "Next, we will fit a `RandomForestRegressor` model with default parameters and score it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of determination for the training set: 0.9595220664760806\n",
      "The coefficient of determination for the test set: 0.8688296178173177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize the model\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "# Fit to the training\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Print the training score\n",
    "print(\"The coefficient of determination for the training set:\", forest.score(X_train, y_train))\n",
    "print(\"The coefficient of determination for the test set:\", forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's is the basic usage of `train_test_split` for regression. But things will get more interesting for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Bias\n",
    "Before I explain how to use `train_test_split` for classification, I have to briefly mention *sampling bias*. Sampling bias occurs when the chosen sample is not representative of the population. For example, an ice-cream company may call 1000 people to find out what ice-cream flavors they like. Not to create a sampling bias, or in other words, to choose a representative ratio, the surveyors should respect the ration of males and females in the given area or city. If there are 54% males and 46% females in the area, the company has to make sure to survey 540 men and 460 women to get a representative sample. \n",
    "\n",
    "When we split the data into training and test sets, we are essentially taking samples from the population. So, whenever there are categorical variables involved, we should split the data in a way that keeps the underlying proportion of categories the same or close to same.\n",
    "\n",
    "Formally, this type of sampling is called *stratified sampling* and each unique category is called a *strata*. Next, we will see how can use this method in code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
