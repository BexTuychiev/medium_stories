{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Is Everyone at Kaggle Obsessed with Optuna For Hyperparameter Tuning?\n",
    "## Let's find out by trying it out...\n",
    "![](images/pixabay.jpg)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://pixabay.com/users/bomei615-2623913/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1751855'>Bo Mei</a>\n",
    "        on \n",
    "        <a href='https://pixabay.com/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1751855'>Pixabay.</a> All images are by author unless specified otherwise.\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out, I have been living under a rock...\n",
    "\n",
    "Every single MOOC I have taken taught me to use GridSearch for hyperparameter tuning. Naively, I loved it and went the extra mile to learn its cousins - Randomized GridSearch and Halving GridSearch.\n",
    "\n",
    "Even though they were great, I somehow tried to avoid hyperparameter tuning as much as possible. Why?\n",
    "\n",
    "First, they take such a damn long time to train. We are talking in multiples of 24-hour sessions if you are doing an exhaustive GridSearch. If you are not, then there is a pretty high chance randomized search comes up with hyperparameters that are actually worse than the defaults.\n",
    "\n",
    "While I was complaining, Kagglers have been using Optuna almost exclusively for the past 2 years to do hyperparameter tuning. \n",
    "\n",
    "After giving it a try, I am truly amazed at how it takes the whole tuning experience to the next level. So, without further ado, let me show you how to use it in your own workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Optuna?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/optuna/optuna/master/docs/image/optuna-logo.png)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Optuna logo\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optuna is a next-generation automatic hyperparameter tuning framework, written completely in Python.\n",
    "\n",
    "Its most prominent features are:\n",
    "- the ability to define Pythonic search spaces using loops and conditionals. \n",
    "- completely platform agnostic API - using Optuna, you can tune estimators of almost any ML, DL package/framework including Sklearn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost, etc.\n",
    "- a large suite of optimization algorithms with early stopping and pruning features baked in.\n",
    "- easy parallelization with little or no changes to the code.\n",
    "- built-in support for visual exploration of search results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's familiarize ourselves with Optuna API by tuning a simple function like $(x-1)^2 + (y+3)^2$. We know the function converges to its minimum at x=1 and y=-3. Let's see if Optuna can find these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna  # pip install optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -7, 7)\n",
    "    y = trial.suggest_float(\"y\", -7, 7)\n",
    "    return (x - 1) ** 2 + (y + 3) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing `optuna`, we define an objective that returns the function we want to minimize. \n",
    "\n",
    "In the body of the objective, we define the parameters to be optimized, in this case simple `x` and `y`. The argument `trial` is a special Trial object of optuna which does the optimization for each hyperparameter. \n",
    "\n",
    "Along many others, it has a `suggest_float` method which takes the name of the hyperparameter and the range to look for its optimal value. In other words\n",
    "\n",
    "```\n",
    "x = trial.suggest_float(\"x\", -7, 7)\n",
    "```\n",
    "is almost the same as `{\"x\": np.arange(-7, 7)}` when doing GridSearch.\n",
    "\n",
    "To start the optimization, we create a `study` object from Optuna and pass the `objective` function to its `optimize` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)  # number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 0.8806708977164549, 'y': -3.0941841160297767}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty close but not as close as you would want. Here, we only did 100 trials, as can be seen with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(study.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will introduce the first magic that comes with Optuna. We can resume the optimization even after it is finished if we are not satisfied with the results! \n",
    "\n",
    "This is a huge advantage over other tools because after the search is done, they completely forget the history of previous trials. Optuna does not!\n",
    "\n",
    "To continue searching, just call `optimize` again with the desired params. Here, we will add 100 more trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1.045706853335669, 'y': -2.9501109059847512}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the results are much closer to the optimal parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on Optuna terminology and conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Optuna, the whole optimization process is called a *study*. For example, tuning XGBoost parameters with a log loss as a metric is one study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "optuna.study.Study"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "type(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study needs a function it can optimize. Typically, this function is defined by the user and by convention, it should be named `objective`. \n",
    "\n",
    "The objective function is expected to have this signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Conventional optimization function\n",
    "    signature for optuna.\n",
    "    \"\"\"\n",
    "    custom_metric = ...\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should accept `optuna.Trial` object as a parameter and return the metric we want to optimize for. \n",
    "\n",
    "As we saw in the first example, a study is a collection of *trials* where in each trial, we evaluate the objective function using a single set of hyperparameters from the given search space. \n",
    "\n",
    "Each trial in the study is represented as `optuna.Trial` class. This class is key to how Optuna finds optimal values for parameters. \n",
    "\n",
    "To start a study, we create a study object with `direction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the metric we want to optimize is a point-performance score like ROC AUC or accuracy, we set the direction to `maximize`. Otherwise, we minimize a loss function like RMSE, RMSLE, log loss, etc. by setting direction to `minimize`. \n",
    "\n",
    "Then, we will call the `optimize` method of the study passing the objective function name and the number of \n",
    "trials we want:\n",
    "\n",
    "```python\n",
    "# Optimization with 100 trials\n",
    "study.optimize(objective, n_trials=100)\n",
    "```\n",
    "\n",
    "Next, we will take a closer look into creating the objective functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the search space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get serious by starting with defining the hyperparameter search space for a simple Random Forest Regressor. \n",
    "\n",
    "It is a convention to do the whole optimization process inside a function called `objective` which accepts an `optuna.trial.Trial` object and returns the metric we want to optimize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    \"\"\"Conventional optimization function\n",
    "    signature for optuna.\n",
    "    \"\"\"\n",
    "    custom_metric = ...\n",
    "    return custom_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inside this function, we will define the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    rf_params = {\n",
    "        \"n_estimators\": trial.suggest_integer(name=\"n_estimators\", low=100, high=2000),\n",
    "        \"max_depth\": trial.suggest_float(\"max_depth\", 3, 8),\n",
    "        \"max_features\": trial.suggest_categorical(\n",
    "            \"max_features\", choices=[\"auto\", \"sqrt\", \"log2\"]\n",
    "        ),\n",
    "        \"n_jobs\": -1,\n",
    "        \"random_state\": 1121218,\n",
    "    }\n",
    "\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I introduce 3 new functions of the trial object. These functions, respectively, *suggest* integer or floating point numbers within `low`/`high` or a categorical value from `choices`. \n",
    "\n",
    "> I marked the word \"suggest\" because it refers to how Optuna samples hyperparameters from a given range. We will discuss different \"samplers\" Optuna uses in the coming sections.\n",
    "\n",
    "These `suggest_*` functions are invoked to suggest a reasonable value for the hyparameter based on past iterations for every iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
