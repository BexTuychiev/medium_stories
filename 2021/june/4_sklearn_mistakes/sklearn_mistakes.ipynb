{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Sklearn Mistakes That Silently Tell You Are a Rookie\n",
    "## No error messages - that's what makes them subtle...\n",
    "![](images/unsplash.jpg)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://unsplash.com/@santabarbara77?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText'>Varvara Grabova</a>\n",
    "        on \n",
    "        <a href='https://unsplash.com/s/photos/mistake?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText'>Unsplash</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"figure.figsize\"] = [12, 9]\n",
    "rcParams[\"figure.autolayout\"] = True\n",
    "rcParams[\"xtick.labelsize\"] = 15\n",
    "rcParams[\"ytick.labelsize\"] = 15\n",
    "rcParams[\"legend.fontsize\"] = \"small\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `fit` or `fit_transform` everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the most serious mistake - a mistake that is related to *data leakage*. Data leakage is subtle and can be destructive to model performance. It occurs when information that would not be available at prediction time is used during the model training. Data leakage causes models to give very optimistic results, even in cross-validation but perform terribly when testing on actual novel data. \n",
    "\n",
    "Data leakage mostly occurs when doing data preprocessing, particularly when the training and test sets are not separated. Many Sklearn preprocessing transformers such as imputers, normalizers, standardization functions and log transformers tap into the underlying distribution of the data during the fit time. \n",
    "\n",
    "For example, `StandardScaler` normalizes the data by subtracting the mean from each sample and dividing by the standard deviation. Calling the `fit()` function on the full data (X) allows the transformer to learn the mean and standard deviation of the whole distribution of each feature. After transformation, if this data is then split into train and test sets, the train set would be contaminated because `StandardScaler` leaked important information from the actual distribution. \n",
    "\n",
    "Even though this might not be apparent to us, Sklearn algorithms are powerful enough to notice this and take advantage during testing. In other words, the train data would be too perfect for the model because it has useful information of the test set and the test would not be novel enough to test the model's performance on actual unseen data.\n",
    "\n",
    "The easiest solution is to never call `fit` on the full data. Before doing any preprocessing, always split the data into train and test sets. Even after the split, you should never call `fit` or `fit_transform` on the test set because you will end up at the same problem. \n",
    "\n",
    "Since both train and test sets should receive the same preprocessing steps, a golden rule is to use `fit_transform` on the train data - this ensures that the transformer learns only from the train set and transforms it simultaneously. Then, call the `transform` method on the test set to transform it based on the information learned only from the training data.\n",
    "\n",
    "A more robust solution would be using Sklearn's built-in pipelines. Pipeline classes are specifically built to guard algorithms from data leakage. Using pipelines ensures that only the training data is used during `fit` and the test data is used only for calculations. You can learn about them in detail in my separate article:\n",
    "\n",
    "https://towardsdatascience.com/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d?source=your_stories_page-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
