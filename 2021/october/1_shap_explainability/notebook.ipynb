{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21725b2c-8fcd-4392-8b32-f607154f6ae1",
   "metadata": {},
   "source": [
    "# Model Explainability with SHAP: A Guide to Those Who Are Serious About Machine Learning\n",
    "## SUBTITLE TODO\n",
    "![](images/pexels.jpg)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@iriser?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Irina Iriser</a>\n",
    "        on \n",
    "        <a href=https://www.pexels.com/photo/blue-and-red-jellyfish-artwork-1086583/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels''></a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689887c9-c483-4afb-8621-f2b8ae34310f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699a14ef-ff61-432d-8973-5c8f77ab8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import catboost as cb\n",
    "import datatable as dt\n",
    "import joblib\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_selector,\n",
    "    make_column_transformer,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\", datefmt=\"%d-%b-%y %H:%M:%S\", level=logging.INFO\n",
    ")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"float_format\", \"{:.5f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6fd98a-13b6-448c-92da-d6e83c91e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "X, y = diamonds.drop(\"price\", axis=1), diamonds[[\"price\"]].values.flatten()\n",
    "\n",
    "# Encode cats\n",
    "oe = OrdinalEncoder()\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "X.loc[:, cats] = oe.fit_transform(X[cats])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=1121218\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa29325-b4df-4d7a-9f67-34d2808760e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For classification - HIDE\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "X, y = diamonds.drop(\"cut\", axis=1), diamonds[[\"cut\"]].values.flatten()\n",
    "\n",
    "# Encode cats\n",
    "oe = OrdinalEncoder()\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "X.loc[:, cats] = oe.fit_transform(X[cats])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=1121218\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc63526-e4e6-4bf5-b770-9f0fafc0a39b",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2e723-9eb0-452b-b3d3-1f45c547e932",
   "metadata": {},
   "source": [
    "Today, you can't just come up to your boss and say, \"Here is my best model. Let's put it into production and be happy!\". No, it doesn't work that way now. Companies and businesses are being picky over the adoption of AI solutions because of their \"black box\" nature. They **demand** explainability. \n",
    "\n",
    "If ML specialists are coming up with tools to understand and explain the tools *they* created, the concerns and suspicions of non-technical folks is entirely justified. One of those tools introduced a few years ago is SHAP. It has the ability to break down mechanics of any machine learning model and deep neural net to make them understandable to anyone. TODO \n",
    "\n",
    "Today, we will learn how exactly SHAP works and how you can use it for classical ML tasks in your own practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c47bf-e4f4-4aac-863b-6c4ad405819d",
   "metadata": {},
   "source": [
    "# What is SHAP and Shapley values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe770d5-c18f-478a-a78f-e3db9e424fce",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) is a Python package based on the 2016 NIPS paper about SHAP values. The premise of this paper and Shapley values comes from approaches in game theory. \n",
    "\n",
    "One of the questions often posed in games is that in a group of *n* players with different skillsets, how do we divide a prize in a way that everyone gets a fair share based on their skillset? Depending on the number of players, their time of joining the game and their different contributions to the outcome, this type of calculation can become horribly complex.\n",
    "\n",
    "But what does game theory have to do with machine learning? Well, we could reframe the above question so that it becomes \"Given a prediction, how do we most accurately measure each feature's contribution?\" Yes, it is kinda like asking feature importances of a model but the answer the Shapley values give is much more sophisticated. \n",
    "\n",
    "Specifically, Shapley values can help you in:\n",
    "1. *Global model interpretability* - imagine you work for a bank and you build a classification model for loan applications. Your manager wants you to explain what (and how) different factors influence the decisions of your model. Using SHAP values, you can give a concrete answer with details of which features lead to more loans and which features lead to more rejections. You make your manager happy because now, he can draw up basic guidelines for future customers of the bank to increase their chances of getting a loan. More loans - more money for the bank.\n",
    "\n",
    "TODO - show a sample plot.\n",
    "\n",
    "2. *Local interpretability* - your model rejects one of the applications submitted to the bank a few days ago. The customer claims he followed all the guidelines and was sure to get a loan from your bank. Now, you are legally obligated to explain why your model rejected that particular candidate. Using Shapley values, every case can be analyzed on its own, without worrying about its connections to other samples in the data. In other words, you have local interpretability. You extract the Shapley values for the complaining customer and show them what parts of their application caused the rejection. You prove them wrong.\n",
    "\n",
    "TODO - show a sample plot.\n",
    "\n",
    "So, how do you calculate the mighty Shapley values? That's where we start using the SHAP package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc96fb-058d-4f95-b72c-b688cec30ac3",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a23b8e04-cdd4-4fa2-8f7a-95ab9d579ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init/train\n",
    "model = xgb.XGBRegressor(n_estimators=1000, tree_method=\"gpu_hist\").fit(\n",
    "    X_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5323ef0e-67a0-4941-89d1-ccedc7545b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate preds/score\n",
    "preds = model.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "247497ce-b097-45e7-a821-3e54dedcecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573.9077249528166"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "905b64a0-49ce-4ef6-a678-af697b62fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tree explainer\n",
    "xgb_explainer = shap.TreeExplainer(\n",
    "    model, X_train, feature_names=X_train.columns.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c076bf72-7041-46b8-bd5c-fd50fc5e3399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 45830/45849 [21:36<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Shap values with tree explainer\n",
    "shap_values = xgb_explainer.shap_values(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c8e3b1a-f344-4588-b51f-dd69b12f08e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45849, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "441e2866-3569-4f20-8b76-8bacdb0c68af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Shap values with XGBoost core moedl\n",
    "booster_xgb = model.get_booster()\n",
    "shap_values_xgb = booster_xgb.predict(xgb.DMatrix(X_train, y_train), pred_contribs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecb2d91f-fe11-4eb6-8ccb-9396cd5d8432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45849, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values_xgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d27b669-a28f-410b-bda9-46bf69f345b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SHAP interactions with XGB\n",
    "interactions_xgb = booster_xgb.predict(\n",
    "    xgb.DMatrix(X_train, y_train), pred_interactions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "647865f3-bbe3-4320-a2d7-0287d0416d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45849, 10, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_xgb.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
