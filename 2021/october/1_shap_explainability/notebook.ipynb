{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21725b2c-8fcd-4392-8b32-f607154f6ae1",
   "metadata": {},
   "source": [
    "# Model Explainability with SHAP: A Guide to Those Who Are Serious About Machine Learning\n",
    "## SUBTITLE TODO\n",
    "![](images/pexels.jpg)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@iriser?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Irina Iriser</a>\n",
    "        on \n",
    "        <a href=https://www.pexels.com/photo/blue-and-red-jellyfish-artwork-1086583/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels''></a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689887c9-c483-4afb-8621-f2b8ae34310f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699a14ef-ff61-432d-8973-5c8f77ab8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import catboost as cb\n",
    "import datatable as dt\n",
    "import joblib\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.compose import (\n",
    "    ColumnTransformer,\n",
    "    make_column_selector,\n",
    "    make_column_transformer,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\", datefmt=\"%d-%b-%y %H:%M:%S\", level=logging.INFO\n",
    ")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"float_format\", \"{:.5f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a6fd98a-13b6-448c-92da-d6e83c91e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For regression\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "X, y = diamonds.drop(\"price\", axis=1), diamonds[[\"price\"]].values.flatten()\n",
    "\n",
    "# Encode cats\n",
    "oe = OrdinalEncoder()\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "X.loc[:, cats] = oe.fit_transform(X[cats])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=1121218\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa29325-b4df-4d7a-9f67-34d2808760e1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For classification - HIDE\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "X, y = diamonds.drop(\"cut\", axis=1), diamonds[[\"cut\"]].values.flatten()\n",
    "\n",
    "# Encode cats\n",
    "oe = OrdinalEncoder()\n",
    "cats = X.select_dtypes(exclude=np.number).columns.tolist()\n",
    "X.loc[:, cats] = oe.fit_transform(X[cats])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=1121218\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc63526-e4e6-4bf5-b770-9f0fafc0a39b",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2e723-9eb0-452b-b3d3-1f45c547e932",
   "metadata": {},
   "source": [
    "Today, you can't just come up to your boss and say, \"Here is my best model. Let's put it into production and be happy!\". No, it doesn't work that way now. Companies and businesses are being picky over the adoption of AI solutions because of their \"black box\" nature. They **demand** explainability. \n",
    "\n",
    "If ML specialists are coming up with tools to understand and explain the tools *they* created, the concerns and suspicions of non-technical folks is entirely justified. One of those tools introduced a few years ago is SHAP. It has the ability to break down mechanics of any machine learning model and deep neural net to make them understandable to anyone. TODO \n",
    "\n",
    "Today, we will learn how exactly SHAP works and how you can use it for classical ML tasks in your own practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c47bf-e4f4-4aac-863b-6c4ad405819d",
   "metadata": {},
   "source": [
    "# What is SHAP and Shapley values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe770d5-c18f-478a-a78f-e3db9e424fce",
   "metadata": {},
   "source": [
    "SHAP (SHapley Additive exPlanations) is a Python package based on the 2016 NIPS paper about SHAP values. The premise of this paper and Shapley values comes from approaches in game theory. \n",
    "\n",
    "One of the questions often posed in games is that in a group of *n* players with different skillsets, how do we divide a prize in a way that everyone gets a fair share based on their skillset? Depending on the number of players, their time of joining the game and their different contributions to the outcome, this type of calculation can become horribly complex.\n",
    "\n",
    "But what does game theory have to do with machine learning? Well, we could reframe the above question so that it becomes \"Given a prediction, how do we most accurately measure each feature's contribution?\" Yes, it is kinda like asking feature importances of a model but the answer the Shapley values give is much more sophisticated. \n",
    "\n",
    "Specifically, Shapley values can help you in:\n",
    "1. *Global model interpretability* - imagine you work for a bank and you build a classification model for loan applications. Your manager wants you to explain what (and how) different factors influence the decisions of your model. Using SHAP values, you can give a concrete answer with details of which features lead to more loans and which features lead to more rejections. You make your manager happy because now, he can draw up basic guidelines for future customers of the bank to increase their chances of getting a loan. More loans - more money for the bank.\n",
    "\n",
    "TODO - show a sample plot.\n",
    "\n",
    "2. *Local interpretability* - your model rejects one of the applications submitted to the bank a few days ago. The customer claims he followed all the guidelines and was sure to get a loan from your bank. Now, you are legally obligated to explain why your model rejected that particular candidate. Using Shapley values, every case can be analyzed on its own, without worrying about its connections to other samples in the data. In other words, you have local interpretability. You extract the Shapley values for the complaining customer and show them what parts of their application caused the rejection. You prove them wrong.\n",
    "\n",
    "TODO - show a sample plot.\n",
    "\n",
    "So, how do you calculate the mighty Shapley values? That's where we start using the SHAP package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b6c5d-9114-48be-bab4-b5722045f2fe",
   "metadata": {},
   "source": [
    "# How to calculate Shapley values with SHAP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44add272-b36e-4017-8e02-8cc602e39658",
   "metadata": {},
   "source": [
    "The exact mathematical details of calculating Shapley values deserves an article of its own. Therefore, for now, I will be standing on the shoulder of giants and refer you to their posts. They are guaranteed to solidify your understanding of the concepts ([1](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30), [2](https://towardsdatascience.com/explain-your-model-with-the-shap-values-bc36aac4de3d)). \n",
    "\n",
    "In practice however, you will rarely refer to the math behind Shapley values. The reason is that all the magical details are nicely packaged inside SHAP. So, let's look our very first example. \n",
    "\n",
    "Using the Diamonds dataset built into Seaborn, we will be predicting diamond prices using several physical measurements. I processed the dataset beforehand and divided into train and validation sets. Here is the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c267df4-80e8-4b61-8196-6fc30c06de35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50250</th>\n",
       "      <td>0.73000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>62.50000</td>\n",
       "      <td>58.00000</td>\n",
       "      <td>5.73000</td>\n",
       "      <td>5.69000</td>\n",
       "      <td>3.57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34529</th>\n",
       "      <td>0.33000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>61.70000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>4.45000</td>\n",
       "      <td>4.47000</td>\n",
       "      <td>2.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25048</th>\n",
       "      <td>0.30000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>63.50000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>4.26000</td>\n",
       "      <td>4.21000</td>\n",
       "      <td>2.69000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33207</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>61.20000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>4.77000</td>\n",
       "      <td>4.81000</td>\n",
       "      <td>2.93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>0.33000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>62.40000</td>\n",
       "      <td>56.00000</td>\n",
       "      <td>4.41000</td>\n",
       "      <td>4.43000</td>\n",
       "      <td>2.76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        carat     cut   color  clarity    depth    table       x       y  \\\n",
       "50250 0.73000 3.00000 4.00000  3.00000 62.50000 58.00000 5.73000 5.69000   \n",
       "34529 0.33000 2.00000 3.00000  6.00000 61.70000 56.00000 4.45000 4.47000   \n",
       "25048 0.30000 4.00000 2.00000  2.00000 63.50000 57.00000 4.26000 4.21000   \n",
       "33207 0.40000 2.00000 6.00000  2.00000 61.20000 56.00000 4.77000 4.81000   \n",
       "7051  0.33000 2.00000 5.00000  7.00000 62.40000 56.00000 4.41000 4.43000   \n",
       "\n",
       "            z  \n",
       "50250 3.57000  \n",
       "34529 2.75000  \n",
       "25048 2.69000  \n",
       "33207 2.93000  \n",
       "7051  2.76000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a19711a-0dad-4a59-a9d6-5432d6aa1108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45849, 9), (8091, 9))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29f3e8-b360-453d-8190-89edb9470eba",
   "metadata": {},
   "source": [
    "Cut, color and clarity are categorical features. They are encoded ordinally as their orders have meaning to the context and ultimately, to model decision.\n",
    "\n",
    "As a baseline, we fit a XGBRegressor model and evaluate the performance with Root Mean Squared Error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a23b8e04-cdd4-4fa2-8f7a-95ab9d579ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=1000, tree_method=\"gpu_hist\").fit(\n",
    "    X_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5323ef0e-67a0-4941-89d1-ccedc7545b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, preds, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "247497ce-b097-45e7-a821-3e54dedcecc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573.9077249528166"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab4028-f9b8-4787-b370-5465e9db5753",
   "metadata": {},
   "source": [
    "Now, let's finally take a peek behind the curtains and calculate the Shapley values for the training set. \n",
    "\n",
    "We start by creating an explainer object for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "905b64a0-49ce-4ef6-a678-af697b62fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tree explainer\n",
    "xgb_explainer = shap.TreeExplainer(\n",
    "    model, X_train, feature_names=X_train.columns.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4075758-615d-4995-8399-ceaf05ab309c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<shap.explainers._tree.Tree at 0x283af1834c0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc556334-b987-4c2e-9c0d-ad636855fb70",
   "metadata": {},
   "source": [
    "`TreeExplainer` is a special class of SHAP optimized to work with any tree-based model in Sklearn, XGBoost, LightGBM, CatBoost and so on. You can use `KernelExplainer` for any other type of models, though it is slower than tree explainers. \n",
    "\n",
    "This tree explainer has many methods, one of which is `shap_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c076bf72-7041-46b8-bd5c-fd50fc5e3399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 45830/45849 [21:36<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Shap values with tree explainer\n",
    "shap_values = xgb_explainer.shap_values(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c8e3b1a-f344-4588-b51f-dd69b12f08e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45849, 9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa134c8b-3dd9-4aa8-ac9b-6b5e59d90ccb",
   "metadata": {},
   "source": [
    "As I have said, calculating Shapley values is a complex process, which is why it took ~22 mins for just 45k observations on CPU. For modern large datasets with hundreds of features and millions of samples, the calculation can take days. So, we turn to GPUs to calculate the SHAP values. \n",
    "\n",
    "As of now, GPU support is not stable in SHAP but we have a workaround. The `predict` method of the core XGBoost model has `pred_contribs` argument, which when set to True, calculates SHAP values on GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "441e2866-3569-4f20-8b76-8bacdb0c68af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Shap values with XGBoost core moedl\n",
    "booster_xgb = model.get_booster()\n",
    "shap_values_xgb = booster_xgb.predict(xgb.DMatrix(X_train, y_train), pred_contribs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9100a-8a84-4e07-886c-7946c9014e31",
   "metadata": {},
   "source": [
    "After extracting the core booster model of XGBoost, it only took about a second to calculate Shapley values for 45k samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ecb2d91f-fe11-4eb6-8ccb-9396cd5d8432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45849, 10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values_xgb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2ac75-26a9-472d-97e7-696a0328ab94",
   "metadata": {},
   "source": [
    "But wait - the Shap values from the tree explainer had 9 columns, this one has 10! Don't worry, we can safely ignore the last column for now, as it just contains the bias term which XGBoost adds by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6aeb6dd5-a074-4675-9fff-29ce781895a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-421.47510</td>\n",
       "      <td>-12.88472</td>\n",
       "      <td>-159.49399</td>\n",
       "      <td>-558.31531</td>\n",
       "      <td>55.80539</td>\n",
       "      <td>14.40838</td>\n",
       "      <td>248.02771</td>\n",
       "      <td>-1009.00201</td>\n",
       "      <td>30.72342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2049.56787</td>\n",
       "      <td>52.70433</td>\n",
       "      <td>-8.38827</td>\n",
       "      <td>843.81110</td>\n",
       "      <td>-4.97748</td>\n",
       "      <td>16.81901</td>\n",
       "      <td>-105.95525</td>\n",
       "      <td>-1551.31506</td>\n",
       "      <td>-254.29324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1785.33105</td>\n",
       "      <td>-3.75646</td>\n",
       "      <td>171.85605</td>\n",
       "      <td>-216.71945</td>\n",
       "      <td>-42.69937</td>\n",
       "      <td>-22.18572</td>\n",
       "      <td>-85.50812</td>\n",
       "      <td>-1073.96741</td>\n",
       "      <td>-226.29549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1453.86597</td>\n",
       "      <td>54.70154</td>\n",
       "      <td>-592.66589</td>\n",
       "      <td>-157.38893</td>\n",
       "      <td>-14.12593</td>\n",
       "      <td>-3.75636</td>\n",
       "      <td>151.64543</td>\n",
       "      <td>-1124.40649</td>\n",
       "      <td>-179.72470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1849.81641</td>\n",
       "      <td>45.16076</td>\n",
       "      <td>-491.12134</td>\n",
       "      <td>518.77423</td>\n",
       "      <td>-18.75873</td>\n",
       "      <td>-1.10862</td>\n",
       "      <td>-2.68244</td>\n",
       "      <td>-1293.74329</td>\n",
       "      <td>-236.80804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        carat       cut      color    clarity     depth     table          x  \\\n",
       "0  -421.47510 -12.88472 -159.49399 -558.31531  55.80539  14.40838  248.02771   \n",
       "1 -2049.56787  52.70433   -8.38827  843.81110  -4.97748  16.81901 -105.95525   \n",
       "2 -1785.33105  -3.75646  171.85605 -216.71945 -42.69937 -22.18572  -85.50812   \n",
       "3 -1453.86597  54.70154 -592.66589 -157.38893 -14.12593  -3.75636  151.64543   \n",
       "4 -1849.81641  45.16076 -491.12134  518.77423 -18.75873  -1.10862   -2.68244   \n",
       "\n",
       "            y          z  \n",
       "0 -1009.00201   30.72342  \n",
       "1 -1551.31506 -254.29324  \n",
       "2 -1073.96741 -226.29549  \n",
       "3 -1124.40649 -179.72470  \n",
       "4 -1293.74329 -236.80804  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values_xgb = shap_values_xgb[:, :-1]\n",
    "\n",
    "pd.DataFrame(shap_values_xgb, columns=X_train.columns.tolist()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503a38b-e2ab-4775-a69c-7173e9295725",
   "metadata": {},
   "source": [
    "We got the Shapley values, now what? Now, we get plottin'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc96fb-058d-4f95-b72c-b688cec30ac3",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d27b669-a28f-410b-bda9-46bf69f345b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# SHAP interactions with XGB\n",
    "interactions_xgb = booster_xgb.predict(\n",
    "    xgb.DMatrix(X_train, y_train), pred_interactions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "647865f3-bbe3-4320-a2d7-0287d0416d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45849, 10, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_xgb.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
