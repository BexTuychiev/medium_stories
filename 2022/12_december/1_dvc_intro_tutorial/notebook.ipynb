{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ed35f9-a045-483f-991e-e8f5a6b26ba6",
   "metadata": {},
   "source": [
    "# How to Version Gigabyte-Sized Datasets Just Like Code With DVC in Python\n",
    "# A Complete Tutorial to Data Version Control With DVC in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d89740-675c-45bb-bf41-d6a8d1530de2",
   "metadata": {},
   "source": [
    "![](images/pexels.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8595dcc-022c-4379-ad69-981eb59c1c71",
   "metadata": {},
   "source": [
    "### The big problem in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7e524-ca4b-44e7-a813-492a47711f10",
   "metadata": {},
   "source": [
    "When a dataset is large, it creates an even larger mess. Why? Data scientists and ML engineers perform many experiments that involve massive datasets and models. They create huge headaches in terms of collaboration and software engineering best practices. \n",
    "\n",
    "In a traditional setting, software engineers collaborate by making copies to the central codebase and suggesting changes to it via pull requests. Then, their changes are reviewed, tested and merged into the main codebase if approved. This process can happen multiple times in a single day.\n",
    "\n",
    "Tools like Git have matured for almost two decades, making the above process a breeze for programmers. But, Git is only designed for lightweight code scripts, not hundreds of thousands of images we use to train costly CNNs. \n",
    "\n",
    "Yes, there are alternatives like GitLFS but it is too much a hassle to set up; it doesn't allow safe branching, commit and experimentation on large files, which are must-have features. \n",
    "\n",
    "For this reason, there are now many open-source (or paid) tools to solve these headaches. One of them is DVC (Data Version Control)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce7cb6-a119-4c3b-af80-1a84dca4bdf0",
   "metadata": {},
   "source": [
    "### What is data version control and DVC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47ba23-b401-4264-a6fd-b045f98f652d",
   "metadata": {},
   "source": [
    "Data version control is a process of tracking and versioning changes made to data and models in data projects. A good data version control system must have the following features:\n",
    "\n",
    "1. Track changes made to data and models like Git handles scripts.\n",
    "2. Ease of set up and use. Ideally, you should be able to install it with a single command.\n",
    "3. Compatible with existing systems like Git, so that it shouldn't reinvent the wheel.\n",
    "4. Support for branching and committing. The system should support the ability to create branches and commits, allowing for safe experimentation and easy collaboration.\n",
    "5. Reproducibility: The system should enable easy reproduction of experiments, allowing other users to quickly and easily reproduce results.\n",
    "6. Sharing capabilities: The system should support the ability to easily share data and models with other users, allowing for collaboration and sharing of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9042d3-76ec-4232-9525-e6635aebc79a",
   "metadata": {},
   "source": [
    "One tool that has all of the above features is DVC. It integrates seamlessly with Git and imitates its features but for large files.\n",
    "\n",
    "While Git stores a codebase on hosting services like GitHub or GitLab, DVC uses remote storages to upload data and models. A remote storage can be any cloud provider like AWS, GCP, Azure or even a plain-old directory on your local machine. A remote will be a single source of truth for the whole project, used by all team members. \n",
    "\n",
    "When a file is tracked by DVC and added to the remote storage, a lightweight file with the `.dvc` extension is created. The file will serve as a placeholder to the original large file and will contain instructions of how DVC can download it from the remote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f17a8-74ce-4aa5-951b-3024d766d0b0",
   "metadata": {},
   "source": [
    "### What will you learn in the tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1cf0a-4224-46a9-b93a-d57c9d89ef7e",
   "metadata": {},
   "source": [
    "By completing this tutorial, you will have a GitHub repository for an image classification project. Other people will be able to get all your code, data, models and experiments with only two commands:\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/username/repo.git\n",
    "$ cd repo\n",
    "$ dvc pull # Get all the data and models\n",
    "```\n",
    "\n",
    "The article will teach you everything needed, so you can run the `dvc pull` command and understand almost everything that goes under the hood. Let's jump right in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d07138-2983-4c65-b95d-dce1db86ce32",
   "metadata": {},
   "source": [
    "### Setting up the project and environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bab42-dbac-436d-aabf-89a5b9e1f845",
   "metadata": {},
   "source": [
    "Let's get started by creating the `conda` environment will be working in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a4f6f-4382-45a9-a4c5-624a5af63661",
   "metadata": {},
   "source": [
    "```\n",
    "conda create -n traffic_signs_recognition python=3.9 -y\n",
    "\n",
    "conda activate traffic_signs_recognition\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b1771-ace3-40bb-a837-0d39fe78e2df",
   "metadata": {},
   "source": [
    "Next, we clone the following repo and change into the working directory. Alternatively, you can create the working directory yourself and initialize `git` with `git init`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689abd1f-49da-44c1-8e4f-ff6888b15fec",
   "metadata": {},
   "source": [
    "```\n",
    "git clone https://github.com/BexTuychiev/traffic_signs_recognition.git\n",
    "cd traffic_signs_recognition\n",
    "```\n",
    "\n",
    "TODO - create a base repo on GitHub to clone with DVC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51897b3a-3b41-4ccb-bc37-fc32a887033f",
   "metadata": {},
   "source": [
    "Let's first create the `requirements.txt` file with a few dependencies and install them. Run the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c7a9f-e3b7-46a5-bdd2-c3cccb6df943",
   "metadata": {},
   "source": [
    "```\n",
    "$ echo -e \"tensorflow\\nscikit-learn\\nnumpy\\npandas\\nmatplotlib\\nseaborn\\nscikit-image\\ndvc\" >> requirements.txt\n",
    "$ cat requirements.txt\n",
    "tensorflow\n",
    "scikit-learn\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "seaborn\n",
    "scikit-image\n",
    "dvc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a003c-91e9-4f80-bb32-1b4b2e9265ef",
   "metadata": {},
   "source": [
    "> Running the `echo` command with `-e` tag makes it detect special characters like line breaks (`\\n`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f633cc-1c19-436c-a6ff-c900f76a6cc6",
   "metadata": {},
   "source": [
    "We installed a few standard data libraries along with `scikit-image` for image manipulation and `tensorflow` for building the models. The last one is `dvc`, which is the main focus of the article.\n",
    "\n",
    "Now, let's build the tree structure of our project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c76f3-7e32-47b4-bd13-0131968ef618",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir data notebooks src data/raw data/prepared data/prepared/train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfa55a-65e8-4eee-a18a-8ae70dc11119",
   "metadata": {},
   "source": [
    "We will store the scripts inside `src`, while `data` and `notebooks` will hold the images and analysis notebooks we might create later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc039b2-b066-4b46-a079-efd31b3eec56",
   "metadata": {},
   "source": [
    "### Download and set up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f495d6-84b0-41c5-8291-92d38ed90127",
   "metadata": {},
   "source": [
    "Now, we will download the dataset for the project. The GTSRB - German Traffic Sign Recognition Benchmark dataset contains more than 50k images divided into 40 road sign categories. Our task is to build a convolutional neural network that can accurately classify each category.\n",
    "\n",
    "You can go to the [dataset page](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) or download it directly using [this link](https://storage.googleapis.com/kaggle-data-sets/82373/191501/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221210%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221210T130850Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=65eeae3c577195c0b9185b9e37ab185a3e5cc8c990a501390621201196cfd2e5ecbb0952db6bc443a09d08e252744472705c7bc90caa2c82aaa699b7d24f5592075046a771f05e424bb0d7fc6e8f8bff4e04e25a5e4e2b2e816a966e25df023050344400b97e676d9d0ac0c93c9046a007d74db740d311822fd79ea6bbdfa4d6459de2b2b061ca5187d2bf83c284feef39b06296cf4f46c7bc6f95c6488d7ea78a4eaf28ea43e7f8ef0afd97805d0943782b99377fd35a9e8781f17419d2fff43d66822d56c11802f209822dd86ba4e64edd7800d3125a7cff88b5616fbd3ddc0f2f3dfea2f86325cd185fc88cb5e46d517a846d407d4b6637df713cd8a36c36) and the below commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a144a-0d94-4b2d-8c4c-ee7a7c5b5f41",
   "metadata": {},
   "source": [
    "```\n",
    "$ curl \"the_link_inside_quotes\" -o data/traffic_signs.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e31762-14d7-4f4c-b740-3797cfc30abb",
   "metadata": {},
   "source": [
    "Once the download is done, unzip the images into the `data/raw` directory. Then, we can remove the unnecessary files and directories like duplicates of the images and metadata. This will leave us only with the `train` and `test` folders inside `data/raw`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c850f5-251a-482a-a0ac-7e58809e6419",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ unzip data/traffic_signs.zip -d data/raw\n",
    "$ cd data/raw\n",
    "$ rm -rf Train Test Meta meta Meta.csv Test.csv Train.csv\n",
    "$ rm test/GT-final_test.csv\n",
    "$ cd ../..\n",
    "$ rm data/traffic_signs.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c858362-b18f-4311-993f-86d5d9da035b",
   "metadata": {},
   "source": [
    "In the end, we will remove the downloaded zipped dataset as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67741f6-ef56-4fe0-bdf5-174c9697f24e",
   "metadata": {},
   "source": [
    "The `train` folder has 43 folders, one for each class. Keep this directory structure in mind, as we will use it when training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cbd42c-0d52-4be0-a720-ced0a828c772",
   "metadata": {},
   "source": [
    "### Initializing DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcc6c5-8d82-4753-8956-d126c4e2b25e",
   "metadata": {},
   "source": [
    "Having a dataset is already enough to start working with `dvc`. In this section, you will see the basics of how Git and DVC work together. \n",
    "\n",
    "To add DVC tracking to our project, we just need to call `dvc init` just like `git init`. DVC only works on top of Git repositories. The `init` command will add a special `.dvc` directory that holds DVC configuration. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc839e3-6635-4c1e-ac6d-55131764cf4c",
   "metadata": {},
   "source": [
    "```\n",
    "$ git status -s\n",
    "A  .dvc/.gitignore\n",
    "A  .dvc/config\n",
    "A  .dvcignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a912941-24da-4796-a507-090c60f5d9e0",
   "metadata": {},
   "source": [
    "The command will also create `.dvcignore` file that can be used to list directories that should be ignored by DVC. For now, we will leave it empty. \n",
    "\n",
    "Once DVC is initialized, it needs a place called a remote storage to upload data and large files so that they aren't tracked by Git. DVC remote can be any cloud storage provider like AWS, Azure, GCP or just any other directory on your machine.\n",
    "\n",
    "For simplicity, we will set the remote storage for this project to a new directory called `dvc_remote` in the home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cfe17-d7e6-4d56-a9ee-53caae5708cb",
   "metadata": {},
   "source": [
    "```\n",
    "$ mkdir ~/dvc_remote\n",
    "$ dvc remote add -d remote ~/dvc_remote\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a25e0-5439-4741-b79e-d012d5e478c7",
   "metadata": {},
   "source": [
    "The `remote` command is used to work with remote storages. Here, we are naming our remote storage simply `remote`. The `-d` tags tells DVC that `dvc_remote` is your default remote storage path.\n",
    "\n",
    "Once you run these commands, you can look at the `config` file inside `.dvc` folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b212113-d8d0-4897-a532-3f782ea957de",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ cat .dvc/config\n",
    "[core]\n",
    "    remote = remote\n",
    "['remote \"remote\"']\n",
    "    url = /home/bexgboost/dvc_remote/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3ebbe-9512-473f-a7f9-dbd091e6cfb0",
   "metadata": {},
   "source": [
    "As you can see, the remote name is listed as `remote` and the `url` is set to a path in my own home directory. If our remote was cloud-based, it would be a web URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e966051-fa45-4b4a-a304-d652d7a213fc",
   "metadata": {},
   "source": [
    "#### Adding files to track with DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb281a24-2fa9-4413-a55e-f6d99aec6be5",
   "metadata": {},
   "source": [
    "- Add files with the `add` command\n",
    "- When `add` is called, .dvc extension files are created\n",
    "- They should be tracked with .git\n",
    "- `add` adds the dirs to .gitignore\n",
    "- Write a script to preprocess image, resize or scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e0aac-e7e4-46ce-88fa-42f35ab53614",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git add --all\n",
    "$ git commit -m \"Initialize DVC\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32ae43-710a-4a8c-aa93-ec1f0f612900",
   "metadata": {},
   "source": [
    "To start tracking files and directories, you can use the `dvc add` just like `git add`. Below, we are adding the entire `data` folder to DVC because it contains thousands of images, which would certainly cause a crash if we tried to track them with `git`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7ecbc-7912-4ffd-9101-35f0e441771b",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ dvc add data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f0e9d-73fa-402f-ba69-3a47a9c43a59",
   "metadata": {},
   "source": [
    "When the `add` command is run, here is what happens under the hood:\n",
    "\n",
    "1. The `data` directory is put under DVC'c control.\n",
    "2. `data` directory is added to the `.gitignore` file so it will never be tracked by `git`.\n",
    "3. A lightweight `data.dvc` file is created which serves as a placeholder to the original `data` directory. \n",
    "\n",
    "These lightweight `.dvc` (dot-dvc) files are always tracked with Git. When a user clones our Git repository, `.dvc` files will contain instructions of where the original large files are stored.\n",
    "\n",
    "> Remember that adding files or folders on a new inside a `.gitignore` file will make them invisible to `git` commands.\n",
    "\n",
    "Now, since the large `data` directory is added to `.gitignore`, we can safely stage all the other files with `git` and commit them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78393a24-a775-4021-9b1e-36061566e669",
   "metadata": {},
   "source": [
    "```\n",
    "$ git add --all\n",
    "$ git commit -m \"Initialize DVC and add the raw images to DVC\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53079cde-f706-4ce1-80b4-4f8dfea25e97",
   "metadata": {},
   "source": [
    "So, here is the summary of how to use Git and DVC in tandem:\n",
    "\n",
    "1. Whenever you make changes to code or other lightweight files, track the changes with `git add filename` or `git add --all`.\n",
    "2. Whenever there is a change to large files tracked with `dvc`, track it by running `dvc add file/or/dir`, which updates the corresponding `.dvc` file. So, you add the change in the `.dvc` file to `git`.\n",
    "\n",
    "For example, running `python src/preprocess.py` will resize and rescale all the images inside `raw/train` and saves them to `data/prepared/train`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d150f6-88fd-406b-921a-f5325919aa05",
   "metadata": {},
   "source": [
    "```python\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "train_dir = DATA_DIR / \"raw\" / \"train\"\n",
    "\n",
    "\n",
    "def resize_image(image_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize image to target size.\n",
    "    \"\"\"\n",
    "    # Resize the image to the target_size\n",
    "    image = imread(image_path) / 255.0\n",
    "    image = resize(image, target_size, anti_aliasing=True)\n",
    "\n",
    "    # Create a new path to the image in the prepared directory\n",
    "    target_path = str(image_path).replace(\"raw\", \"prepared\")\n",
    "    Path(target_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save the image to a new path\n",
    "    imsave(target_path, image)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_paths = []\n",
    "    \n",
    "    # Collect all image paths from `data/raw/train`\n",
    "    for directory in train_dir.iterdir():\n",
    "        image_paths.extend(list(directory.glob(\"*.png\")))\n",
    "\n",
    "    Parallel(n_jobs=10, backend=\"multiprocessing\")(\n",
    "        delayed(resize_image)(path, (150, 150)) for path in tqdm(image_paths)\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a3c70-b483-4323-a2eb-c252f4b7a047",
   "metadata": {},
   "source": [
    "The `resize` function takes an image path and reads it using the `imread` function as a NumPy array. It is resized to the `target_size` and saved into a new path inside `prepared` directory. \n",
    "\n",
    "In the `__main__` context, we are collecting all image paths and using parallel execution to resize and save multiple images simultaneously.\n",
    "\n",
    "Once the script finishes, you can see if there were changes to any DVC-tracked files with `dvc status`. You should see an output similar to below:\n",
    "\n",
    "```bash\n",
    "$ dvc status\n",
    "data.dvc:\n",
    "    changed outs:\n",
    "          modified:        data/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73191e-5f92-437a-bc19-f049789b4451",
   "metadata": {},
   "source": [
    "So, we track the new changes with `dvc add` and stage the changes made to `data.dvc` with `git add --all` and commit the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2611d-b2e2-499f-8625-e3ccfe4c82d2",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ dvc add data\n",
    "$ git add --all\n",
    "$ git commit -m \"Save resized images\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa6828-1ee3-4cdf-a260-4a4115b33f0c",
   "metadata": {},
   "source": [
    "#### Uploading files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562180c-1e2d-4920-8f9b-b4a37bfabe5e",
   "metadata": {},
   "source": [
    "Now, let's push all the commits made with `git` and DVC changes. First, we run `git push` followed by `dvc` push.\n",
    "\n",
    "`git push` will upload the code and `.dvc` files to GitHub, while `dvc push` sends the original and resized images to the `remote`, which is the `~/dvc_remote` directory on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fd678-f845-47d2-a89b-d56c7533b7e7",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git push\n",
    "$ dvc push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac3cca-131f-47d2-84ab-108a2bacc9f2",
   "metadata": {},
   "source": [
    "Once the large files are stored in the remote, you can delete them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780391c-b341-4ae4-b870-3a17bef1ecf1",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ rm -rf data/raw/train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacf494-98cf-4050-800e-297fd5d22848",
   "metadata": {},
   "source": [
    "If you want to redownload those files, you can simply call `dvc pull`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e176a-a18f-4b85-b475-5e32edc6b7c5",
   "metadata": {},
   "source": [
    "```\n",
    "$ dvc pull\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d15d9-15ae-4f41-8ea6-e053e6bda5c3",
   "metadata": {},
   "source": [
    "`dvc pull` will detect any differences with the working directory and the remote stores and downloads them. \n",
    "\n",
    "When a new user clones your Git repository, they will also use the `dvc pull` command to populate the working directory with the files stored in your remote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d01b1-1448-4ce3-a166-e252b58cc32a",
   "metadata": {},
   "source": [
    "### Building an image classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696e5e8-04ef-4954-a913-377ff334a2a6",
   "metadata": {},
   "source": [
    "Now, it is time to build a baseline model and track it with DVC. In `src/train.py`, we have the following script that trains a baseline CNN using the `ImageDataGenerator` class. Since the focus of the article isn't on TensorFlow, you can learn [how `ImageDataGenerator` works](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) from the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef6c10-a472-4d0e-8269-23105dc20681",
   "metadata": {},
   "source": [
    "```bash\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from joblib import dump\n",
    "\n",
    "# Set the paths to the train and validation directories\n",
    "base_dir = Path(__file__).parent.parent\n",
    "data_dir = base_dir / \"data\"\n",
    "\n",
    "# Create an ImageDataGenerator object for the train set\n",
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(...)\n",
    "\n",
    "# Generate training data from the train directory\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    data_dir / \"raw\" / \"train\",  # Target directory\n",
    "    target_size=(50, 50),  # Resize images to 150x150\n",
    "    ...\n",
    ")\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model to be fit\"\"\"\n",
    "    # Define a CNN model\n",
    "    model = tf.keras.models.Sequential(...)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(...)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Get the model\n",
    "    model = get_model()\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        train_generator,  # Use the train generator\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,  # Train for 10 epochs\n",
    "    )\n",
    "\n",
    "    metrics_dir = base_dir / \"metrics\"\n",
    "    models_dir = base_dir / \"models\"\n",
    "    metrics_dir.mkdir(exist_ok=True)\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    dump(history.history, metrics_dir / \"history.joblib\")\n",
    "    dump(model, models_dir / \"model.joblib\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013073d-abd8-4334-963e-7c4b7a9b0bb4",
   "metadata": {},
   "source": [
    "> You can find the full script from the website repository [here](https://github.com/BexTuychiev/traffic_signs_recognition/blob/main/src/train.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d8bf4-ba37-4bec-8100-ebe6d3d4a4ef",
   "metadata": {},
   "source": [
    "The important part of the script is the `main` function. Inside, we are fitting and saving the model and its metrics newly-created `models` and `metrics` directories using `joblib.dump`. \n",
    "\n",
    "We run the script:\n",
    "\n",
    "```\n",
    "$ python src/train.py\n",
    "```\n",
    "\n",
    "Once finished, we add the `models` directory to DVC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea3ac8-3730-47b7-a804-8171957501c3",
   "metadata": {},
   "source": [
    "```\n",
    "$ dvc add models\n",
    "$ git add --all\n",
    "$ git commit -m \"Baseline model with 0.2192 accuracy\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1fedd5-7290-4968-9d88-495027296598",
   "metadata": {},
   "source": [
    "Then, we run `git add --all` once again to stage `models.dvc` file and the `history.joblib` file. It is also a good practice to tag each experiment with `git`:\n",
    "\n",
    "```bash\n",
    "$ git tag -a baseline -m \"Baseline model with 0.2192 accuracy\"\n",
    "```\n",
    "\n",
    "Finally, we push the commits, DVC changes and tags with:\n",
    "\n",
    "```\n",
    "$ dvc push\n",
    "$ git push\n",
    "$ git push origin --tags\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c51ba3-ca92-40ab-bcfb-8c1c712f27d6",
   "metadata": {},
   "source": [
    "Now, if we want to improve the accuracy score by trying different CNN architectures, we modify the `train.py` script, run it and track the new `model.joblib` and `history.joblib` files. We also create a commit and tag that summarizes that summarizes the model performance. In the end, push the changes and tags with both Git and DVC. \n",
    "\n",
    "Even though this machine learning experimentation workflow is simple and effective, in the next part of the article we will see a much better way of tracking our experiments. Using DVC pipelines and VSCode DVC extension, we will be able to visualize our metrics and model runs right inside an IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f799990-f5d2-4008-86e4-791959fb0939",
   "metadata": {},
   "source": [
    "### DVC internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522bd78a-34f9-4433-b8b1-ca2c24b917d2",
   "metadata": {},
   "source": [
    "Now that you know how to track and upload files to DVC remote, it is time to take a deeper look at DVC internals. \n",
    "\n",
    "We've discussed DVC remote, which is similar to GitHub, where you store the latest official version of your data and models uploaded with `dvc push`.\n",
    "\n",
    "But, just like Git first adds files to a staging area before committing them to GitHub, DVC has a staging area called cache. \n",
    "\n",
    "When `dvc init` is called, `cache` directory is added to `.dvc` folder. Every time you call `dvc add` or `dvc commit`, the files will be copied to the cache.\n",
    "\n",
    "And now, you are asking - doesn't that duplicate the files and waste space? Yes! But just like you can configure the location of the remote storage, you can configure the cache.\n",
    "\n",
    "In large-scale projects, many professionals use share a single powerful machine instead of laptops or PCs. Therefore, it doesn't make sense for every team member to have a cache under in their own working directory. A solution is to point the cache to a shared location. \n",
    "\n",
    "If you've been following along, our projects cache is under `.dvc/cache`. But, we can point to another directory with the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d2bfb-1164-4bdc-8ee7-e78c2233cb80",
   "metadata": {},
   "source": [
    "```\n",
    "$ dvc cache dir path/to/shared_cache\n",
    "$ mv .dvc/cache/* path/to/shared_cache\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a9c30-267c-4129-ba5f-fb0bed3f7d0b",
   "metadata": {},
   "source": [
    "Just make sure that all team members have read/write permissions to the `path/to/shared_cache` when sharing a single development machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b313f0d-1721-4444-9063-b346bd89ef19",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889e7fd-0177-4449-95a7-acbe67eccfed",
   "metadata": {},
   "source": [
    "Here is a summary of working with DVC:\n",
    "\n",
    "- DVC project is initialized on top of a Git repo with `dvc init`\n",
    "- You should set up a remote for the project with `dvc remote add -d remote_name path/to/remote`\n",
    "- To start tracking files, use `dvc add`\n",
    "- `dvc add` copies the specified directory or files to `.dvc/cache` or `shared_cache/you/specified`, creates `.dvc` files for each tracked folder or file and adds them to `.gitignore`\n",
    "- `.dvc` and other files are tracked with `git add --all`\n",
    "- To push commits and DVC-tracked file changes, use both `git push` and `dvc push`\n",
    "- `dvc push` uploads the files from the cache to the remote storage\n",
    "- Label each ML experiment run with a tag and repeat `dvc add or commit`/`dvc push` and `git add`/`git push` for each changed file.\n",
    "\n",
    "This step-by-step tutorial is already enough to solve most of your problems in data science projects in terms of collaboration and reproducibility. In the next part of the article, we will talk more about simplifying machine learning experimentation with DVC (yes, it can be made even easier)!\n",
    "\n",
    "Thank you for reading!\n",
    "\n",
    "https://ibexorigin.medium.com/membership\n",
    "\n",
    "https://ibexorigin.medium.com/subscribe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
