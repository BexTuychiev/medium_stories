{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52ed35f9-a045-483f-991e-e8f5a6b26ba6",
   "metadata": {},
   "source": [
    "# How to Version Gigabyte-Sized Datasets Just Like Code With DVC in Python\n",
    "# A Complete Tutorial to Data Version Control With DVC in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d89740-675c-45bb-bf41-d6a8d1530de2",
   "metadata": {},
   "source": [
    "![](images/pexels.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8595dcc-022c-4379-ad69-981eb59c1c71",
   "metadata": {},
   "source": [
    "### The big problem in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7e524-ca4b-44e7-a813-492a47711f10",
   "metadata": {},
   "source": [
    "When a dataset is large, it creates an even larger mess. Why? Data scientists and ML engineers perform many experiments on massive datasets and models. They create huge headaches in terms of collaboration and software engineering best practices. \n",
    "\n",
    "Traditionally, software engineers collaborate by making copies to the central codebase and suggesting changes to it via pull requests. Then, their changes are reviewed, tested and merged into the main codebase if approved. This process can happen multiple times in a single day.\n",
    "\n",
    "Tools like Git have matured for almost two decades, making the above process a breeze for programmers. But, Git is only designed for lightweight code scripts, not hundreds of thousands of images we use to train costly CNNs. \n",
    "\n",
    "Yes, there are alternatives like GitLFS but it is too much a hassle to set up; it doesn't allow safe branching, committing and experimentation on large files, which are must-have features. \n",
    "\n",
    "For this reason, there are now many tools to solve these problems. One of them is DVC (Data Version Control)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce7cb6-a119-4c3b-af80-1a84dca4bdf0",
   "metadata": {},
   "source": [
    "### What is data version control and DVC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47ba23-b401-4264-a6fd-b045f98f652d",
   "metadata": {},
   "source": [
    "Data version control is tracking and versioning dataset and model changes. A good data version control system must have the following features:\n",
    "\n",
    "1. Track data/model changes like Git handles scripts.\n",
    "2. Ease of set up and use: ideally, you should be able to install it with a single command.\n",
    "3. Compatible with existing systems like Git, so that it shouldn't reinvent the wheel.\n",
    "4. Support for branching and committing: there must be support to create branches, commits, and experimenting in isolation.\n",
    "5. Reproducibility: allowing other team members reproduce ML experiments quickly and easily.\n",
    "6. Sharing capabilities: seamlessly share data and models with other users for collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9042d3-76ec-4232-9525-e6635aebc79a",
   "metadata": {},
   "source": [
    "One tool with all of the above features is DVC, which imitates Git's features for large files.\n",
    "\n",
    "While Git stores a codebase on hosting services like GitHub or GitLab, DVC uses remote storages to upload data and models. A remote storage can be any cloud provider like AWS, GCP, Azure or even a plain-old directory on your local machine. A remote will be a single source of truth for the whole project, used by all team members, just like a GitHub repository.\n",
    "\n",
    "When DVC tracks a file, it adds it to the remote storage. Then, a lightweight `.dvc` file (dot-dvc) is created, which will serve as a placeholder to the original large file. It will contain instructions of how DVC can download the file from the remote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f17a8-74ce-4aa5-951b-3024d766d0b0",
   "metadata": {},
   "source": [
    "### What will you learn in the tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1cf0a-4224-46a9-b93a-d57c9d89ef7e",
   "metadata": {},
   "source": [
    "By completing this tutorial, you will have a GitHub repository for an image classification project. Other people will be able to get all your code, data, models and experiments with only two commands:\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/username/repo.git\n",
    "$ cd repo\n",
    "$ dvc pull # Get all the data and models\n",
    "```\n",
    "\n",
    "The article will teach you everything needed to run the `dvc pull` command and understand almost everything that goes under the hood. Let's jump right in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d07138-2983-4c65-b95d-dce1db86ce32",
   "metadata": {},
   "source": [
    "### Setting up the project and environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20bab42-dbac-436d-aabf-89a5b9e1f845",
   "metadata": {},
   "source": [
    "Let's get started by creating a `conda` environment: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a4f6f-4382-45a9-a4c5-624a5af63661",
   "metadata": {},
   "source": [
    "```\n",
    "conda create -n traffic_signs_recognition python=3.9 -y\n",
    "\n",
    "conda activate traffic_signs_recognition\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b1771-ace3-40bb-a837-0d39fe78e2df",
   "metadata": {},
   "source": [
    "Next, go to your GitHub account and fork [this repository](https://github.com/BexTuychiev/dvc-tutorial.git). This will create the same version of the repo under your account. Then, clone it on the terminal and change into the working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689abd1f-49da-44c1-8e4f-ff6888b15fec",
   "metadata": {},
   "source": [
    "```\n",
    "git clone https://github.com/YourUsername/dvc-tutorial.git\n",
    "cd dvc-tutorial\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51897b3a-3b41-4ccb-bc37-fc32a887033f",
   "metadata": {},
   "source": [
    "Now, let's create the `requirements.txt` file with a few dependencies and install them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81f98b8-7934-4d08-80e8-57f7fab92ada",
   "metadata": {},
   "source": [
    "> If you don't have installed TensorFlow with GPU support, I have got a guide for you [right here](https://towardsdatascience.com/how-to-finally-install-tensorflow-gpu-on-windows-10-63527910f255)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c7a9f-e3b7-46a5-bdd2-c3cccb6df943",
   "metadata": {},
   "source": [
    "```\n",
    "$ echo -e \"tensorflow\\nscikit-learn\\nnumpy\\npandas\\nmatplotlib\\nseaborn\\nscikit-image\\ndvc\" >> requirements.txt\n",
    "$ cat requirements.txt\n",
    "tensorflow\n",
    "scikit-learn\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "seaborn\n",
    "scikit-image\n",
    "dvc\n",
    "\n",
    "$ pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a003c-91e9-4f80-bb32-1b4b2e9265ef",
   "metadata": {},
   "source": [
    "> Running the `echo` command with `-e` tag makes it detect special characters like line breaks (`\\n`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f633cc-1c19-436c-a6ff-c900f76a6cc6",
   "metadata": {},
   "source": [
    "We installed a few standard data libraries along with `scikit-image` for image manipulation and `tensorflow` for building the models. The last one is `dvc`, which is the main focus of the article.\n",
    "\n",
    "Now, let's build the tree structure of our project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c76f3-7e32-47b4-bd13-0131968ef618",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ mkdir data notebooks src data/raw data/prepared data/prepared/train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecfa55a-65e8-4eee-a18a-8ae70dc11119",
   "metadata": {},
   "source": [
    "We will store the scripts inside `src`, while `data` and `notebooks` will hold the images and analysis notebooks we might create later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc039b2-b066-4b46-a079-efd31b3eec56",
   "metadata": {},
   "source": [
    "### Download and set up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f495d6-84b0-41c5-8291-92d38ed90127",
   "metadata": {},
   "source": [
    "Now, we will download the dataset for the project. The GTSRB - German Traffic Sign Recognition Benchmark dataset contains more than 50k images divided into 40 road sign categories. Our task is to build a convolutional neural network that can accurately classify each category.\n",
    "\n",
    "You can go to the [dataset page](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign) or download it directly using [this link](https://storage.googleapis.com/kaggle-data-sets/82373/191501/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221210%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221210T130850Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=65eeae3c577195c0b9185b9e37ab185a3e5cc8c990a501390621201196cfd2e5ecbb0952db6bc443a09d08e252744472705c7bc90caa2c82aaa699b7d24f5592075046a771f05e424bb0d7fc6e8f8bff4e04e25a5e4e2b2e816a966e25df023050344400b97e676d9d0ac0c93c9046a007d74db740d311822fd79ea6bbdfa4d6459de2b2b061ca5187d2bf83c284feef39b06296cf4f46c7bc6f95c6488d7ea78a4eaf28ea43e7f8ef0afd97805d0943782b99377fd35a9e8781f17419d2fff43d66822d56c11802f209822dd86ba4e64edd7800d3125a7cff88b5616fbd3ddc0f2f3dfea2f86325cd185fc88cb5e46d517a846d407d4b6637df713cd8a36c36) and the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72a144a-0d94-4b2d-8c4c-ee7a7c5b5f41",
   "metadata": {},
   "source": [
    "```\n",
    "$ curl \"the_link_inside_quotes\" -o data/traffic_signs.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e31762-14d7-4f4c-b740-3797cfc30abb",
   "metadata": {},
   "source": [
    "Once the download is done, unzip the images into the `data/raw` directory. Then, we can remove the unnecessary files and directories like duplicates of the images and metadata. This will leave us only with the `train` and `test` folders inside `data/raw`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c850f5-251a-482a-a0ac-7e58809e6419",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ unzip data/traffic_signs.zip -d data/raw\n",
    "$ cd data/raw\n",
    "$ rm -rf Train Test Meta meta Meta.csv Test.csv Train.csv\n",
    "$ rm test/GT-final_test.csv\n",
    "$ cd ../..\n",
    "$ rm data/traffic_signs.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c858362-b18f-4311-993f-86d5d9da035b",
   "metadata": {},
   "source": [
    "In the end, we have removed the original zip file as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67741f6-ef56-4fe0-bdf5-174c9697f24e",
   "metadata": {},
   "source": [
    "The `train` folder has 43 folders, one for each class. Keep this directory structure in mind, as we will use it when training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cbd42c-0d52-4be0-a720-ced0a828c772",
   "metadata": {},
   "source": [
    "### Initializing DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcc6c5-8d82-4753-8956-d126c4e2b25e",
   "metadata": {},
   "source": [
    "In this section, you will see the basics of how Git and DVC work together. \n",
    "\n",
    "To add DVC tracking to your project, we just need to call `dvc init`. DVC only works on top of Git repositories, so if you use it for other projects, make sure you've run the `git init` command. We've forked the repo from GitHub, so it already came with Git initialized. \n",
    "\n",
    "The `dvc init` command will add a special `.dvc` directory that holds DVC configuration. We will take a closer look at DVC internals in a later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc839e3-6635-4c1e-ac6d-55131764cf4c",
   "metadata": {},
   "source": [
    "```\n",
    "$ git status -s\n",
    "A  .dvc/.gitignore\n",
    "A  .dvc/config\n",
    "A  .dvcignore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a912941-24da-4796-a507-090c60f5d9e0",
   "metadata": {},
   "source": [
    "The command creates `.dvcignore` file that can be used to list directories that should be ignored by DVC. The Git repository already has `.gitignore` file already-prefilled. \n",
    "\n",
    "Once DVC is initialized, it needs a place called a remote storage to upload data and large files so that they aren't tracked by Git. DVC remote can be any cloud storage provider like AWS, Azure, GCP or just any other directory on your machine.\n",
    "\n",
    "For simplicity, we will set the remote storage for this project to a new directory called `dvc_remote` in the home directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cfe17-d7e6-4d56-a9ee-53caae5708cb",
   "metadata": {},
   "source": [
    "```\n",
    "$ mkdir ~/dvc_remote\n",
    "$ dvc remote add -d remote ~/dvc_remote\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a25e0-5439-4741-b79e-d012d5e478c7",
   "metadata": {},
   "source": [
    "The `remote` command is used to control remote storages. Here, we are naming our remote storage simply `remote`. The `-d` tags tells DVC that `dvc_remote` is your default remote storage path.\n",
    "\n",
    "Once you run these commands, you can look at the `config` file inside `.dvc` folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b212113-d8d0-4897-a532-3f782ea957de",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ cat .dvc/config\n",
    "[core]\n",
    "    remote = remote\n",
    "['remote \"remote\"']\n",
    "    url = /home/bexgboost/dvc_remote/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3ebbe-9512-473f-a7f9-dbd091e6cfb0",
   "metadata": {},
   "source": [
    "As you can see, the remote name is listed as `remote` and the `url` is set to a path in my home directory. If our remote was cloud-based, it would be a web URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e966051-fa45-4b4a-a304-d652d7a213fc",
   "metadata": {},
   "source": [
    "#### Adding files to track with DVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32ae43-710a-4a8c-aa93-ec1f0f612900",
   "metadata": {},
   "source": [
    "To start tracking changes on files and directories with DVC, you can use the `dvc add` command. Below, we are adding the entire `data` folder to DVC because it contains thousands of images, which would certainly cause a crash if added to `git`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7ecbc-7912-4ffd-9101-35f0e441771b",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ dvc add data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f0e9d-73fa-402f-ba69-3a47a9c43a59",
   "metadata": {},
   "source": [
    "When the `add` command is run, here is what happens under the hood:\n",
    "\n",
    "1. The `data` directory is put under DVC'c control.\n",
    "2. `data` directory is added to the `.gitignore` file so it will never be tracked by `git`.\n",
    "3. A lightweight `data.dvc` file is created which serves as a placeholder to the original `data` directory. \n",
    "\n",
    "These lightweight `.dvc` (dot-dvc) files are always tracked with Git. When a user clones our Git repository, `.dvc` files will contain instructions of where the original large files are stored.\n",
    "\n",
    "> Remember that adding files or folders on a new line inside a `.gitignore` file will make them invisible to `git` commands.\n",
    "\n",
    "Now, since the `data` directory is added to `.gitignore`, we can safely stage all the other files with `git` and commit them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78393a24-a775-4021-9b1e-36061566e669",
   "metadata": {},
   "source": [
    "```\n",
    "$ git add --all\n",
    "$ git commit -m \"Initialize DVC and add the raw images to DVC\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53079cde-f706-4ce1-80b4-4f8dfea25e97",
   "metadata": {},
   "source": [
    "So, here is the summary of how to use Git and DVC in combination:\n",
    "\n",
    "1. Whenever you make changes to code or other lightweight files, track the changes with `git add filename` or `git add --all`.\n",
    "2. Whenever there is a change to large files tracked with `dvc`, track it by running `dvc add file/or/dir`, which updates the corresponding `.dvc` file. So, you add the change in the `.dvc` file to `git` with `git add filename.dvc`.\n",
    "\n",
    "For example, running `python src/preprocess.py` will resize and rescale all the images inside `raw/train` and saves them to `data/prepared/train`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d150f6-88fd-406b-921a-f5325919aa05",
   "metadata": {},
   "source": [
    "```python\n",
    "from joblib import Parallel, delayed\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "train_dir = DATA_DIR / \"raw\" / \"train\"\n",
    "\n",
    "\n",
    "def resize_image(image_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize image to target size.\n",
    "    \"\"\"\n",
    "    ...\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_paths = []\n",
    "    \n",
    "    # Collect all image paths from `data/raw/train`\n",
    "    for directory in train_dir.iterdir():\n",
    "        image_paths.extend(list(directory.glob(\"*.png\")))\n",
    "\n",
    "    Parallel(n_jobs=10, backend=\"multiprocessing\")(\n",
    "        delayed(resize_image)(path, (150, 150)) for path in tqdm(image_paths)\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e0287-3422-4ed0-9fdc-96608113c8a3",
   "metadata": {},
   "source": [
    "> You can copy/paste the full version of the above script from [here](https://github.com/BexTuychiev/traffic_signs_recognition/blob/main/src/preprocess.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a3c70-b483-4323-a2eb-c252f4b7a047",
   "metadata": {},
   "source": [
    "The `resize` function takes an image path and reads it using the `imread` function as a NumPy array. It is resized to the `target_size` and saved into a new path inside `prepared` directory. \n",
    "\n",
    "In the `__main__` context, we are collecting all image paths and using parallel execution to resize and save multiple images simultaneously.\n",
    "\n",
    "Once the script finishes, you can see if there were changes to any DVC-tracked files with `dvc status`. You should see an output similar to below:\n",
    "\n",
    "```bash\n",
    "$ dvc status\n",
    "data.dvc:\n",
    "    changed outs:\n",
    "          modified:        data/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73191e-5f92-437a-bc19-f049789b4451",
   "metadata": {},
   "source": [
    "So, we track the new changes with `dvc add` and stage the changes made to `data.dvc` with `git add --all` and commit the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2611d-b2e2-499f-8625-e3ccfe4c82d2",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ dvc add data\n",
    "$ git add --all\n",
    "$ git commit -m \"Save resized images\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa6828-1ee3-4cdf-a260-4a4115b33f0c",
   "metadata": {},
   "source": [
    "#### Uploading files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562180c-1e2d-4920-8f9b-b4a37bfabe5e",
   "metadata": {},
   "source": [
    "Now, let's push all the commits made with `git` and DVC-tracked changes. We run `git push` followed by `dvc` push.\n",
    "\n",
    "`git push` will upload the code and `.dvc` files to GitHub, while `dvc push` sends the original and resized images to the `remote`, which is the `~/dvc_remote` directory on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682fd678-f845-47d2-a89b-d56c7533b7e7",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git push\n",
    "$ dvc push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aac3cca-131f-47d2-84ab-108a2bacc9f2",
   "metadata": {},
   "source": [
    "Once the large files are stored in the remote, you can delete them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d780391c-b341-4ae4-b870-3a17bef1ecf1",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ rm -rf data/raw/train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacf494-98cf-4050-800e-297fd5d22848",
   "metadata": {},
   "source": [
    "If you want to redownload those files, you can simply call `dvc pull`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e176a-a18f-4b85-b475-5e32edc6b7c5",
   "metadata": {},
   "source": [
    "```\n",
    "$ dvc pull\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d15d9-15ae-4f41-8ea6-e053e6bda5c3",
   "metadata": {},
   "source": [
    "`dvc pull` will detect any differences with the working directory and the remote storage and downloads them. \n",
    "\n",
    "When a new user clones your Git repository, they will also use the `dvc pull` command to populate the working directory with the files stored in your remote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d01b1-1448-4ce3-a166-e252b58cc32a",
   "metadata": {},
   "source": [
    "### Building an image classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696e5e8-04ef-4954-a913-377ff334a2a6",
   "metadata": {},
   "source": [
    "Now, it is time to build a baseline model and track it with DVC. In `src/train.py`, we have the following script that trains a baseline CNN using the `ImageDataGenerator` class. Since the focus of the article isn't on TensorFlow, you can learn [how `ImageDataGenerator` works](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) from the docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ef6c10-a472-4d0e-8269-23105dc20681",
   "metadata": {},
   "source": [
    "```bash\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from joblib import dump\n",
    "\n",
    "# Set the paths to the train and validation directories\n",
    "base_dir = Path(__file__).parent.parent\n",
    "data_dir = base_dir / \"data\"\n",
    "\n",
    "# Create an ImageDataGenerator object for the train set\n",
    "data_gen = tf.keras.preprocessing.image.ImageDataGenerator(...)\n",
    "\n",
    "# Generate training data from the train directory\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    data_dir / \"raw\" / \"train\",  # Target directory\n",
    "    target_size=(50, 50),  # Resize images to 150x150\n",
    "    ...\n",
    ")\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model to be fit\"\"\"\n",
    "    # Define a CNN model\n",
    "    model = tf.keras.models.Sequential(...)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(...)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Get the model\n",
    "    model = get_model()\n",
    "\n",
    "    # Fit the model\n",
    "    history = model.fit(\n",
    "        train_generator,  # Use the train generator\n",
    "        steps_per_epoch=100,\n",
    "        epochs=10,  # Train for 10 epochs\n",
    "    )\n",
    "\n",
    "    metrics_dir = base_dir / \"metrics\"\n",
    "    models_dir = base_dir / \"models\"\n",
    "    metrics_dir.mkdir(exist_ok=True)\n",
    "    models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    dump(history.history, metrics_dir / \"history.joblib\")\n",
    "    dump(model, models_dir / \"model.joblib\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013073d-abd8-4334-963e-7c4b7a9b0bb4",
   "metadata": {},
   "source": [
    "> You can find the full script from the repository [here](https://github.com/BexTuychiev/traffic_signs_recognition/blob/main/src/train.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d8bf4-ba37-4bec-8100-ebe6d3d4a4ef",
   "metadata": {},
   "source": [
    "The important part of the script is the `main` function. Inside, we are fitting and saving the model and its metrics inside the newly-created `models` and `metrics` directories using `joblib.dump`. \n",
    "\n",
    "We run the script:\n",
    "\n",
    "```\n",
    "$ python src/train.py\n",
    "```\n",
    "\n",
    "Once finished, we add the `models` directory to DVC:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea3ac8-3730-47b7-a804-8171957501c3",
   "metadata": {},
   "source": [
    "```\n",
    "$ dvc add models\n",
    "$ git add --all\n",
    "$ git commit -m \"Baseline model with 0.2192 accuracy\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1fedd5-7290-4968-9d88-495027296598",
   "metadata": {},
   "source": [
    "Then, we run `git add --all` once again to stage `models.dvc` file and the `metrics.dvc` files. It is also a good practice to tag each experiment with `git`:\n",
    "\n",
    "```bash\n",
    "$ git tag -a baseline -m \"Baseline model with 0.2192 accuracy\"\n",
    "```\n",
    "\n",
    "Finally, we push the commits, DVC changes and tags with:\n",
    "\n",
    "```\n",
    "$ dvc push\n",
    "$ git push\n",
    "$ git push origin --tags\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c51ba3-ca92-40ab-bcfb-8c1c712f27d6",
   "metadata": {},
   "source": [
    "Now, if we want to improve the accuracy score by trying different CNN architectures, we modify the `train.py` script, run it and track the new `model.joblib` and `history.joblib` files. We also create a commit and a tag that summarize the model performance. In the end, we push the changes and tags with both Git and DVC. \n",
    "\n",
    "Even though this experimentation workflow is simple and effective, in the next part of the article we will see a much better way of tracking our experiments. Using DVC pipelines and VSCode DVC extension, we will be able to visualize our metrics and model runs right inside an IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f799990-f5d2-4008-86e4-791959fb0939",
   "metadata": {},
   "source": [
    "### DVC internals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522bd78a-34f9-4433-b8b1-ca2c24b917d2",
   "metadata": {},
   "source": [
    "Now that you know how to track and upload files to DVC remote, it is time to take a deeper look at DVC internals. \n",
    "\n",
    "We've discussed DVC remote, which is similar to GitHub, where you store the latest official version of your data and models uploaded with `dvc push`.\n",
    "\n",
    "But, just like Git first adds files to a staging area before committing them to GitHub, DVC has a staging area called cache. \n",
    "\n",
    "When `dvc init` is called, `cache` directory is added to `.dvc` folder. Every time you call `dvc add`, the files will be copied to the cache.\n",
    "\n",
    "And now, you are asking - doesn't that duplicate the files and waste space? Yes! But just like you can configure the location of the remote storage, you can configure the cache.\n",
    "\n",
    "In large-scale projects, many professionals share a single powerful machine instead of laptops or PCs. Therefore, it doesn't make sense for every team member to have a cache in their own working directory. A solution is to point the cache to a shared location. \n",
    "\n",
    "If you've been following along, our projects cache is under `.dvc/cache`. But, we can point to another directory with the following commands:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d2bfb-1164-4bdc-8ee7-e78c2233cb80",
   "metadata": {},
   "source": [
    "```\n",
    "$ dvc cache dir path/to/shared_cache\n",
    "$ mv .dvc/cache/* path/to/shared_cache\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb619a-df5a-4d1e-a671-60058f97a797",
   "metadata": {},
   "source": [
    "The `mv` command moves the files inside the old cache into a new cache location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a9c30-267c-4129-ba5f-fb0bed3f7d0b",
   "metadata": {},
   "source": [
    "Just make sure that all team members have read/write permissions to the `path/to/shared_cache` when sharing a single development machine.\n",
    "\n",
    ">  If you are working by yourself, there is no need to follow this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b313f0d-1721-4444-9063-b346bd89ef19",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1889e7fd-0177-4449-95a7-acbe67eccfed",
   "metadata": {},
   "source": [
    "Here is a summary of working with DVC:\n",
    "\n",
    "- DVC project is initialized on top of a Git repo with `dvc init`\n",
    "- You should set up a remote for the project with `dvc remote add -d remote_name path/to/remote`\n",
    "- To start tracking files, use `dvc add`\n",
    "- `dvc add` copies the specified directory or files to `.dvc/cache` or `shared_cache/you/specified`, creates `.dvc` files for each tracked folder or file and adds them to `.gitignore`\n",
    "- `.dvc` and other files are tracked with `git add --all`\n",
    "- To push commits and DVC-tracked file changes, use both `git push` and `dvc push`\n",
    "- `dvc push` uploads the files from the cache to the remote storage\n",
    "- Label each ML experiment run with a tag and repeat `dvc add`/`dvc push` and `git add`/`git push` for each changed file.\n",
    "\n",
    "This step-by-step tutorial is already enough to solve most of your problems in data science projects in terms of collaboration and reproducibility. In the next part of the article, we will talk more about simplifying machine learning experimentation with DVC (yes, it can be made even easier)!\n",
    "\n",
    "Thank you for reading!\n",
    "\n",
    "https://ibexorigin.medium.com/membership\n",
    "\n",
    "https://ibexorigin.medium.com/subscribe\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
