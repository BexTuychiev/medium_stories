{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9430e6e-83e5-4dad-94fc-ea0c671ffc93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How to Upload And Download Files From AWS S3 Using Python (2022)\n",
    "## Learn how to use cloud resources in your Python scripts\n",
    "![](images/pexels.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01300205-c01e-4961-8d48-0ea0ae411c4b",
   "metadata": {},
   "source": [
    "I am writing this post out of sheer frustration. \n",
    "\n",
    "Every post I've read on this topic assumed that I had already had an account in AWS, an S3 bucket and a mound of data already stored. They just show the code but kindly shadow over the most important part - how to make the code work through your AWS account. \n",
    "\n",
    "Well, I could've figured out the code easily, thank you very much. I had sift through many SO threads and the AWS docs to get rid of every nasty authentication error along the way.\n",
    "\n",
    "So that you won't feel the same and do the hard work, I will share all the technicalities of managing and S3 bucket programmatically, right from account creation to adding permissions to your local machine to access your AWS resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc13671-ce6f-4faa-8b0b-e0ec929007fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Setup an account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c003f-8198-475e-a088-88cabbf747d1",
   "metadata": {},
   "source": [
    "Right, let's start with creating your AWS account, if you haven't already. Nothing unusual, just follow the steps from this [link](https://aws.amazon.com/free/?trk=ps_a131L0000085EJvQAM&trkCampaign=acq_paid_search_brand&sc_channel=ps&sc_campaign=acquisition_US&sc_publisher=google&sc_category=core-main&sc_country=US&sc_geo=NAMER&sc_outcome=acq&sc_detail=aws&sc_content=Brand_Core_aws_e&sc_segment=432339156150&sc_medium=ACQ-P|PS-GO|Brand|Desktop|SU|Core-Main|Core|US|EN|Text&s_kwcid=AL!4422!3!432339156150!e!!g!!aws&ef_id=EAIaIQobChMIxa2ogpvA9QIVxP7jBx2iAwgNEAAYASAAEgJGR_D_BwE:G:s&s_kwcid=AL!4422!3!432339156150!e!!g!!aws&all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsf.Free%20Tier%20Categories=*all):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b029e-3872-4939-b09a-6df9f5a124b7",
   "metadata": {},
   "source": [
    "![](images/sign_up.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0760c79-c97c-442d-a1fb-ef389c13c79a",
   "metadata": {},
   "source": [
    "Then, we will go to the [AWS IAM (Identity and Access Management) console](https://console.aws.amazon.com/), which is the place we will be doing most of the work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bed68d-819d-40f9-a24c-9fd65fa02677",
   "metadata": {},
   "source": [
    "![](images/aws_console.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821e50e-d8f6-4a9a-839c-0068830a3fdb",
   "metadata": {},
   "source": [
    "From the console, you can easily switch between different AWS servers, create users, add policies and allow access to your user account. We will do each one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51513a2e-d8eb-472e-9ad2-038c217e8bb5",
   "metadata": {},
   "source": [
    "### Step 2: Create a user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578edac-3e91-4085-8e92-fe74a5a3fd85",
   "metadata": {},
   "source": [
    "For one AWS account, you can create multiple users and each user can have various levels of access to your account's resources. Let's create a sample user for this tutorial:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261fd615-82a9-450c-b7f0-0ce964fd5b2c",
   "metadata": {},
   "source": [
    "![](images/create_user.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf553937-6980-4504-8b9a-197e226c4fc2",
   "metadata": {},
   "source": [
    "In the IAM console:\n",
    "\n",
    "1. Go to the users tab.\n",
    "2. Click on Add users.\n",
    "3. Enter a username in the field.\n",
    "4. Tick the \"Access key - Programmatic access field\" (essential).\n",
    "5. Click \"Next\" and \"Attach existing policies directly\".\n",
    "6. Tick the \"AdministratorAccess\" policy.\n",
    "7. Click \"Next\" until you see the \"Create user\" button\n",
    "8. Finally, download the given CSV file of your user's credentials.\n",
    "\n",
    "It should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99ed3e-928d-4193-b1f9-1e240e18ec79",
   "metadata": {},
   "source": [
    "![](images/credentials.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345afbd-a1ba-49de-ba16-7e71f831dc1c",
   "metadata": {},
   "source": [
    "Store it somewhere safe, because we will be using the credentials later. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c10fa-bd90-4c57-b263-b4a92be5e470",
   "metadata": {},
   "source": [
    "### Step 3: Create a bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018e81c7-7d43-4251-9f5b-da678c8f6770",
   "metadata": {},
   "source": [
    "Now, let's create an S3 bucket where we can store data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f733b29-d033-4da0-a6e0-15480822da41",
   "metadata": {},
   "source": [
    "![](images/create_bucket.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9f8b9-1b91-4201-9f9f-23477eec6076",
   "metadata": {},
   "source": [
    "In the [IAM console](https://console.aws.amazon.com/):\n",
    "\n",
    "1. Click services in the top left corner.\n",
    "2. Scroll down to storage and select S3 from the right-hand list.\n",
    "3. Click \"Create bucket\" and give it a name. \n",
    "\n",
    "You can choose any region you want. Leave the rest of the settings as is and click \"Create bucket\" once more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b675cf-cb43-480c-9a2f-273be37e1e5f",
   "metadata": {},
   "source": [
    "### Step 4: Create a policy and add it to your user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6e9290-9e91-4f71-99a9-c7bcb53d18c2",
   "metadata": {},
   "source": [
    "In AWS, access is management through policies. A policy can be a set of settings or a JSON file attached to an AWS object (user, resource, group, roles) and it controls what aspects of the object you can use. \n",
    "\n",
    "Below, we will create a policy that enables us to interact with our bucket programmatically - i.e., through the CLI or in a script. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0787e59-9d4f-427f-bed8-44933cd28d8d",
   "metadata": {},
   "source": [
    "![](images/create_policy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65798103-9bfb-49eb-8625-a6b6babc091b",
   "metadata": {},
   "source": [
    "In the [IAM console](https://console.aws.amazon.com/):\n",
    "\n",
    "1. Go to the Policies tab and click \"Create a policy\".\n",
    "2. Click the \"JSON\" tab and insert the code below:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"ConsoleAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::your-bucket-name\",\n",
    "                \"arn:aws:s3:::your-bucket-name/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "replacing *your-bucket-name* with your own. If you pay attention, in the Action field of the JSON, we are putting `s3:*` to allow any type of interaction to our bucket. This is very broad, so you may allow only certain actions. In that case, check out [this page](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_examples_s3_rw-bucket-console.html) of the AWS docs to learn to limit access.\n",
    "\n",
    "Now, this policy is only attached to the bucket. We should attach it to the user as well so that your API credentials work properly. Here are the instructions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b5277-7e25-4d39-999a-11a550c3d5db",
   "metadata": {},
   "source": [
    "![](images/add_permission.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd57a57-d9ee-4af8-b48c-9dda20063396",
   "metadata": {},
   "source": [
    "In the [IAM console](https://console.aws.amazon.com/):\n",
    "\n",
    "1. Go the Users tab and click on the user we created in the last section.\n",
    "2. Click the \"Add permissions\" button.\n",
    "3. Click \"Attach existing policies\" tab.\n",
    "4. Filter them by the policy we just created.\n",
    "5. Tick the policy, review it and click \"Add\" the final time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7329c6-f4d4-424d-b70c-f9ecb7989a02",
   "metadata": {},
   "source": [
    "### Step 5: Download AWS CLI and configure your user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0160d1-58ef-4694-a619-c4f8e88ead32",
   "metadata": {},
   "source": [
    "Now, we download the AWS command-line tool, because it makes authentication so much easier. Kindly go to [this page](https://aws.amazon.com/cli/) and download the executable for your platform:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f6744-045e-4902-a4a2-c5c14d96b732",
   "metadata": {},
   "source": [
    "![](images/download_cli.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e85e671-b7ec-420a-a414-9a50b4060a24",
   "metadata": {},
   "source": [
    "Run the executable and reopen any active terminal sessions to let the changes take effect. Then, type `aws configure`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db55db4-8469-4db7-b79e-d024dd08dc4f",
   "metadata": {},
   "source": [
    "![](images/configure_aws.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbeec1-d1d5-4a1f-af78-2c2dd10e1a7d",
   "metadata": {},
   "source": [
    "Insert your AWS Key ID and Secret Access Key, along with the region your created your bucket in (use the CSV file). You can find the region name of your bucket in the S3 page of the console:\n",
    "\n",
    "![](images/region.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3128ae-5be4-4e1c-9f72-24513ec98b63",
   "metadata": {},
   "source": [
    "Just click \"Enter\" when you reach the Default Output Format field in the configuration. There won't be any output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd1c8e-6ff4-4af2-b123-06606dfa4f19",
   "metadata": {},
   "source": [
    "### Step 6: Upload your files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859bf3a6-ea52-436b-9bd2-18b5c1e099ee",
   "metadata": {},
   "source": [
    "We are nearly there.\n",
    "\n",
    "Now, we upload a sample dataset to our bucket so that we can download it in a script later:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3713f30-55fe-425a-86b3-af82471b5818",
   "metadata": {},
   "source": [
    "![](images/upload_file.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee564d40-f5de-44b6-9e1a-cd67b0396d21",
   "metadata": {},
   "source": [
    "It should be easy once you go to the S3 page and open your bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2efd56-97c6-48a0-a15e-11ec226bcbe2",
   "metadata": {},
   "source": [
    "### Step 7: Check if authentication is working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672c65e-b30d-4283-9069-12f5df9229d5",
   "metadata": {},
   "source": [
    "Finally, pip install the [Boto3 package](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) and run this snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1be15303-539e-48ef-8988-6d70af2d004d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample-bucket-1801\n"
     ]
    }
   ],
   "source": [
    "import boto3  # pip install boto3\n",
    "\n",
    "# Let's use Amazon S3\n",
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "# Print out bucket names\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b408c347-f162-4815-ad28-8afb6d9f614b",
   "metadata": {},
   "source": [
    "If the output contains your bucket name(s), congratulations - you now have full access to many AWS services through `boto3`, not just S3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e38c28-c763-4703-9d3d-9c76d9bd14b1",
   "metadata": {},
   "source": [
    "### Using Python Boto3 to download files from S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e91b7-c8ba-438b-8c03-2a50409acfae",
   "metadata": {},
   "source": [
    "With the Boto3 package, you have programmatic access to many AWS services such as SQS, EC2, SES and many aspects of the IAM console. \n",
    "\n",
    "However, as a regular data scientists, you will mostly need to upload and download data from an S3 bucket, so we will only cover only those operations. \n",
    "\n",
    "Let's start with the download. After importing the package, create an S3 class using the `client` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "603bc2f6-6722-40eb-8374-05503a50bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an S3 access object\n",
    "s3 = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8cb8f-a5b1-433b-ad33-b77316715a88",
   "metadata": {},
   "source": [
    "To download a file from an S3 bucket and immediately save it to a file, we can use the `download_file` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c019549-34a0-40a8-90b4-275441ec2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\n",
    "    Bucket=\"sample-bucket-1801\", Key=\"train.csv\", Filename=\"data/downloaded_from_s3.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a45b67-645c-45e6-b3ee-aad9d2308de3",
   "metadata": {},
   "source": [
    "There won't be any output if the download is successful. You should pass the exact file path of the file to be downloaded to the `Key` parameter. The `Filename` should contain the pass you want to save the file to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0425a-4f19-471c-8414-0edc316a1baf",
   "metadata": {},
   "source": [
    "Uploading is also very straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24249777-1318-41f1-9800-34c0ce873d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(\n",
    "    Filename=\"data/downloaded_from_s3.csv\",\n",
    "    Bucket=\"sample-bucket-1801\",\n",
    "    Key=\"new_file.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb666ad4-3e26-4d59-8509-fbb11cb53364",
   "metadata": {},
   "source": [
    "The function is `upload_file` and you only have to change the order of the parameters from the download function. \n",
    "\n",
    "![](images/new_file.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc70f9b-9f8f-4bec-a3c4-158b01ffb959",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610da06a-1cb1-49dd-b85c-db6e98ace396",
   "metadata": {},
   "source": [
    "I suggest reading the [Boto3 docs] for more advanced examples of managing your AWS resources. It covers services other than S3 and contains code recipes for the most common tasks with each one. \n",
    "\n",
    "Thanks for reading!\n",
    "\n",
    "**You can become a premium Medium member using the link below and get access to all of my stories and thousands of others:**\n",
    "\n",
    "https://ibexorigin.medium.com/membership\n",
    "\n",
    "**Or just subscribe to my email list:**\n",
    "\n",
    "https://ibexorigin.medium.com/subscribe\n",
    "\n",
    "#### You can reach out to me on [LinkedIn](https://www.linkedin.com/in/bextuychiev/) or [Twitter](https://twitter.com/BexTuychiev) for a friendly chat about all things data. Or you can just read another story from me. How about these:\n",
    "\n",
    "https://towardsdatascience.com/8-booming-data-science-libraries-you-must-watch-out-in-2022-cec2dbb42437\n",
    "\n",
    "https://towardsdatascience.com/how-to-get-started-on-kaggle-in-2022-even-if-you-are-terrified-8e073853ac46\n",
    "\n",
    "https://towardsdatascience.com/7-cool-python-packages-kagglers-are-using-without-telling-you-e83298781cf4\n",
    "\n",
    "https://towardsdatascience.com/22-2-built-in-python-libraries-you-didnt-know-existed-p-guarantee-8-275685dbdb99\n",
    "\n",
    "https://towardsdatascience.com/good-bye-pandas-meet-terality-its-evil-twin-with-identical-syntax-455b42f33a6d\n",
    "\n",
    "https://towardsdatascience.com/6-pandas-mistakes-that-silently-tell-you-are-a-rookie-b566a252e60d\n",
    "\n",
    "https://towardsdatascience.com/8-booming-data-science-libraries-you-must-watch-out-in-2022-cec2dbb42437"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
