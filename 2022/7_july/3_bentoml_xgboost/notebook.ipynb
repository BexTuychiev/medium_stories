{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a17246-0add-4cec-9f07-000ed7f7c9bc",
   "metadata": {},
   "source": [
    "# Deploying Machine Learning Models as API Services With BentoML And AWS Lambda\n",
    "## Get that model online!\n",
    "![](images/pexels.jpg)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/photo/blue-and-red-galaxy-artwork-1629236/'>Suzy Hazelwood</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce1397-b247-4884-b37a-1e0232bfbcae",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d6393-49ee-41c6-8e3b-786deaf3e411",
   "metadata": {},
   "source": [
    "According to ml-ops.org, the current state of MLOps stack looks like the following template:\n",
    "\n",
    "![](https://ml-ops.org/img/mlops-full-stack.png)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://valohai.com/blog/the-mlops-stack/'>Henrik Skogström</a>\n",
    "        on \n",
    "        <a href='https://ml-ops.org/content/state-of-mlops'>ml-ops.org</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9c266-64f0-48fa-94dd-45dfba3d6e61",
   "metadata": {},
   "source": [
    "The industry is fast-changing, leading to multiple candidates for performing each of the operations in the template.\n",
    "\n",
    "BentoML is a new open-source library that handles the model serving part of the MLOps life cycle. It offers a Python API that allow users to serve their models as APIs in a simple script and get an HTTP server they can send POST requests to generate predictions on unseen data. \n",
    "\n",
    "This lightweight API then can be inserted into any machine learning use case, be it a Docker container or a web app.\n",
    "\n",
    "In this post, we will go deep into how you can use BentoML and its Bentos API and how you can combine it with AWS Lambda to get your models up and running for anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08528785-2d22-47e8-96a4-58c1f37899cc",
   "metadata": {},
   "source": [
    "## What is BentoML and its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2aca6c-3b40-4abb-848a-84e2154183f9",
   "metadata": {},
   "source": [
    "To maximize the business impact of machine learning, the hand-off between data scientists and engineers from model training to deployment should be fast and iterative. However, data scientists often don't have the skills to properly package trained models and push them to the engineers while engineers struggle with working models that come from dozens of different ML frameworks.\n",
    "\n",
    "BentoML was created to solve these issues and make the hand-off to production deployment as easy and fast as possible. In the coming sections, you will see how BentoML makes it stupidly easy to perform tedious operations. The examples are:\n",
    "- Saving any model of any framework into a unified format\n",
    "- Create an HTTP API endpoint with a single Python function\n",
    "- Containerize everything the model needs using Docker with a single CLI command\n",
    "\n",
    "So, without further ado, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6712872-007f-4152-8df7-25a6e5d7a15b",
   "metadata": {},
   "source": [
    "## Dataset preparation and model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9fd6f-c134-4c5e-b527-eec6ec9f32f8",
   "metadata": {},
   "source": [
    "The crux of the article is about model deployment, so I want to concentrate all your attention on that area only. For that purpose, I will assume you are reading this article with your best trained model already in hand and want to deploy it as soon as possible. \n",
    "\n",
    "To simulate that here, we will simply create a synthetic dataset, train an XGBoost model and move forward as though you have done all the previous steps of the MLOps life cycle like data cleaning, exploration, feature engineering, model experimentation, hyperparameter tuning and found the model that performs best on your problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1e2f33-1ca3-4ff1-a680-40539a70bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d54791c-f2c8-48b8-bf83-911bfcc1f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate the data\n",
    "n_samples, n_features = 10000, 7\n",
    "X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=5)\n",
    "\n",
    "# Save it as a CSV\n",
    "feature_names = [f\"feature_{i}\" for i in range(n_features)]\n",
    "\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "df.to_csv(\"data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc6b34-9085-4455-9b6b-45cd59136706",
   "metadata": {},
   "source": [
    "We create a simple dataset with 7 features and 10k samples with a binary classification target. Now, we load it back into environment and train a vanilla XGBoost classifier and pretend that it is our best tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8453d788-028a-488f-9c7c-50d2b449d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_validate, train_test_split\n",
    "\n",
    "# Load and prep the data\n",
    "data = pd.read_csv(\"data/data.csv\")\n",
    "X, y = data.drop(\"target\", axis=1), data[[\"target\"]]\n",
    "\n",
    "# Initialize a classifier\n",
    "clf = xgb.XGBClassifier(tree_method=\"gpu_hist\")\n",
    "\n",
    "# Cross-validate\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_validate(\n",
    "    clf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"roc_auc\",\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc2e29-c996-4333-85a9-44aeb849934a",
   "metadata": {},
   "source": [
    "After loading the data, we use 10-fold cross-validation and use ROC AUC score as a metric. For the sake of completeness, let's quickly log the train/validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0203b5c9-d63e-45aa-a8ad-c3f72318be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training ROC AUC: 0.999 ± 0.000\n",
      "Average test ROC AUC: 0.971 ± 0.003\n"
     ]
    }
   ],
   "source": [
    "avg_train = scores[\"train_score\"].mean()\n",
    "avg_test = scores[\"test_score\"].mean()\n",
    "\n",
    "std_train = scores[\"train_score\"].std()\n",
    "std_test = scores[\"test_score\"].std()\n",
    "\n",
    "print(f\"Average training ROC AUC: {avg_train:.3f} ± {std_train:.3f}\")\n",
    "print(f\"Average test ROC AUC: {avg_test:.3f} ± {std_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd923473-45af-4a77-8890-475d98e73ae7",
   "metadata": {},
   "source": [
    "Great! Now, we can move on to deployment!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c8dca-36e2-427d-854d-e6932ec5f7f9",
   "metadata": {},
   "source": [
    "## Saving trained models to BentoML format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6014e44-bd18-4bf0-a00f-30676035e858",
   "metadata": {},
   "source": [
    "1. In this section, readers will learn about an already trained XGBoost model on a sample dataset. They will be given a brief overview of the model hyperparameters and the dataset used to train it\n",
    "\n",
    "2. Then, main BentoML concepts like saving models to Bento store, and how to retrieve them will be explained. The trained XGB model will also be saved in the local store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28489f8-8a99-461a-92d9-02408c18cceb",
   "metadata": {},
   "source": [
    "## Creating an API service script\n",
    "This section explains how to load a saved XGB model into a prediction script and how to create a service function with the ‘@service.api’ decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6e73f-ca45-400c-b8a2-4465981496e0",
   "metadata": {},
   "source": [
    "## Building a Bento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968000f-d98d-4191-9ca4-ca0b1bd5a4fe",
   "metadata": {},
   "source": [
    "This section will explain how to use the ‘bentoml build’ command and all the steps required before running it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814390d-c539-4a97-9fc1-354e55abe63c",
   "metadata": {},
   "source": [
    "## Deploying the Bento to AWS Lambda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
