{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a17246-0add-4cec-9f07-000ed7f7c9bc",
   "metadata": {},
   "source": [
    "# Deploying Any Machine Learning Model as API Services With AWS Lambda\n",
    "## Get that model online!\n",
    "![](images/pexels.jpg)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/photo/blue-and-red-galaxy-artwork-1629236/'>Suzy Hazelwood</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce1397-b247-4884-b37a-1e0232bfbcae",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78d6393-49ee-41c6-8e3b-786deaf3e411",
   "metadata": {},
   "source": [
    "According to ml-ops.org, the current state of MLOps stack looks like this:\n",
    "\n",
    "![](https://ml-ops.org/img/mlops-full-stack.png)\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://valohai.com/blog/the-mlops-stack/'>Henrik Skogström</a>\n",
    "        on \n",
    "        <a href='https://ml-ops.org/content/state-of-mlops'>ml-ops.org</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9c266-64f0-48fa-94dd-45dfba3d6e61",
   "metadata": {},
   "source": [
    "The industry is fast-changing, leading to multiple candidates for performing each of the operations in the template.\n",
    "\n",
    "BentoML is a new open-source library that handles the model serving part of the MLOps life cycle. It offers a Python API that allow users to serve their models as APIs in a simple script and get an HTTP server they can send POST requests to generate predictions on unseen data. \n",
    "\n",
    "This lightweight API then can be inserted into any machine learning use case, be it a Docker container or a web app.\n",
    "\n",
    "In this post, we will go deep into how you can use BentoML and its Bentos API and how you can combine it with AWS Lambda to get your models up and running for anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08528785-2d22-47e8-96a4-58c1f37899cc",
   "metadata": {},
   "source": [
    "## What is BentoML and its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2aca6c-3b40-4abb-848a-84e2154183f9",
   "metadata": {},
   "source": [
    "To maximize the business impact of machine learning, the hand-off between data scientists and engineers from model training to deployment should be fast and iterative. However, data scientists often don't have the skills to properly package trained models and push them to the engineers while engineers struggle with working models that come from dozens of different ML frameworks.\n",
    "\n",
    "BentoML was created to solve these issues and make the hand-off to production deployment as easy and fast as possible. In the coming sections, you will see how BentoML makes it stupidly easy to perform tedious MLOps operations. The examples are:\n",
    "- Saving any model of any framework into a unified format\n",
    "- Create an HTTP API endpoint with a single Python function\n",
    "- Containerize everything the model needs using Docker with a single CLI command\n",
    "\n",
    "So, without further ado, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6712872-007f-4152-8df7-25a6e5d7a15b",
   "metadata": {},
   "source": [
    "## Dataset preparation and model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d9fd6f-c134-4c5e-b527-eec6ec9f32f8",
   "metadata": {},
   "source": [
    "The crux of the article is about model deployment, so I want to concentrate all your attention on that area only. For that purpose, I will assume you are reading this article with your best trained model already in hand and want to deploy it as soon as possible. \n",
    "\n",
    "To simulate that here, we will simply create a synthetic dataset, train an XGBoost model and move forward as though you have done all the previous steps of the MLOps life cycle like data cleaning, exploration, feature engineering, model experimentation, hyperparameter tuning and found the model that performs best on your problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f1e2f33-1ca3-4ff1-a680-40539a70bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d54791c-f2c8-48b8-bf83-911bfcc1f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate the data\n",
    "n_samples, n_features = 10000, 7\n",
    "X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=5)\n",
    "\n",
    "# Save it as a CSV\n",
    "feature_names = [f\"feature_{i}\" for i in range(n_features)]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "df.to_csv(\"data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc6b34-9085-4455-9b6b-45cd59136706",
   "metadata": {},
   "source": [
    "We create a simple dataset with 7 features and 10k samples with a binary classification target. Now, we load it back into the environment and train a vanilla XGBoost classifier and pretend that it is our best tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8453d788-028a-488f-9c7c-50d2b449d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, cross_validate, train_test_split\n",
    "\n",
    "# Load and prep the data\n",
    "data = pd.read_csv(\"data/data.csv\")\n",
    "X, y = data.drop(\"target\", axis=1), data[[\"target\"]]\n",
    "\n",
    "# Create a DMatrıx\n",
    "dtrain = xgb.DMatrix(X.values, label=y.values)\n",
    "\n",
    "# Specify parameters for a binary classification problem\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "}\n",
    "\n",
    "# Train\n",
    "booster = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cc2e29-c996-4333-85a9-44aeb849934a",
   "metadata": {},
   "source": [
    "After loading the data, we use 10-fold cross-validation and use ROC AUC score as a metric. For the sake of completeness, let's quickly log the train/validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0e6fc-45ea-477f-9996-c5663a8e84b0",
   "metadata": {},
   "source": [
    "Great! Now, we are ready for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c8dca-36e2-427d-854d-e6932ec5f7f9",
   "metadata": {},
   "source": [
    "## Saving trained models to BentoML format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4e24a-d9b2-4602-81a2-0a4611dc2146",
   "metadata": {},
   "source": [
    "Saving a trained model into BentoML-compatible format is done calling the framework-specific `save` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da3a5d27-bc53-41f1-a634-90f903c8e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"xgb_initial:m7juljbhp2bvsj77\", path=\"/home/bexgboost/bentoml/models/xgb_initial/m7juljbhp2bvsj77/\")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml  # pip install bentoml\n",
    "\n",
    "bento_xgb = bentoml.xgboost.save_model(\"xgb_initial\", booster)\n",
    "bento_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22f34ac-3867-49fa-b607-6a7cdb21dd96",
   "metadata": {},
   "source": [
    "Even though we trained an XGBoost classifier, we still use the `sklearn.save_model` command because we initialized the model in Sklearn API. The returned object is an instance of BentoML `Model` class with a label called *tag*. \n",
    "\n",
    "The tag consists of two parts - a name given by the user and a version string to differentiate between models saved at different times. Even if an identical model is saved, a new directory and a version string will be created for it. \n",
    "\n",
    "BentoML supports almost all important ML frameworks:\n",
    "- Classic: Sklearn, XGBoost, CatBoost, LightGBM\n",
    "- Deep learning: TensorFlow, PyTorch, PyTorch Lightning, Keras, Transformers\n",
    "- Others: ONNX, MLFlow, fast.ai, statsmodels, spaCy, h2o, Gluon, etc.\n",
    "\n",
    "Each of the frameworks have a corresponding `framework.save_model` command.\n",
    "\n",
    "When a model is saved, it goes into a local directory called BentoML model store. From the last output, we saw that my model store resides in `/home/bexgboost/bentoml/models/home/bexgboost/bentoml/models`. You can see the list of all your models by calling the `bentoml models list` command in the terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00e045e2-3a1e-4b44-811f-159b323b7641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\n",
      " xgb_initial:m7juljbhp2bvsj77  bentoml.xgboost  41.79 KiB   2022-08-29 14:38:57 \n",
      " xgb_custom:hz3mt7bhpwbvsj77   bentoml.xgboost  42.29 KiB   2022-08-29 14:30:39 \n",
      " xgb_initial:5a35jarhpsbvsj77  bentoml.xgboost  42.02 KiB   2022-08-29 14:28:14 \n",
      " xgb_booster:mkxbjbrge27gwaav  bentoml.xgboost  67.08 KiB   2022-08-27 21:36:22 \n",
      " xgb_booster:m5vkj4bf66gfaaav  bentoml.xgboost  69.34 KiB   2022-08-27 16:00:04 \n",
      " xgb_booster:onhegxrf62rksaav  bentoml.xgboost  59.84 KiB   2022-08-27 15:53:14 \n",
      " xgb_custom:hgpjk2iqxk67yjcl   bentoml.sklearn  442.29 KiB  2022-07-31 15:19:13 \n"
     ]
    }
   ],
   "source": [
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71758e4a-75e8-47a1-8266-c611849a07cd",
   "metadata": {},
   "source": [
    "You can also see models from my other projects.\n",
    "\n",
    "> Note: in BentoML docs and this article, the names \"model\" and \"tag\" are used interchangeably to refer to saved models in the model store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3fd787-b9f7-4477-a413-bdf12825fd35",
   "metadata": {},
   "source": [
    "The `save_model` has other parameters that allow you to pass extra information about the model, from metadata to additional user-defined objects (e.g. weights of your model as a separate object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6351e190-14b9-410c-8861-ff8c9e6e8c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"xgb_custom:nk3qcarhp2bvsj77\", path=\"/home/bexgboost/bentoml/models/xgb_custom/nk3qcarhp2bvsj77/\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bentoml.xgboost.save_model(\n",
    "    \"xgb_custom\",\n",
    "    booster,\n",
    "    metadata={\"auc\": 0.99, \n",
    "              \"feature_importances\": booster.get_score(importance_type=\"gain\")},\n",
    "    labels={\"author\": \"Bex\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f068c16-1f9a-4f69-aab9-d7ff0a3fd6f2",
   "metadata": {},
   "source": [
    "## Sharing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e00d910-f5ad-4a55-bca0-271ff2e779b9",
   "metadata": {},
   "source": [
    "Models in the BentoML model store can be shared as standalone archives using the `bentoml models export` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1352483-1dd9-4339-9e3e-ae12d1e3480d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(tag=\"xgb_custom:nk3qcarhp2bvsj77\") exported to /home/bexgboost/articles/2022/8_august/3_bentoml_xgboost/models/xgb_custom-nk3qcarhp2bvsj77.bentomodel\n"
     ]
    }
   ],
   "source": [
    "!bentoml models export xgb_custom:latest ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b136e3-e606-4f58-b26c-d9e15e2c79f7",
   "metadata": {},
   "source": [
    "When you don't know the exact version string of your tag, you can use the \":latest\" suffix to choose the most recent. With the above command, we are exporting the classifier into a `.bentomodel` archive to the models directory. When a teammate sends you a `.bentomodel` archive, you can use the `import` command to send it to your local BentoML model store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfa2f89e-44fb-49ed-8145-b966972497ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \u001b[31m[models] `import` failed: Item 'xgb_custom:nk3qcarhp2bvsj77' already exists in the store <osfs '/home/bexgboost/bentoml/models'>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml models import ./models/xgb_custom-nk3qcarhp2bvsj77.bentomodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e3294-5dda-4850-a288-6366e55fc5c9",
   "metadata": {},
   "source": [
    "## Retrieving saved models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bbb4c-b033-49ac-b33d-76f1a8e4c774",
   "metadata": {},
   "source": [
    "There are a few ways of loading saved models from the model store into your environment. The simplest one is the `load_model` function. Like `save_model`, `load_model` is also framework-specific:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "607ac8b4-37b7-4b15-a98a-b478b8d80ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x7fd0959da4f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "booster = bentoml.xgboost.load_model(\"xgb_custom:latest\")\n",
    "booster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637f9b5-6248-43c6-bfa8-f9247da31fd9",
   "metadata": {},
   "source": [
    "The function will load the model in exactly the same format it was before it was saved, meaning you can use its native methods like `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7e4b257-30e1-4ab1-a661-e6bce70a5ad6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4840052], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample = np.random.random(size=(1, 7))\n",
    "\n",
    "booster.predict(xgb.DMatrix(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ca9c3-6eea-4a32-9540-4ea675e8626a",
   "metadata": {},
   "source": [
    "To load the model as a BentoML `Model` object, you can use the `models.get` command, which IS NOT framework-specific:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93228c0b-b963-4822-adfd-53cd5b2f3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = bentoml.models.get(\"xgb_custom:latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4d27a-c2d6-49b6-b287-923c1f9fd47c",
   "metadata": {},
   "source": [
    "The reason you might want to load the model in this format is because now, you can access its add-ons like metadata and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59b4da14-11e4-416c-8ea5-4743a7310f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Bex'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.info.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "480de251-4a5c-423a-80a7-c4595c09cd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.99,\n",
       " 'feature_importances': {'f0': 134.2563934326172,\n",
       "  'f1': 27.976463317871094,\n",
       "  'f2': 56.519203186035156,\n",
       "  'f3': 13.31026554107666,\n",
       "  'f4': 13.665970802307129,\n",
       "  'f5': 12.156410217285156,\n",
       "  'f6': 22.775766372680664}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.info.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7016dadc-b9dc-411d-bd42-9446083fb7e7",
   "metadata": {},
   "source": [
    "The final and most important way of retrieving models is by loading them as runners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "260616ee-d396-4aa1-8ed3-2615a45ae211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "tag = bentoml.models.get(\"xgb_custom:latest\")\n",
    "xgb_runner = tag.to_runner()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e893634-c907-43cd-b059-718658d27690",
   "metadata": {},
   "source": [
    "Runners are special objects of BentoML that are optimized to use system resources in the most efficient way possible based on their framework. Runners are the core components of the APIs we will build in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c021dbd-7624-4c57-b51b-c7d190113f3e",
   "metadata": {},
   "source": [
    "Now, we are ready to start building the API!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa3009-f8f8-44b9-ac92-24c427460783",
   "metadata": {},
   "source": [
    "## Organize into scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14727d0-a1aa-48da-90e2-2557fa7ddda8",
   "metadata": {},
   "source": [
    "Up until now, we have been using notebooks. To start building an API service, we need to switch to Python scripts. Let's organize the code of the previous sections. In `generate_data.py` file, create a function that saves the synthetic data from the \"Dataset Preparation\" section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e57c0d1b-b382-40fe-9232-da73d04ea3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "def generate_data(n_samples, n_features, n_informative, path):\n",
    "    \"\"\"\n",
    "    A simple function to save a synthetic dataset to path.\n",
    "    \"\"\"\n",
    "    # The code from the above sections\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16718382-a53c-47de-bc39-9b0fe34a116e",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    n_samples, n_features = 10000, 7\n",
    "    generate_data(n_samples, n_features, 5, \"data/data.csv\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ac613-ea03-41fa-aa2d-da8625348a1a",
   "metadata": {},
   "source": [
    "> The full `generate_data.py` script can be found [here](https://github.com/BexTuychiev/bentoml_sample_project/blob/main/src/generate_data.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba1fd3-2827-421f-9968-064823f07a1e",
   "metadata": {},
   "source": [
    "In a `train.py` file, create a function that trains our XGBoost classifier and saves it to BentoML model store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03ae34e2-664f-4c86-87e8-37b25e1c5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb_save(X, y, tag_name=\"xgb_final\"):\n",
    "    \"\"\"\n",
    "    A simple function to train a model and save it to BentoML model store.\n",
    "    \"\"\"\n",
    "    # Create DMatrix\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "    # Specify parameters for a binary classification problem\n",
    "    params = {\"objective\": \"binary:logistic\", \"booster\": \"gbtree\", \"eval_metric\": \"auc\"}\n",
    "\n",
    "    # Train\n",
    "    booster = xgb.train(params, dtrain, num_boost_round=20)\n",
    "\n",
    "    bentoml.xgboost.save_model(tag_name, booster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec96825b-d8e9-44c2-960c-0fc2bea79391",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prep the data\n",
    "    data = pd.read_csv(\"data/data.csv\")\n",
    "    X, y = data.drop(\"target\", axis=1), data[[\"target\"]]\n",
    "\n",
    "    # Train and save\n",
    "    train_xgb_save(X, y, \"xgb_booster\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e932d-89a5-4a0f-b010-dad3f3a85e6b",
   "metadata": {},
   "source": [
    "> The full `train.py` script can be found [here](https://github.com/BexTuychiev/bentoml_sample_project/blob/main/src/train.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90d3e9-5fd2-4b9d-94d0-149201de314b",
   "metadata": {},
   "source": [
    "For completeness, run both scripts in the correct order to generate the dataset and save a new model to the model store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28489f8-8a99-461a-92d9-02408c18cceb",
   "metadata": {},
   "source": [
    "## Creating an API service script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a81b2-5b8e-4544-ba0f-5fab5af77e78",
   "metadata": {},
   "source": [
    "Now, it is time to create the local API. For that, we will only need a simple script that starts like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fca5f55d-ebd8-4236-9c07-1100fac8c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "\n",
    "# Get the runner\n",
    "xgb_runner = bentoml.models.get(\"xgb_booster:latest\").to_runner()\n",
    "\n",
    "# Create a Service object\n",
    "svc = bentoml.Service(\"xgb_classifier\", runners=[xgb_runner])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b24d3-0af2-4c74-921a-b27887c12e84",
   "metadata": {},
   "source": [
    "After loading our model with `models.get` as a runner, we create an object called `svc`. It will be an instance of BentoML `Service` object. `Service` is a high-level class that abstractly represents our API. \n",
    "\n",
    "To the service object, we add a single endpoint called `classify`, which is done by creating a function with the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e632e529-dc98-4d2a-9313-d06364c4de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bentoml.io import NumpyNdarray\n",
    "import numpy as np\n",
    "\n",
    "# Create an endpoint named `classify`\n",
    "@svc.api(input=NumpyNdarray(), output=NumpyNdarray())\n",
    "def classify(input_series) -> np.ndarray:\n",
    "    # Convert the input string to numpy array\n",
    "    label = xgb_runner.predict.run(input_series)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bce929-aa53-4357-9ee2-5be8bb51e8e2",
   "metadata": {},
   "source": [
    "Let's understand the above snippet line-by-line. \n",
    "\n",
    "First, we are importing a new class called `NumpyNdarray` from `bentoml.io` - Input/Output module. To standardize inputs and outputs, BentoML offers several classes like `NumpyNdarray` such as, `Text`, `File`, `Image`, `PandasDataFrame`, etc. \n",
    "\n",
    "Adding these classes to the `input` and `output` arguments of the `svc.api` decorator ensures that correct datatypes are passed to our API endpoint. In our case, we are making sure that the data passed to our `classify` function is always a NumPy array. If we were working with image models, our input class could be a `File` or `Image` class, while the output would be `NumpyNdarray` again. \n",
    "\n",
    "Inside the function, we are using the `run` function of our runner to get a prediction on the input. Here is what the script looks like in the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0fa703e-4b99-4787-b61a-7ad447ab66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import numpy as np\n",
    "from bentoml.io import NumpyNdarray\n",
    "\n",
    "# Get the runner\n",
    "xgb_runner = bentoml.models.get(\"xgb_booster:latest\").to_runner()\n",
    "\n",
    "# Create a Service object\n",
    "svc = bentoml.Service(\"xgb_classifier\", runners=[xgb_runner])\n",
    "\n",
    "\n",
    "# Create an endpoint named classify\n",
    "@svc.api(input=NumpyNdarray(), output=NumpyNdarray())\n",
    "def classify(input_series) -> np.ndarray:\n",
    "    # Convert the input string to numpy array\n",
    "    label = xgb_runner.predict.run(input_series)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e40f9-510d-4062-b181-47dc126eb639",
   "metadata": {},
   "source": [
    "That's it! By using `bentoml serve`, we can create a local debug server:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a0ae0-743c-420e-a19d-3f8585d9cd09",
   "metadata": {},
   "source": [
    "```\n",
    "$ bentoml serve service.py:svc --reload\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a328bb17-94af-4532-90fe-cee25278443d",
   "metadata": {},
   "source": [
    "> Important: `service.py` and `svc` variables in the above command changes based on your script name and the name of the service object. If you had a service object named `api` in a script called `api.py`, the command would be `bentoml serve api.py:api --reload`. The `--reload` tags ensures that BentoML detects changes made to your script without needing to restart the server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc11eebc-0d27-4fff-8ef1-be6032d86456",
   "metadata": {},
   "source": [
    "Here is a sample output of the command (ignore the name mismatch):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2698d-90da-46af-b0fc-e2dd09358748",
   "metadata": {},
   "source": [
    "![](images/debug_server.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d35162-7011-46cb-8573-963aaec6c9bc",
   "metadata": {},
   "source": [
    "The GIF shows that the API is live locally on https://127.0.0.1:3000:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63ad40-8419-4504-8ded-7fa9ea99bf67",
   "metadata": {},
   "source": [
    "SHOW THE GIF HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a795b1c-8da6-4aec-88fa-83fb8dea9c75",
   "metadata": {},
   "source": [
    "By using Swagger UI, BentoML shows you an interactive documentation of our API. We can already send requests to it to get predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5991b26-a02e-4dce-8e22-db79fedc6a26",
   "metadata": {},
   "source": [
    "SHOW TO GET REQUESTS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6e73f-ca45-400c-b8a2-4465981496e0",
   "metadata": {},
   "source": [
    "## Building a Bento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61066985-2153-4c23-a1f0-30a289652025",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f5f2c0-7059-4079-b367-3893ac25ae41",
   "metadata": {},
   "source": [
    "```yaml\n",
    "service: \"service.py:svc\"  # Same as the argument passed to `bentoml serve`\n",
    "labels:\n",
    "   owner: Bex Tuychiev\n",
    "include:\n",
    "- \"*.py\"\n",
    "python:\n",
    "   packages:  # Additional pip packages required by the service\n",
    "   - bentoml==1.0.0\n",
    "   - numpy==1.22.4\n",
    "   - pandas==1.4.2\n",
    "   - scikit_learn==1.1.1\n",
    "   - xgboost==1.4.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65673a1c-8626-4b6f-89a9-8bf2b055ab62",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install pipreqs\n",
    "$ pipreqs --force .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1dcf67-70ed-458b-858e-ac33b2a2e4e7",
   "metadata": {},
   "source": [
    "```\n",
    "$ bentoml build .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d6165-64b2-4b89-8e9c-7b408de2f03a",
   "metadata": {},
   "source": [
    "![](images/bentoml_build.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b7539a6-0ffa-4b5f-9f2c-963ea21ffccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mPath                  \u001b[0m\u001b[1m \u001b[0m\n",
      " xgb_classifier:scwjjg…  81.50 KiB  2022-08-29 15:08:54  ~/bentoml/bentos/xgb_… \n",
      " xgb_classifier:7m4jyq…  81.50 KiB  2022-08-29 15:04:44  ~/bentoml/bentos/xgb_… \n",
      " sample_service:qpvhfk…  74.24 KiB  2022-08-27 15:54:00  ~/bentoml/bentos/samp… \n"
     ]
    }
   ],
   "source": [
    "!bentoml list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88f5bd1-4ca9-4613-a17d-d14ccabc3c28",
   "metadata": {},
   "source": [
    "## Setting up AWS credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4716f7-d310-4084-8350-84fd864f3dc7",
   "metadata": {},
   "source": [
    "Go to [AWS console](https://console.aws.amazon.com/console/home)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404bc280-46e6-4e46-8d46-b4064f6e18d0",
   "metadata": {},
   "source": [
    "![](images/aws_credentials.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d760866-4ae0-4c49-a470-ab7b0526ed99",
   "metadata": {},
   "source": [
    "```bash\n",
    "export AWS_ACCESS_KEY_ID=REPLACE_WITH_YOUR_ACCESS_KEY\n",
    "export AWS_SECRET_ACCESS_KEY=REPLACE_WITH_YOUR_SECRET_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b01334-7917-4f0a-9209-6bbc10ad4690",
   "metadata": {},
   "source": [
    "```bash\n",
    "setx AWS_ACCESS_KEY_ID REPLACE_WITH_YOUR_ACCESS_KEY\n",
    "setx AWS_SECRET_ACCESS_KEY REPLACE_WITH_YOUR_SECRET_KEY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814390d-c539-4a97-9fc1-354e55abe63c",
   "metadata": {},
   "source": [
    "## Deploying the Bento to AWS Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b91bd-1151-40d3-8d47-d0af704d4077",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install bentoctl boto3\n",
    "$ bentoctl operator install aws-lambda\n",
    "$ bentoctl init\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75d78e-a3b5-4f5b-be5c-a0994673da3c",
   "metadata": {},
   "source": [
    "![](images/bentoctl_tfvars.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536d6aa-972b-41bf-84b6-5dce5deb5bd1",
   "metadata": {},
   "source": [
    "![](images/main_tf.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ae87c-d391-4603-80eb-2d116ad37853",
   "metadata": {},
   "source": [
    "Terraform installations are [here](https://www.terraform.io/cli/install/apt) for Linux. For other systems, [here](https://learn.hashicorp.com/tutorials/terraform/install-cli)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a71f8-4e0f-46bf-8938-248a022e8ffe",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ terraform -h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1cdfd-bd79-4725-b030-bc7c60182b3b",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ bentoctl build -b xgb_classifier:latest -f deployment_config.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0d191-596a-4be4-9557-70a3d6db5ea6",
   "metadata": {},
   "source": [
    "![](images/bentoctl_build.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae5f7a-2bd9-4eec-bad5-b3a6bf8f4cb0",
   "metadata": {},
   "source": [
    "If you receive `botocore.exceptions.ClientError`, then AWS credentials is not set up properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa785a5-3622-48d4-b708-20401e644003",
   "metadata": {},
   "source": [
    "![](images/build_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b24bd7-5040-433b-a7cd-d4d9d92fd5f0",
   "metadata": {},
   "source": [
    "```\n",
    "$ terraform init\n",
    "$ terraform apply -var-file=bentoctl.tfvars -auto-approve\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6ebab-6d64-43d9-b401-c01b47d327dd",
   "metadata": {},
   "source": [
    "![](images/terraform_apply.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19376dc-e828-4ef4-9d95-4a11f73f24dc",
   "metadata": {},
   "source": [
    "![](images/terraform_output.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cae9ff-5890-46bb-8d17-10690909919c",
   "metadata": {},
   "source": [
    "If you go to https://console.aws.amazon.com/lambda, you should see:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bentoml",
   "language": "python",
   "name": "bentoml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
