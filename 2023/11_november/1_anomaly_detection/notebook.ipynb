{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dda2ef-5de5-4215-83c6-095eda4eb11d",
   "metadata": {},
   "source": [
    "# What is Anomaly Detection? Methods, Examples, and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc61d5-01c4-4b34-905a-5db061b68bd6",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dffbd3c-605d-4124-b996-a4ccd0088faf",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "2. What is Anomaly Detection?\n",
    "    1. Definition and context\n",
    "    2. Importance in data science\n",
    "3. Real-world Applications of Anomaly Detection\n",
    "4. Types of Anomalies\n",
    "5. Anomaly detection methods and when to use each one\n",
    "6. Building an anomaly detection model\n",
    "7. Challenges and Limitations in Anomaly Detection\n",
    "8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277f8ca-c0d8-49d7-98dc-73ef76063f9f",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011b0c9-a68a-4d3e-a86f-590008a58fd1",
   "metadata": {},
   "source": [
    "Everyone loves to stand out, to be different. But, that's not the quality you want in your data points as a data scientists. Divergent data points or _anomalies_ in a dataset, are one of the most dangerous data quality issues that plague almost all data projects. \n",
    "\n",
    "This last sentence may surprise you if you have only been working on polished open-source datasets that often come without outliers. But real-world datasets always have some amount of different from the norm samples. It is your job to detect and deal with them appropriately. \n",
    "\n",
    "In this article, you will learn the fundamental ideas of this process, which is often called __anomaly detection__:\n",
    "\n",
    "1. The detrimental effect anomalies have on your project.\n",
    "2. The importance of detecting anomalies.\n",
    "3. Real-world applications of anomaly detection.\n",
    "4. The difference between anomalies, outliers and novelties.\n",
    "5. Types of anomalies and anomaly detection methods.\n",
    "6. How to build anomaly detection algorithms in Python.\n",
    "7. How to deal with the challenges of anomaly detection. \n",
    "\n",
    "By the end, you will master the fundamentals of anomaly detection and gain the confidence to mitigate the disruptive influence of outliers in your projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e084ecbd-85e5-4a8e-ac3b-edb423b02d5c",
   "metadata": {},
   "source": [
    "### What is Anomaly Detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52faac7f-ef95-465e-be63-645ab29e87eb",
   "metadata": {},
   "source": [
    "Anomaly detection, often referred to as outlier detection, is a process of finding patterns or instances in a dataset that deviate significantly from the expected or \"normal behavior\".\n",
    "\n",
    "The definiton of both \"normal\" and anomalous data significantly varies depending on the context. Below are a few examples.\n",
    "\n",
    "##### 1. Financial transactions\n",
    "__Normal__: Routine purchases and consistent spending by an individual in London.\n",
    "\n",
    "__Outlier__: A massive withdrawal from Ireland from the same account, hinting at potential fraud.\n",
    "\n",
    "##### 2. Network traffic in cybersecurity\n",
    "__Normal__: Regular communication, steady data transfer, and adherence to protocol.\n",
    "\n",
    "__Outlier__: Abrupt increase in data transfer or use of unknown protocols signaling a potential breach or malware.\n",
    "\n",
    "##### 3. Patient vital signs monitoring\n",
    "__Normal__: Stable heart rate and consistent blood pressure\n",
    "\n",
    "__Outlier__: Sudden increase in heart rate and decrease in blood pressure, indicating a potential emergency or equipment failure. \n",
    "\n",
    "Anomaly detection includes many types of unsupervised methods to identify divergent samples. Data specialists choose them based on anomaly type, the context, structure and characteristics of the dataset at hand. We'll cover them in the coming sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0c46f5-a942-4ae4-8a24-1cb24fa034e8",
   "metadata": {},
   "source": [
    "### Real-world applications of Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e35e2-1675-4e0d-bbc2-c94cf8eb1ad0",
   "metadata": {},
   "source": [
    "Even though we saw some examples above, let's look at a real-life story how anomaly detection works in finance.\n",
    "\n",
    "Shaq O'Neal, four times NBA winner, gets traded from the Miami Heat to the Phoenix Suns. When Shaq arrives at the empty apartment provided by the Phoenix Suns, he wants to furnish his apartment immediately in the middle of the night. So, he goes to Walmart and makes the biggest purchase in Walmart history for $70.000... or at least, he tries to, because his card gets declined.\n",
    "\n",
    "As he wonders what possibly could be the problem (he _can't_ be broke!) at 2 am in the morning, American Express security calls him, all out of breath, and tells him that his card was stolen because somebody was trying to make a 70.000$ purchase at Walmart in Phoenix (watch [here](https://www.youtube.com/watch?v=1W3A2hQhdg4&ab_channel=TheLateLateShowwithJamesCorden)). \n",
    "\n",
    "There are so many other real-world applications of anomaly detection beyond finance and fraud detection:\n",
    "\n",
    "- Cybersecurity\n",
    "- Healthcare\n",
    "- Industrial equipment monitoring\n",
    "- Network intrusion detection\n",
    "- Energy grid monitoring\n",
    "- E-commerce and user behavior analysis\n",
    "- Quality control in manufacturing\n",
    "\n",
    "and so on. Anomaly detection is deeply woven into the daily services we use and often, we don't even notice it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1e011-dc20-451d-a8a9-039314bfd685",
   "metadata": {},
   "source": [
    "### The importance in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a5915a-0dd9-470c-810c-e6dd190bf666",
   "metadata": {},
   "source": [
    "Data is the most precious commodity in data science and anomalies are the most disruptive threats to its quality. Bad data quality means bad analytics, bad dashboards, bad machine learning models, bad decisions, and ultimately, a compromised foundation for informed decision-making.\n",
    "\n",
    "Anomalies distort statistical analyses by introducing non-existent patterns leading to wrong conclusions and unreliable predictions. As they are often the extreme values in a dataset, anomalies often skew the two most important characteristics of distributions: mean and the standard deviation.\n",
    "\n",
    "As the internals of almost all machine learning models rely heavily on these two metrics, timely detection of anomalies in data science is crucial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c427e-7e01-498a-9ddd-77ebb79788fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Types of Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388264b-a77b-4857-986d-4f6e7a336ccb",
   "metadata": {},
   "source": [
    "Anomaly detection encompasses two broad practices: outlier detection and novelty detection. \n",
    "\n",
    "Outliers are abnormal or extreme data points that exist only in training data. In contrast, novelties are new or previously unseen instances compared to the original (training) data.\n",
    "\n",
    "For example, consider a dataset of daily temperatures in a city. Most days, the temperatures range between 20°C and 30°C. However, one day, there's a spike of 40°C. This extreme temperature is an outlier as it significantly deviates from the usual daily temperature range.\n",
    "\n",
    "Now, imagine that the city installs a new, more accurate weather monitoring station. As a result, the dataset starts consistently recording slightly higher temperatures, ranging from 25°C to 35°C. This sustained increase in temperatures is a __novelty__, representing a new pattern introduced by the improved monitoring system.\n",
    "\n",
    "Anomalies, on the other hand, is a broad term that refers to both outliers and novelties. It can be used to define any abnormal instance in any context.\n",
    "\n",
    "Identifying the type of anomalies is crucial as it allows you to choose the right algorithm to detect them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0dba6-5dc5-4f48-990c-9e15b84f7e86",
   "metadata": {},
   "source": [
    "### Types of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2016a84c-f88a-4771-ad72-b24dd4f355c7",
   "metadata": {},
   "source": [
    "As there are two types of anomalies, there are two types of outliers as well: _univariate_ and _multivariate_. Depending on the type, we will use different detection algorithms.\n",
    "\n",
    "1. Univariate outliers are identified based on the distribution of a single variable or feature in isolation. Univariate outliers are extreme or abnormal values that deviate from the typical range of values for that specific feature\n",
    "2. Multivariate outliers are identified by combining the values of multiple variables simultaneously. \n",
    "\n",
    "For example, consider a dataset of housing prices in a neighborhood. Most houses are priced between \\$200.000 and \\$400.000, but there is House A with an exceptionally high price of $1.000.000. When only prices are analyzed, House A is a clear outlier.\n",
    "\n",
    "Now, let's add two more variables to our dataset of housing prices: the square footage and the number of bedrooms. When we consider the square footage, the number of bedrooms and the price, there is House B that looks odd:\n",
    "\n",
    "- It has half the square footage of the mean house price.\n",
    "- It has only one bedroom.\n",
    "- It costs the top of the range $380.000.\n",
    "\n",
    "When we look at these characteristics individually, they seem ordinary. Only when we put them together, we will find out that House B is a clear multivariate outlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25f330-f2dc-442b-9585-95a356ae7d07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Anomaly Detection Methods And When to Use Each One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c59c6-1327-425a-b4b4-39092afeb4f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Anomaly detection algorithms differ depending on the type of outliers and the structure in the dataset.\n",
    "\n",
    "For univariate outlier detection, the most popular methods are:\n",
    "\n",
    "1. __Z-score (standard score)__: the z-score measures how many standard deviations a datapoint is away from the mean. Generally, instances with a z-score over 3 are chosen as outliers\n",
    "2. Interquartile range (IQR): The IQR is the range between the first quartile (Q1) and the third quartile (Q3). When an instance is beyond Q1 or Q3 for some multiplier of IQR, they are considered outliers. The most common multiplier is 1.5, making the outlier range \\[Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\\].\n",
    "3. Modified z-scores: similar to z-scores but modified z-scores use median and a measure called Median Absolute Deviation (MAD) to find outliers. Since mean and standard deviation are easily skewed by outliers, modified z-scores are generally considered more robust. \n",
    "\n",
    "For multivariate outliers, we generally use machine learning algorithms. Because of their depth and strength, they are able to identify intricate patterns in complex datasets:\n",
    "\n",
    "1. Isolation Forest: uses a collection of isolation trees (similar to decision trees) that recursively partition complex datasets until each instance is isolated. The instances that get isolated the quickest are considered outliers.\n",
    "2. Local Outlier Factor (LOF): LOF measures the local density deviation of a sample compared to its neighbors. Points with significantly lower density are chosen as outliers.\n",
    "3. Clustering techniques: techniques such as k-means or hierarchical clustering divide the dataset into groups. Points that don't belong to any group or are in their own little clusters are consider outliers. \n",
    "4. Angle-based Outlier Detection (ABOD): ABOD measures the angles between individual points. Instances with odd angles can be considered outliers.\n",
    "\n",
    "Apart from considering the type of anomalies, you should consider dataset characteristics and project constraints. For example, Isolation Forest works well on almost any dataset but it is slower as it is an ensemble method. In comparison, LOF is very fast in training but may not perform as well as Isolation Forest.\n",
    "\n",
    "You can see a comparison of the most common Anomaly Detection algorithms on 55 datasets from this [page](https://pyod.readthedocs.io/en/latest/benchmark.html) of Python Outlier Detection (PyOD) package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f4e960-4b7d-447c-85b9-ad97f00a2dd9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Building an anomaly detection model in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416069b4-bc50-4fc4-89bd-20c90afe8f9b",
   "metadata": {},
   "source": [
    "Like virtually any task you can imagine, there are many libraries in Python to perform anomaly detection. The best contenders are:\n",
    "\n",
    "- Python Outlier Detection (PyOD)\n",
    "- Scikit-learn\n",
    "\n",
    "While scikit-learn offers five classic machine learning algorithms (you can use them for both univariate and multivariate algorithms), PyOD includes over 30 algorithms from simple methods such as MAD to complex deep learning models. You can also use TensorFlow or PyTorch for custom models but they are beyond the scope of this article.\n",
    "\n",
    "I prefer `pyod` for its rich library of algorithms and an API consistent with `sklearn`. It takes just a few lines of code to identify and extract outliers from a dataset using PyOD. Here is an example of performing MAD outlier detection on a univariate dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3e29d5-c7e1-4979-8100-baa11c31fec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    49708\n",
       "1     4232\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyod.models.mad import MAD\n",
    "\n",
    "# Load a sample dataset\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "# Extract the feature we want\n",
    "X = diamonds[[\"price\"]]\n",
    "\n",
    "# Initialize and fit a model\n",
    "mad = MAD().fit(X)\n",
    "\n",
    "# Extract the outlier labels\n",
    "labels = mad.labels_\n",
    "\n",
    "pd.Series(labels).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d97b23-9ed5-4a42-8535-0b5add22256d",
   "metadata": {},
   "source": [
    "Let's go through the code line-by-line. First, we load the necessary libraries for data manipulation, loading a dataset and `pyod` for the outlier detection model. Then, after loading the Diamonds dataset built into Seaborn, we extract the diamond prices. \n",
    "\n",
    "Then, we initialize and fit a Median Absolute Deviation (MAD) model to `X` in a single line. Next, we extract the inlier and outlier labels using the `labels_` attribute of `mad` into `labels`.\n",
    "\n",
    "When we print the value counts of `labels` at the end, we see that 49708 belongs to category 0 (inliers) while 4232 belongs to 1 (outliers). If we want to remove the outliers from the original dataset, we can use pandas subsetting on `diamonds`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e7c35c-b564-438f-a5ea-115f8cfd7fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49708"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_free = diamonds[labels == 0]\n",
    "\n",
    "len(outlier_free)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9b0f6-d1c8-4f72-91e4-522869d141b9",
   "metadata": {},
   "source": [
    "`labels == 0` creates an array of True/False values (boolean array) where `True` denotes an inlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c509d5-baa6-4f46-9580-6cb50140a891",
   "metadata": {},
   "source": [
    "The process of creating a multivariate anomaly detection model is also the same. But multivariate outlier detection requires extra processing steps if categorical features are present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed03034b-7aa4-4818-8dac-7af28f74c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   carat    53940 non-null  float64 \n",
      " 1   cut      53940 non-null  category\n",
      " 2   color    53940 non-null  category\n",
      " 3   clarity  53940 non-null  category\n",
      " 4   depth    53940 non-null  float64 \n",
      " 5   table    53940 non-null  float64 \n",
      " 6   price    53940 non-null  int64   \n",
      " 7   x        53940 non-null  float64 \n",
      " 8   y        53940 non-null  float64 \n",
      " 9   z        53940 non-null  float64 \n",
      "dtypes: category(3), float64(6), int64(1)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "diamonds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c32269f-a4c9-438d-98f2-a84601e87ccb",
   "metadata": {},
   "source": [
    "Since `pyod` expects all features to be numeric, we need to encode categorical variables. We will use Sklearn to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a5a4b4-7189-4c10-8cce-3112b692e32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut  color  clarity  depth  table  price     x     y     z\n",
       "0   0.23  2.0    1.0      3.0   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  3.0    1.0      2.0   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23  1.0    1.0      4.0   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  3.0    5.0      5.0   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31  1.0    6.0      3.0   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "oe = OrdinalEncoder()\n",
    "\n",
    "# Extract the categorical feature names\n",
    "cats = diamonds.select_dtypes(include=\"category\").columns.tolist()\n",
    "\n",
    "# Encode the categorical features\n",
    "cats_encoded = oe.fit_transform(diamonds[cats])\n",
    "\n",
    "# Replace the old values with encoded values\n",
    "diamonds.loc[:, cats] = cats_encoded\n",
    "\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8187d-500c-46a1-8fdb-5f077cf05986",
   "metadata": {},
   "source": [
    "Let's go through the code line-by-line again. First, we import the `OrdinalEncoder` class that encodes ordinal categorical features and initialize it. Ordinal features are variables that have natural, ordered categories as in the case of diamond quality measurements. The cut and clarity are ordinal while `color` isn't. But not to complicate things, we will consider it ordinal for now.\n",
    "\n",
    "Then, we extract the categorical feature names using the `select_dtypes` method of Pandas DataFrames. We chain the `.columns` and `.tolist()` attributes to get column names in a list named `cats`.\n",
    "\n",
    "Then, we will the list to transform the features we want with `oe`. Finally, using a neat Pandas trick with `.loc`, we replace the old text values with numeric ones. \n",
    "\n",
    "Before fitting the model, we will extract the feature array `X`. The purpose of the `diamonds` dataset is to predict diamond prices given its characteristics. So, `X` will contain all columns but `price`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf29640-210e-4977-80fd-aca3230ccd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diamonds.drop(\"price\", axis=1)\n",
    "y = diamonds[[\"price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49d743-8b0d-4aad-8a37-590853821eb4",
   "metadata": {},
   "source": [
    "Now, let's build and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f728005-f982-4210-9b0f-09042920b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "\n",
    "# Create a model with 10000 trees\n",
    "iforest = IForest(n_estimators=10000)\n",
    "iforest.fit(X)  # This will take a minute\n",
    "\n",
    "# Extract the labels\n",
    "labels = iforest.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a405102-d158-452f-bf8d-790e1fac7b64",
   "metadata": {},
   "source": [
    "> The more trees `IForest` estimator has, the more time it takes to fit the model to the dataset. \n",
    "\n",
    "After we have labels, we can remove the outliers from the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d8b5ee-2961-45e1-99c0-34852b5f2872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_outlier_free = X[labels == 0]\n",
    "y_outlier_free = X[labels == 0]\n",
    "\n",
    "len(X_outlier_free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10cf5d5-7a0d-42ca-a96e-da81230b1af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53940"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The length of the original dataset\n",
    "len(diamonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb76782-c72f-42cf-a31e-ebd955139fb6",
   "metadata": {},
   "source": [
    "The model found over 5000 outliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82115b2d-c7de-4acb-bd31-8c8d8a59cc1a",
   "metadata": {},
   "source": [
    "### Challenges in Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012665d-22ad-40fc-8eda-de06566f2fce",
   "metadata": {},
   "source": [
    "Anomaly detection may pose bigger challenges than other machine learning tasks because of its unsupervised nature. However, most of these challenges can be mitigated with various methods (see the next section for resources). \n",
    "\n",
    "When an outlier detection model produces results, we need to ask these two questions:\n",
    "- Are the found outliers actually outliers?\n",
    "- Did the model find all outliers in the data?\n",
    "\n",
    "In supervised learning, we can easily check if the model is performing well by matching its predictions on the test data on the actual labels. But, we can't do the same in outlier detection as there aren't ready-made labels telling us which samples are inliers and which are outliers. \n",
    "\n",
    "So, some or most of the +5000 outliers found from the diamonds dataset may not actually be outliers! There is no way of knowing for sure. It may have labeled some inliers as outliers while missing some actual outliers.\n",
    "\n",
    "This problem of not knowing the __contamination level__, the percentage of outliers in a dataset, is the biggest one in anomaly detection. Because of it, we can't reliably measure the performance of outlier classifiers nor can we verify its results. \n",
    "\n",
    "For this reason, all estimators in `pyod` have a parameter called `contamination`, which is set to 0.1 by default. As a machine learning engineer, you have to tune this parameter by yourself.\n",
    "\n",
    "Of course, sometimes there are alternatives. For example, the `IsolationForest` model offered by Sklearn as an internal algorithm to find the contamination level. But `IsolationForest` is a single model and not a silver bullet to all outlier detection problems.\n",
    "\n",
    "Another problem in anomaly detection is the data imbalance. Anomalies are often rare compared to normal instances, causing datasets to be imbalanced. This imbalance can lead to difficulties in distinguishing between actual anomalies and irregularities within the majority class.\n",
    "\n",
    "Addressing these issues (and much more we haven't covered) involves choosing suitable algorithms, hyperparameter tuning, feature selection, handling class imbalance and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19604f03-2d25-47b2-8225-df226cacc328",
   "metadata": {},
   "source": [
    "### Summary and what to do next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7cdee-7176-497c-bfc1-fb53e93e7b9a",
   "metadata": {},
   "source": [
    "We've finished your (probably) first exposure to the fascinating world of anomaly detection. The fundamental concepts and skills in this tutorial can go a long way in exploring anomaly detection further.\n",
    "\n",
    "To deepen your understanding, here are some resources to check out next:\n",
    "- [Anomaly Detection in Python course by DataCamp](https://www.datacamp.com/courses/anomaly-detection-in-python): covers methods and techniques more deeply discussed in this article and discusses how to address the issues presented in the last section. \n",
    "- [Anomaly Detection in R course by DataCamp]: a course for people who prefer good-ol' R\n",
    "- [Anomaly Detection course by Intel](https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/course-anomaly-detection.html): an advanced, 8-week free course with a focus on the internals on anomaly detection\n",
    "\n",
    "Thank you for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
