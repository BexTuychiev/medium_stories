{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edddc3a2-2bec-42a5-9f0d-51a39a3c6831",
   "metadata": {},
   "source": [
    "# Using XGBoost in Python Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941c1658-1c82-45fe-8557-12698b56732e",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "- Give a brief motivation why you should learn XGBoost\n",
    "- List a few of its advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e47c94-de61-4970-879a-54ef2720fc4a",
   "metadata": {},
   "source": [
    "## What you will learn in this tutorial\n",
    "- Directly tell the topics and features of XGB covered in the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5402a5e3-d9a6-45f7-ac5a-1dae55c7b9b0",
   "metadata": {},
   "source": [
    "## Installation\n",
    "- Installing via pip and conda\n",
    "- (Possibly) on WSL2 - we want to be inclusive\n",
    "- Maybe suggest DataCamp workspace?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20cfb2-aa45-4580-852c-fc8a5729a25b",
   "metadata": {},
   "source": [
    "## Loading and exploring the data \n",
    "- Load the Diamonds dataset from Seaborn\n",
    "- Show data description (summary stats, info, feature names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6996fbe-ae36-44c1-bd87-40c1cc9c0c23",
   "metadata": {},
   "source": [
    "## Regression in XGBoost\n",
    "- Build the DMatrix\n",
    "- Discuss the objective and loss functions for regression\n",
    "- Create the first model and fit to the dataset\n",
    "- Evaluate on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d98efa-bda0-449d-9335-8e8ffba1cc9c",
   "metadata": {},
   "source": [
    "## Classification in XGBoost\n",
    "- Discuss a few classification metrics and objective functions XGB offers\n",
    "- Build the DMatrix for a classification task\n",
    "- Train and evaluate an XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450f0fc-bda6-47e6-bddb-372e9dcadb71",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "- Give brief and straightforward intro to Optuna for HP tuning\n",
    "- Show how to create an objective and a study to tune XGB hyperparameters\n",
    "- Show how to tune XGB models with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8895a931-7434-49ab-92e5-a92d2093a74a",
   "metadata": {},
   "source": [
    "## XGBoost training API vs. Scikit-learn API\n",
    "- List the differences between two APIs of XGB\n",
    "- Show how to switch models between two APIs even after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766f455-7cda-4361-acf7-e4b30cf376f5",
   "metadata": {},
   "source": [
    "## Feature importances\n",
    "- Extracting and plotting feature importances\n",
    "- Why feature importances is important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faa1f10-2ab1-4803-96a8-e259c75a3cbe",
   "metadata": {},
   "source": [
    "## Why XGBoost performs so well?\n",
    "- Discuss the internals of XGB without getting into math and the details too much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfff8c-6bda-4705-b276-b512b133481c",
   "metadata": {},
   "source": [
    "## Wrap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
