{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3235b6c5-7d61-4b6b-adc0-5567c154d57f",
   "metadata": {},
   "source": [
    "# Boosting Your Data Science Workflow with Dask: A Comprehensive Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd07e26-99f2-4a81-bbd5-97f6ed4301e8",
   "metadata": {},
   "source": [
    "- Introduction (50 words)\n",
    "    - What is Dask and why it is important in data science workflows\n",
    "- Basic Concepts of Dask (150 words)\n",
    "    - Overview of Dask\n",
    "    - Comparison between Dask and traditional tools like Pandas, Spark, NumPy, etc.\n",
    "    - Why Dask is more suitable for larger datasets\n",
    "- Setting Up Dask (150 words)\n",
    "    - Steps to install Dask\n",
    "    - How to initialize a Dask session\n",
    "- Dask DataFrames (250 words)\n",
    "    - Explanation of Dask DataFrames\n",
    "    - Comparing Dask DataFrame operations with Pandas DataFrame operations\n",
    "    - Showing how Dask handles larger-than-memory computations with an example\n",
    "- Dask Arrays (250 words)\n",
    "    - Explanation of Dask arrays\n",
    "    - Comparing Dask array operations with NumPy array operations\n",
    "    - Demonstrating how Dask arrays work with an example\n",
    "- Dask Bags and Dask Delayed for Unstructured Data (200 words)\n",
    "    - Explaining Dask Bags and Dask Delayed\n",
    "    - How to use Dask Bags for working with unstructured or semi-structured data\n",
    "    - Example of using Dask Delayed for lazy evaluation\n",
    "- Dask Distributed: Parallel and Distributed Computing (150 words)\n",
    "    - Explanation of the Dask distributed scheduler\n",
    "    - How to set up and use a Dask cluster for parallel and distributed computing\n",
    "- Best Practices for Using Dask (200 words)\n",
    "    - Tips and tricks for getting the most out of Dask\n",
    "    - Common pitfalls to avoid when using Dask\n",
    "- Conclusion and Further Resources (100 words)\n",
    "    - Recap of the key points in the tutorial\n",
    "    - Suggestions for further learning resources on Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a1161-7150-4508-96f1-bb2e45c1edd1",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b47a3ec-c47a-4a30-af49-4ea0c8d5ec39",
   "metadata": {},
   "source": [
    "When Wes McKinney started writing Pandas, he had a rule of thumb: for Pandas to work optimally, the machine's RAM size must be 5-10 times larger than the dataset in question. This rule was easy to follow around 2010 but it is 2023. \n",
    "\n",
    "In 2020 already, most real-world datasets could easily crash common everyday laptops and machines with their massive sizes. Predicting this problem long before it became such a burning issue, a solution was released in 2015.\n",
    "\n",
    "Dask is an open-source library released by the developers of Anaconda to address the need for scalable and efficient computing on large datasets that exceed the memory capacity of a single machine.\n",
    "\n",
    "This tutorial will give a thorough introduction to this library and its most important features like Data DataFrames, Arrays and Bags (yes, you read it right) interfaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7eb045-d436-464b-b9cb-d30cb53bae0a",
   "metadata": {},
   "source": [
    "### Setting Up Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb8487-fbf8-46ab-86d4-33d85aad00ce",
   "metadata": {},
   "source": [
    "Like any other library, Dask can be installed in three ways: conda, pip and from source.\n",
    "\n",
    "Since this is an introductory article on Dask, we won't cover the last installation method, as it is for maintainers.\n",
    "\n",
    "If you use Anaconda, Dask is included in your default installation (which is a mark of how popular the library is). If you wish to reinstall or upgrade it, you can use the `install` command:\n",
    "\n",
    "```python\n",
    "conda install dask\n",
    "```\n",
    "\n",
    "The PIP alternative of the above is the following:\n",
    "\n",
    "```python\n",
    "pip install \"dask[complete]\"\n",
    "```\n",
    "\n",
    "Adding the `[complete]` extension also installs the required dependencies of Dask, eliminating the need to install NumPy, Pandas and Tornado manually.\n",
    "\n",
    "You can check if the installation was successful by looking at the library version:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff868a2d-169b-4f0d-bacd-0dafdad71dc4",
   "metadata": {},
   "source": [
    "```python\n",
    "import dask\n",
    "\n",
    "dask.__version__\n",
    "```\n",
    "\n",
    "```\n",
    "'2023.5.0'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88110e92-a981-440b-95be-5f62dedade4d",
   "metadata": {},
   "source": [
    "Most of your time spent working with Dask will be focused on three interfaces: Dask DataFrames, Arrays and Bag. Let's import them to use for the rest of the articlea along with `numpy` and `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6b9a98-58fd-45a6-ad8c-ae9c6f8e9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057bab6-e5e3-422b-9bbf-2792b3a65b2a",
   "metadata": {},
   "source": [
    "### Basic Concepts of Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa307f5-264f-4162-ab88-55a742f594f9",
   "metadata": {},
   "source": [
    "On a high-level, you can think of Dask as a wrapper that extends the capabilities of traditional tools like Pandas, NumPy and Spark to handle larger-than-memory datasets.\n",
    "\n",
    "When faced with large objects like larger-than-memory arrays (vectors) or matrices (dataframes), Dask breaks them up into chunks, also called partitions. \n",
    "\n",
    "For example, consider the array of 12 random numbers in both NumPy and Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e28d16-5e91-41ed-aaac-4c6c03c757b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9261154 , 0.87774082, 0.87078873, 0.22309476, 0.24575174,\n",
       "       0.04182393, 0.31476305, 0.04599283, 0.62354124, 0.97597454,\n",
       "       0.23923457, 0.81201211])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narr = np.random.rand(12)\n",
    "\n",
    "narr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325b719e-8935-42b1-9f91-a04211f26e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 96 B </td>\n",
       "                        <td> 24 B </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (12,) </td>\n",
       "                        <td> (3,) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 4 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"87\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"120\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"37\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"37\" />\n",
       "  <line x1=\"90\" y1=\"0\" x2=\"90\" y2=\"37\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"37\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,37.56358655585696 0.0,37.56358655585696\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"57.563587\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >12</text>\n",
       "  <text x=\"140.000000\" y=\"18.781793\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,18.781793)\">1</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(12,), dtype=float64, chunksize=(3,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darr = da.from_array(narr, chunks=3)\n",
    "\n",
    "darr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a8d41-3db3-4f65-967d-a7de8a33e51d",
   "metadata": {},
   "source": [
    "The image above shows that the Dask array contains 4 chunks as we set `chunks` to 3. Under the hood, each chunk is a NumPy array in itself.\n",
    "\n",
    "Now, let's consider a much large example. We will create two 10k by 100k array (1 billion elements) and perform element-wise multiplication in both libraries and measure the performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "521050aa-48c9-4a64-91d8-4b7531f34588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the NumPy arrays\n",
    "arr1 = np.random.rand(10_000, 100_000)\n",
    "arr2 = np.random.rand(10_000, 100_000)\n",
    "\n",
    "# Create the Dask arrays\n",
    "darr1 = da.from_array(arr1, chunks=(1_000, 10_000))\n",
    "darr2 = da.from_array(arr2, chunks=(1_000, 10_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef44123-4d25-4c02-8cff-3dea6ad0ac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 966 ms, sys: 2.2 s, total: 3.17 s\n",
      "Wall time: 3.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result_np = np.multiply(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f3b7f3-f635-4684-a032-88a70eb280f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.94 ms, sys: 22 ms, total: 27.9 ms\n",
      "Wall time: 94.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "result_dask = da.multiply(darr1, darr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee718633-a555-4455-bd1d-af4c02875f03",
   "metadata": {},
   "source": [
    "As you can see, Dask is about 34 times faster than NumPy. The performance gains will only be bigger as the computation and array size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf8cb7-6d6a-4e02-9929-59fbf62dab39",
   "metadata": {},
   "source": [
    "Dask uses similar approach of chunking and distributing these chunks across all available cores on your machine for other objects as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51411d-6c2d-4247-96f8-501480e179a3",
   "metadata": {},
   "source": [
    "### Setting Up Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520fe00-0985-42ad-a24d-e957f2e32b45",
   "metadata": {},
   "source": [
    "Like any other library, Dask can be installed in three ways: conda, pip and from source.\n",
    "\n",
    "Since this is an introductory article on Dask, we won't cover the last installation method, as it is for maintainers.\n",
    "\n",
    "If you use Anaconda, Dask is included in your default installation (which is a mark of how popular the library is). If you wish to reinstall or upgrade it, you can use the `install` command:\n",
    "\n",
    "```python\n",
    "conda install dask\n",
    "```\n",
    "\n",
    "The PIP alternative of the above is the following:\n",
    "\n",
    "```python\n",
    "pip install \"dask[complete]\"\n",
    "```\n",
    "\n",
    "Adding the `[complete]` extension also installs the required dependencies of Dask, eliminating the need to install NumPy, Pandas and Tornado manually.\n",
    "\n",
    "You can check if the installation was successful by looking at the library version:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75dfeb9-3d0c-4398-949e-655df2095833",
   "metadata": {},
   "source": [
    "```python\n",
    "import dask\n",
    "\n",
    "dask.__version__\n",
    "```\n",
    "\n",
    "```\n",
    "'2023.5.0'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83316fae-49bf-4c67-8225-ee08ab942305",
   "metadata": {},
   "source": [
    "Most of your time spent working with Dask will be focused on three interfaces: Dask DataFrames, Arrays and Bag. Let's import them to use for the rest of the articlea along with `numpy` and `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e74ead5-977d-4e7b-826c-977859587a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361b9695-259e-4e2f-b52f-de4a99f316f9",
   "metadata": {},
   "source": [
    "### Dask DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c36db8-fc0d-46bf-82d6-a799ef841005",
   "metadata": {},
   "source": [
    "### Dask Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de0c6f-7582-43de-8dd1-f6d7e9a7b1de",
   "metadata": {},
   "source": [
    "### Dask Bags and Dask Delayed for Unstructured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e6d5c9-5eb6-4f1c-afb4-a6ad4a6e6367",
   "metadata": {},
   "source": [
    "### Dask Distributed: Parallel and Distributed Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d8b84-b25a-48fe-bdab-61759db1f4c8",
   "metadata": {},
   "source": [
    "### Best Practices for Using Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6457a7-4b5b-4bf2-9083-0a483993c8f4",
   "metadata": {},
   "source": [
    "### Conclusion and Further Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e78ca-55e4-4170-8877-d995ee22804f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
