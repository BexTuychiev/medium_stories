{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Stochastic Gradient Descent Algorithm in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are trying to find the lowest point among the hills while blindfolded. Since you are limited by your touch, you can only feel the ground immediately around you to determine which way is down. This is essentially what machine learning algorithms do when they are trying to find the best solution to a problem. They frame the problem into a mathematical function whose inputs and outputs represent a hilly surface. Finding the minimum of this function means you've reached the best solution to the problem. One of the most popular algorithms for doing this process is called Stochastic Gradient Descend (SGD).\n",
    "\n",
    "In this tutorial, you will learn everything you should know about the algorithm including:\n",
    "\n",
    "- Initial intuition without the math\n",
    "- The mathematical details\n",
    "- Implementation in Python\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Optimization in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to clear straight away is that stochastic gradient descent (SGD) is not a machine learning algorithm. Rather, it is merely an optimization technique that can be applied _to_ ML algorithms. \n",
    "\n",
    "So, what is optimization? To understand this, let's work our way up from the problem statement stage of machine learning. \n",
    "\n",
    "Let's say we are trying to predict diamond prices based on their carat value (a carat is 0.2 grams). This is a regression problem as the model produces numeric values. \n",
    "\n",
    "To solve the problem, we have a wide range of algorithms at our disposal but let's choose Simple Linear Regression, which has the simple formula of `f(x) = mx + b`. Here:\n",
    "- `b` is the base diamond price\n",
    "- `m` is the price increase per carat\n",
    "- `x` is the carat value of the diamond\n",
    "- `f(x)` is the predicted price of the diamond\n",
    "\n",
    "This linear equation represents our model. Our goal is to find the best values for `m` and `b` that will make our predictions as accurate as possible across all the diamonds in our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had another variable in the picture like diamond volume, our formula would change to `f(x1, x2) = m1*x1 + m2*x2 + b`, where:\n",
    "- `b` is the base diamond price\n",
    "- `m1` is the price increase per carat\n",
    "- `m2` is the price increase per unit volume\n",
    "- `x1` is the carat value of the diamond\n",
    "- `x2` is the volume of the diamond\n",
    "- `f(x)` is the predicted price of the diamond\n",
    "\n",
    "Now, we would need to find the optimal values for `m1, m2`, and `b`. \n",
    "\n",
    "In general, all machine learning models have equations like the ones above with one or more parameters. Thus, the definition of optimization in this context becomes: \"Given this model and this dataset, find the optimal values for the parameters in the equation.\"\n",
    "\n",
    "There are many optimization algorithms that can perform this task, like Stochastic Gradient Descent - the focus of our tutorial. But we fully understand how SGD works, let's go over some fundamental ideas behind it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. The Concept of Error in Machine Learning\n",
    "\n",
    "To understand SGD, we need to learn regular gradient descent algorithm, which shares a lot of the fundamental ideas behind its stochastic version. Simple gradient descent starts with the concept of error in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is an error or loss?\n",
    "ML algorithms usually guess what the correct answer is to a problem. We call this answer a __prediction__ and it is not always accurate. So, we introduce a new term called \"error\" or \"loss\" that represent the difference between the actual answer and the model's prediction. Our goal is to build a model that minimizes this error. \n",
    "\n",
    "Let's make this concrete by going back to the diamond prices prediction example. \n",
    "\n",
    "If our model `f(x)` guesses $10,000 for a diamond that actually costs $12,000, the error is $2000. We should adjust our model to decrease this error.\n",
    "\n",
    "But the model's predictions must be good for any diamond, not just a single one. So, we need a way to combine the error for all diamonds in our dataset. This is where cost functions come in.\n",
    "\n",
    "A cost function combines all individual errors into one number that represents the overall performance of our model. Lower cost means our model's predictions are better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost functions in machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost functions change based on what kind of problem we are solving. \n",
    "\n",
    "In regression problems, the model predicts numeric values like how much a diamond costs or how much time it takes to swim a lap. \n",
    "\n",
    "In classification, the model predicts the category to which something belongs. For example, is a mushroom edible or not, or is the object in the image a cat, dog, or horse?\n",
    "\n",
    "There are other types of problems but the important point is that each problem requires different cost functions. In this tutorial, we will focus on Mean Squared Error (MSE), which is used in regression often. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The difference between the actual values (ground truth) and the model's predictions is called an error or loss. Consequently, a function that combines all these errors or losses is referred to as an _error function_, _loss function_, or _cost function_. Different sources may use these terms interchangeably; this tutorial will use the term _loss function_ from now on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error in regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In regression problems, it is common to see the following graph that plots actual values (ground truth) against model's predictions. \n",
    "\n",
    "MAKE UP A CHART HERE\n",
    "\n",
    "The closer the points are to the straight line, the better model predictions are. Therefore, most regression algorithms try to minimize the average distance from the points to the perfect line. And as we mentioned earlier, the minimization happens using a cost function like Mean Squared Error (MSE).\n",
    "\n",
    "MSE takes the actual and predicted values as inputs and produces the squared average distance to the perfect line. \n",
    "\n",
    "MAKE UP A CHART FOR THE VISUAL INTUITION FOR MSE\n",
    "\n",
    "MSE's popularity as a cost function is due to its simple formula:\n",
    "\n",
    "WRITE THE FORMULA HERE DESCRIBING THE VARIABLES\n",
    "\n",
    "You might be asking \"Why square the differences rather than taking their absolute value?\". The first reason is that it is very easy to find the derivate of a square function. Also, squaring the differences emphasizes bigger errors, penalizing the model for its worst predictions.\n",
    "\n",
    "That's why MSE is preferred to other alternative functions such as Mean Absolute Error (MAE), which on the surface look simpler but is harder to differentiate.\n",
    "\n",
    "SHOW A GRAPH OF MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. The Gradient\n",
    "\n",
    "The next piece in the gradient descent puzzle is the gradient itself. Let's go back to our \"down the hill\" analogy to better understand it. \n",
    "\n",
    "### Gradient as the steepest path\n",
    "\n",
    "We were standing on top of the hill blindfolded and wanted to reach the bottom as quickly as possible. If we poured water at our feet, which way it would flow? It would flow downhill in the direction of the steepest descent. \n",
    "\n",
    "This is exactly what the gradient tells us, but in the opposite direction. The gradient points uphill - in the direction of steepest ascent. When we are trying to minimize the error, we simply go the opposite direction of the gradient to find the quickest way down. \n",
    "\n",
    "Mathematically, gradient tells us how a function's outputs change as we change its inputs. More specifically, it points us in the direction where the function increases most rapidly. In the context of machine learning, where we're typically trying to minimize error using a loss function, the gradient becomes our guide for finding the quickest path to reduce that error.\n",
    "\n",
    "The gradient is represented as a vector - one for each input parameter of our function. Each number in this vector tells us how much the function would change if we made a small adjustment to the corresponding parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to find the gradient of a function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how do you find the gradient of a function? \n",
    "\n",
    "For single variable functions like `f(x) = x ** 2`, the gradient is a derivative of the function, which is given as this vector with one element - `[2x]`. For multi-variable functions like `f(x1, x2) = x1 ** 3 - x2 ** 2`, the gradient contains the partial derivatives of the function with respect to each variable. So, for this example, the gradient is `[3x1 ** 2, 2*x2]`. \n",
    "\n",
    "Our loss function MSE has the following formula:\n",
    "\n",
    "`MSE = (1/n) * Σ(y - f(x))²` where:\n",
    "\n",
    "- `f(x)` is `mx + b`\n",
    "- `m` and `b` are function variables\n",
    "- `x` is the carat value of the diamonds\n",
    "- `n` is the number of data points\n",
    "- `y` is the actual price of diamonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, its gradient is the partial derivatives of `MSE` with respect to `m` and `b`:\n",
    "\n",
    "```python\n",
    "∂/∂m (MSE) = (-2/n) * Σ(x * (y - (mx + b)))\n",
    "∂/∂b (MSE) = (-2/n) * Σ(y - (mx + b))\n",
    "\n",
    "The gradient = [∂/∂m (MSE), ∂/∂b (MSE)]\n",
    "```\n",
    "\n",
    "Don't worry too much about these formulas. The key idea is that they tell us how the mean squared error changes if we change `m` or `b` a tiny bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Gradient Descent: Taking Steps Towards the Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate: controlling our step size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have everything we need to execute gradient descent or in other words, reach the bottom of the hill as efficiently as possible. But do we jump in that direction or take small steps? Well, that's determined by the gradient, isn't it? The size of the gradient tells us how far we go down at each step. \n",
    "\n",
    "But suppose the gradient is so large that instead of reaching the bottom, we shoot over and end up on top of another hill in a single step. This happens surprisingly a lot in gradient descent, so we introduce a parameter called step size, which controls the effects of the gradient. \n",
    "\n",
    "Before taking a step, we simply multiply the gradient by the step size, which lowers its magnitude. For example, if our gradient tells us to take a step of 3.56 downhill, a step size of 0.1 turns it into 0.356, which is much smaller. It takes us longer to reach the bottom but now, we don't run the risk of skipping it altogether. \n",
    "\n",
    "Step size is usually called __learning rate__ in machine learning and typically takes values below 1. 0.001 and 0.3 is a good range to choose from.\n",
    "\n",
    "So, let's see the mathematical version of this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking small steps mathematically\n",
    "\n",
    "First, we give `m` and `b` parameters of our model random values:\n",
    "\n",
    "```python\n",
    "m = 0.215  # Generated randomly\n",
    "b = 0.059\n",
    "```\n",
    "\n",
    "Using these, we calculate the initial MSE on the entire dataset:\n",
    "\n",
    "```python\n",
    "MSE = (1/n) * Σ(y - (0.215 * x + 0.059))² = ...\n",
    "```\n",
    "\n",
    "Now, to lower this error, we need to take a small step in the opposite direction of the gradient or in other words, we need to update `m` and `b` using the gradient and the learning rate:\n",
    "\n",
    "```python\n",
    "m_new = 0.215 - alpha * (∂/∂m (MSE))\n",
    "b_new = 0.059 - alpha * (∂/∂b (MSE))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Most resources choose `alpha` or `α` (the Greek letter) to denote learning rate. \n",
    "\n",
    "After we have new values for `m` and `b`, we calculate MSE again:\n",
    "\n",
    "```python\n",
    "MSE_new = (1/n) * Σ(y - (m_new * x + b_new))²\n",
    "```\n",
    "\n",
    "Now, we calculate the gradient again and continue in this fashion until we reach a stopping condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing when to stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are blindfolded, we can't really see when we have reached the bottom, especially when taking small steps. \n",
    "\n",
    "So, we need some conditions to stop our descent. Typically, these rules are used:\n",
    "\n",
    "- Reaching a pre-determined number of steps (max steps or iterations)\n",
    "- The change in MSE becomes very small after each step (below a pre-defined threshold)\n",
    "- The gradient becoming very close to zero (indicating we're at or near the bottom of the hill)\n",
    "- The MSE starts increasing instead of decreasing\n",
    "\n",
    "These rules are set by you, the ML engineer, when you are performing gradient descent. Python implementations of the algorithm usually have arguments to set these rules and we will see some of them later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and challenges of gradient descent\n",
    "\n",
    "Advantages:\n",
    "- It's a simple and intuitive algorithm\n",
    "- It works well for a wide range of problems\n",
    "- It's computationally efficient for problems with many parameters\n",
    "\n",
    "Challenges:\n",
    "- It can be slow for very large datasets\n",
    "- It can get stuck in local minima for non-convex problems\n",
    "- Choosing the right learning rate can be tricky\n",
    "\n",
    "In the next section, we'll see how Stochastic Gradient Descent addresses some of these challenges, particularly for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "A. The problem with regular gradient descent for large datasets\n",
    "B. The stochastic approach: Randomness to the rescue\n",
    "C. How SGD differs from regular gradient descent\n",
    "1. Using one sample at a time\n",
    "2. Faster but noisier progress\n",
    "D. The math behind SGD\n",
    "1. Stochastic cost function\n",
    "2. Stochastic gradient\n",
    "3. Parameter updates in SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem with regular gradient descent\n",
    "\n",
    "While gradient descent is one of the most elegant optimization algorithms out there, it has a significant disadvantage when dealing with large datasets. Remember that in each step, we calculate the gradient using all the data points in our dataset:\n",
    "\n",
    "```python\n",
    "∂/∂m (MSE) = (-2/n) * Σ(x * (y - (mx + b)))\n",
    "∂/∂b (MSE) = (-2/n) * Σ(y - (mx + b))\n",
    "```\n",
    "\n",
    "where `x` and `y` are arrays containing all the carat values and actual prices of diamonds. This meant that we'd be using every single diamond's information to update parameters in each step. \n",
    "\n",
    "As you can imagine, this becomes computationally expensive and time-consuming when we have millions of data points. In the era of big data, this limitation can make regular gradient descent impractical for many real-world machine learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The stochastic approach: introducing randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Stochastic\" means \"randomly determined\" and that's exactly what SGD does: it introduces randomness into our optimization process.\n",
    "\n",
    "Instead of using all data points to calculate the gradient, SGD randomly selects one data point at each step. It uses this single point to calculate an estimate of the gradient and update the parameters.\n",
    "\n",
    "Because SGD is only looking at one data point at a time, it can make updates to the parameters much more frequently. This allows it to traverse the error surface (the hill) more quickly, especially for large datasets. \n",
    "\n",
    "However, this speed comes at a cost. Since we're using a single data point to estimate the gradient of the entire dataset, our estimates are much noisier. This means our path down the error surface is less smooth and more erratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The math behind Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform SGD, we first define a __stochastic cost function__. \n",
    "\n",
    "Instead of calculating the Mean Squared Error over all data points, we now look at the squared error for a single, randomly chosen point:\n",
    "\n",
    "```py\n",
    "Cost = (y - f(x))²\n",
    "```\n",
    "\n",
    "where `y` is the actual price of the randomly chosen diamond, and `f(x)` is our predicted price for that diamond.\n",
    "\n",
    "Then, we calculate the stochastic gradient of this cost function with respect to our parameters `m` and `b`:\n",
    "\n",
    "```py\n",
    "∂/∂m (Cost) = -2x(y - (mx + b))\n",
    "∂/∂b (Cost) = -2(y - (mx + b))\n",
    "\n",
    "Stochastic gradient = [∂/∂m (Cost), ∂/∂b (Cost)]\n",
    "```\n",
    "\n",
    "Using this stochastic gradient, we update our parameters in the same fashion as regular gradient descent:\n",
    "\n",
    "```py\n",
    "m_new = m_old - learning_rate * ∂/∂m (Cost)\n",
    "b_new = b_old - learning_rate * ∂/∂b (Cost)\n",
    "```\n",
    "\n",
    "The key idea in SGD is that taking each step involves a single randomly chosen data point in each step. The rules for when to stop the descent stays the same as regular gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. SGD in Action: A Walkthrough Example\n",
    "\n",
    "A. Setting up a simple problem: Linear regression\n",
    "B. Implementing SGD step by step\n",
    "C. Visualizing the progress of SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Practical Considerations and Variations\n",
    "\n",
    "A. Choosing the learning rate\n",
    "B. Mini-batch gradient descent: A middle ground\n",
    "C. Dealing with noisy updates\n",
    "D. When to use SGD vs. regular gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Real-World Applications of SGD\n",
    "A. Large-scale machine learning problems\n",
    "B. Deep learning and neural networks\n",
    "C. Online learning scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Conclusion\n",
    "A. Recap of key concepts\n",
    "B. The power and limitations of SGD\n",
    "C. Encouragement for further exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
