{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio-worthy Computer Vision Projects From Beginner to Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Due to the unprecedented amount of image and video data in today's surveillance and social media world, computer vision engineers are in constant hot demand. They build everything from your iPhone's infallible Face ID to models that classify stars in out space. \n",
    "\n",
    "But before you can reach those levels, you have to practice and get your hands dirty. And the best way to do that is through completing projects that resemble real-world problems. In this article, we will list 15 such project ideas divided by complexity level and the tools you need to make each one a success.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Components of a Good Computer Vision Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good portfolio-worthy computer vision project that can capture recruiters' attention typically have these three components in common:\n",
    "- Technical depth and complexity\n",
    "- Real-world applicability\n",
    "- End-to-end implementation\n",
    "\n",
    "Let's elaborate on each of these components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a vision project, you must demonstrate a strong understanding of CV concepts and techniques. These include:\n",
    "- __Algorithms__: Implementations of classic to state-of-the-art algorithms for solving problems\n",
    "- __Model architecture__: Design and implementation of neural network architectures and correct use of custom layers or loss functions\n",
    "- __Data processing__: Adequate data preprocessing, image augmentation and handling techniques.\n",
    "- __Performance optimization__: Techniques for improving model accuracy, reducing computational complexity, or enhancing inference speed.\n",
    "- __Handling challenges__: Addressing common CV challenges such as variations in lighting, scale, or occlusion.\n",
    "\n",
    "The depth of your technical skills must be evident in the code, documentation and project write-up, showcasing your professional approach to solving real-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world applicability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This component is key because it demonstrates the practical value of your skills. A project with clear real-world use shows that you can bridge the gap between knowledge gained in courses and industry needs. Here are some important aspects:\n",
    "- Solving a painful need or problem in a specific industry or domain\n",
    "- Using large-scale real-world datasets or collecting your own\n",
    "- Considering practical constraints such as computational costs, budget limits and real-time processing requirements\n",
    "\n",
    "For example, faulty product detection in a conveyer belt in a plant or a medical image analysis tool for early disease detection would have clear real-world applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the most important aspect of a CV project is whether it is a complete functional solution or not. This means that you can't put up a model trained inside Jupyter on GitHub and call it a day. The project repository must contain the following important parts:\n",
    "\n",
    "1. __Data pipeline__\n",
    "- Data collection or dataset selection\n",
    "- Data preprocessing and cleaning\n",
    "- Data augmentation and normalization\n",
    "- Efficient data loading and batching\n",
    "\n",
    "2. __Model development__\n",
    "- Model architecture design or selection\n",
    "- Training and validation process\n",
    "- Hyperparameter tuning\n",
    "- Model evaluation and performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Deployment and interface__\n",
    "- Creating a user interface (web app, mobile app, or desktop application)\n",
    "- Implementing real-time processing if applicable\n",
    "- Handling input from various sources (e.g., uploaded images, camera feed)\n",
    "- Visualizing results effectively\n",
    "\n",
    "4. __Documentation and presentation__\n",
    "- Clear explanation of the problem and solution approach\n",
    "- Documentation of the codebase\n",
    "- Analysis of results and performance\n",
    "- Discussion of limitations and potential improvements\n",
    "\n",
    "5. __Version control and reproducibility__\n",
    "- Using Git for version control\n",
    "- Providing clear instructions for setting up and running the project\n",
    "- Managing dependencies (e.g., using virtual environments or containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to deliver a complete, usable solution is a highly valuable trait in the industry. So, ensure any future or existing projects meet the above-mentioned requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Find Good Datasets For Computer Vision Projects?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The success of computer vision projects largely depends on the dataset used. Therefore, your chosen dataset must align with the three core components of CV projects. With that said, there are dozens of places you can look for finding good open-source datasets. Here are some established sources:\n",
    "\n",
    "1. __Public Dataset Repositories__:\n",
    "\n",
    "- [Kaggle Datasets](https://www.kaggle.com/datasets)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
    "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
    "- [Papers With Code Datasets](https://paperswithcode.com/datasets)\n",
    "- [AWS Open Data Registry](https://registry.opendata.aws)\n",
    "\n",
    "\n",
    "2. __Domain-Specific Repositories__:\n",
    "\n",
    "- Medical Imaging: [The Cancer Imaging Archive (TCIA)](https://www.cancerimagingarchive.net/), [MICCAI challenges](https://miccai.org/index.php/special-interest-groups/challenges/miccai-registered-challenges/)\n",
    "- Autonomous Driving: [KITTI](https://www.cvlibs.net/datasets/kitti/), [Cityscapes](https://www.cityscapes-dataset.com/), nuScenes\n",
    "- Facial Analysis: [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html), [LFW (Labeled Faces in the Wild)](https://vis-www.cs.umass.edu/lfw/)\n",
    "- Object Detection: [COCO](https://cocodataset.org/#home), [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/), [Open Images](https://storage.googleapis.com/openimages/web/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Academic Sources__:\n",
    "\n",
    "- Look for datasets mentioned in recent research papers in your area of interest\n",
    "- Check conference websites (e.g., CVPR, ICCV, ECCV) for dataset challenges\n",
    "\n",
    "\n",
    "4. __Government and Non-Profit Organizations__:\n",
    "\n",
    "- [NASA Earth Data](https://earthdata.nasa.gov)\n",
    "- [NOAA Data](https://data.noaa.gov/onestop/)\n",
    "- [WHO Data Collections](https://www.who.int/data/collections)\n",
    "\n",
    "\n",
    "5. __Creating Custom Datasets__:\n",
    "\n",
    "- Web scraping (ensure you comply with legal and ethical guidelines)\n",
    "- Data collection using sensors or cameras\n",
    "- Synthetic data generation using tools like Unity or Blender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, your chosen dataset must:\n",
    "- Be relevant to your project idea\n",
    "- Be large enough to train a robust model\n",
    "- Be diverse to represent various scenarios and conditions\n",
    "- Have a suitable license for your intended use (commercial, research)\n",
    "- Be up-to-date\n",
    "- Be well-documented\n",
    "\n",
    "By considering these factors, you ensure the final delivered solution is robust and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginner Computer Vision Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's explore some project ideas starting with the beginner level. In this level, most projects are related to classification or detection techniques such as face emotion recognition or whether an object is in the image or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Face Mask Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Three women wearing masks](images/masks.png)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/code/nageshsingh/mask-and-social-distancing-detection-using-vgg19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first project we have is developing a computer vision system for detecting face masks. This project is an excellent fit because it addresses a recent real-world problem (remember COVID?), showing your ability to adapt CV technologies to current issues. It lets you work on two popular sub-domains of CV: object detection and facial analysis. \n",
    "\n",
    "If you develop a real-time detection system, it will be a huge bonus to the project as it demonstrates your skills performance optimization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset to use__: [Face Mask Detection Dataset on Kaggle](https://www.kaggle.com/datasets/andrewmvd/face-mask-detection/code?datasetId=667889&sortBy=voteCount)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Load and preprocess the dataset\n",
    "2. Build a CNN model using TensorFlow or PyTorch\n",
    "3. Train the model on the dataset\n",
    "4. Implement real-time detection using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Traffic Signs Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A Collage of Traffic Signs](images/traffic_signs.jpg)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next project is classifying traffic signs using a standard benchmark dataset. This project is valuable as it has direct applications in autonomous driving, a cutting-edge field. It also shows your image classification skills, a fundamental CV task. \n",
    "\n",
    "You can get started on this project with a bit of guidance through this [Datalab project](https://www.datacamp.com/projects/2274)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset to use__: [German Traffic Signs Recognition Benchmark (GTSRB) Dataset on Kaggle](https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Load and preprocess the GTSRB dataset\n",
    "2. Design a CNN architecture\n",
    "3. Train and validate the model\n",
    "4. Create a simple UI for testing with new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plant Disease Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A collection of diseased plant images](images/plant_diseases.png)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/code/abdoashraf90/plantvillage-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we have another multi-class classification project. This time, you should develop a CV application for detecting diseased plants based on the images of their leaves. It is recommended to use a pre-trained model like ResNet to improve the accuracy of your solution. This also shows your transfer learning abilities, which is crucial in many CV tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Dataset to use__: [Plant Village Dataset on Kaggle](https://www.kaggle.com/datasets/emmarex/plantdisease/data)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Load and augment the dataset\n",
    "2. Use transfer learning with a pre-trained model like ResNet\n",
    "3. Fine-tune the model on the plant disease dataset\n",
    "4. Build a web application for plant disease diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optical Character Recognition (OCR) for Handwritten Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A handwritten chunk of text](images/handwritten.png)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/datasets/naderabdalghani/iam-handwritten-forms-dataset/data)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [IAM Handwritten Forms Dataset on Kaggle](https://www.kaggle.com/datasets/naderabdalghani/iam-handwritten-forms-dataset/data)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Preprocess and segment the handwritten text images\n",
    "2. Implement a CNN-LSTM architecture\n",
    "3. Train the model on the IAM dataset\n",
    "4. Create a simple application for recognizing handwritten text from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Facial Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Three types of faces with labels on them](images/faces.png)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/datasets/msambare/fer2013/data)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [FER-2013 dataset](https://www.kaggle.com/datasets/msambare/fer2013/data)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Preprocess the FER-2013 dataset\n",
    "2. Design a CNN for emotion classification\n",
    "3. Train and optimize the model\n",
    "4. Implement real-time emotion recognition using a webcam feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Honey Bee Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A bee on a flower](images/bee.jpg)\n",
    "\n",
    "__Description__: [DataCamp project](https://datacamp.com/projects/555)\n",
    "\n",
    "__Dataset to use__: [Naive Bees: Deep Learning With Images Project](https://datacamp.com/projects/555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Clothing Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![An image of multiple items of clothing](images/clothing_classification.png)\n",
    "\n",
    "[Image source](https://datacamp.com/projects/2059)\n",
    "\n",
    "__Description__: DataCamp project\n",
    "\n",
    "__Dataset to use__: [E-Commerce Clothing Classification Project](https://datacamp.com/projects/2059)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Food Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![An image of spaghetti](images/food.png)\n",
    "\n",
    "[Image source: DataCamp](https://datacamp.com/projects/2393)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [Food Images Classification With HuggingFace Project](https://datacamp.com/projects/2393)\n",
    "\n",
    "__High-level implementation steps__: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Computer Vision Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Multi-object Tracking in Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![An image with multiple objects annotated](images/mot.png)\n",
    "\n",
    "[Image source: Papers With Code](https://paperswithcode.com/task/multi-object-tracking)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [Multiple Object Tracking (MOT) Benchmark Challenge Dataset](https://motchallenge.net/)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Implement object detection using YOLO or Faster R-CNN\n",
    "2. Apply a tracking algorithm like SORT or DeepSORT\n",
    "3. Optimize for real-time performance\n",
    "4. Visualize tracking results on video streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Image Captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image from the COCO dataset homepage](images/coco.jpg)\n",
    "\n",
    "[Image source: COCO Homepage](https://cocodataset.org/#home)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [Common Objects in Context (COCO) Dataset](https://cocodataset.org/#home)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Use a pre-trained CNN (e.g., ResNet) for image feature extraction\n",
    "2. Implement an LSTM or Transformer for caption generation\n",
    "3. Train the model end-to-end on the COCO dataset\n",
    "4. Create a web interface for uploading and captioning new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. 3D Object Reconstruction From Multiple Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Various objects from different angles from the ShapeNet dataset](images/shapenet.png)\n",
    "\n",
    "[Image source: Papers With Code](https://paperswithcode.com/dataset/shapenet)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [ShapeNet Dataset](https://paperswithcode.com/dataset/shapenet)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Implement a multi-view stereo algorithm\n",
    "2. Use a 3D convolutional network for volumetric reconstruction\n",
    "3. Train and optimize the model on ShapeNet\n",
    "4. Develop a tool for reconstructing 3D objects from uploaded images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Gesture Recognition For Human-Computer Interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![An image of a thumbs up](images/handgesture.webp)\n",
    "\n",
    "[Image source](https://datadrivenscience.com/wp-content/uploads/2023/06/handgesture.png)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: Collect your own using a depth camera (e.g., Kinect)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Collect and annotate a custom gesture dataset\n",
    "2. Implement skeleton extraction from depth data\n",
    "3. Design an LSTM or GRU network for gesture classification\n",
    "4. Create a demo application controlling a computer interface with gestures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Visual Question Answering (VQA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Visual Question Answering Dataset (VQA)](images/vqa_examples.jpg)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [Visual Question Answering (VQA) Dataset](https://visualqa.org/)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Implement image feature extraction using a pre-trained CNN\n",
    "2. Design a text processing pipeline for questions\n",
    "3. Create a fusion network combining image and text features\n",
    "4. Train on the VQA dataset and build a demo interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Insurance Code Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A team of data entry specialists](images/digitizing_team.png)\n",
    "\n",
    "__Description__: DataCamp project\n",
    "\n",
    "__Dataset to use__: [Implementing Multi-input OCR System Project](https://projects.datacamp.com/projects/2215)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Computer Vision Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Image Deblurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A blurred image](images/deblur.jpg)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/datasets/jishnuparayilshibu/a-curated-list-of-image-deblurring-datasets/code?datasetId=3055596&sortBy=voteCount)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [A Curated List of Image Deblurring Datasets](https://www.kaggle.com/datasets/jishnuparayilshibu/a-curated-list-of-image-deblurring-datasets)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Data preparation and processing\n",
    "2. Developing a multi-scale CNN or GAN model\n",
    "3. Implement various evaluation metrics such as Peak Signal-to-Noise Ratio (PSNR)\n",
    "4. Optimize the model for inference speed; create and deploy use-friendly web application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Video Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/summe.png)\n",
    "\n",
    "[Image source](https://media.springernature.com)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [SumMe Dataset](https://paperswithcode.com/dataset/summe)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Implement shot boundary detection\n",
    "2. Design a feature extraction pipeline for video frames\n",
    "3. Create a sequence-to-sequence model for frame importance scoring\n",
    "4. Develop a user interface for uploading videos and generating summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Face De-Aging/Aging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/aging.png)\n",
    "\n",
    "[Image source: DEX paper](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [IMDB-WIKI dataset](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Preprocess and clean the IMDB-WIKI dataset\n",
    "2. Implement a cycle-consistent GAN architecture\n",
    "3. Train the model to perform age transformation\n",
    "4. Create a web application for uploading and aging/de-aging faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Human Pose Estimation And Action Recognition in Crowded Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/posetrack.gif)\n",
    "\n",
    "[Image source: PoseTrack.net](https://posetrack.net/)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [PoseTrack dataset](https://paperswithcode.com/dataset/posetrack)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Implement multi-person pose estimation (e.g., OpenPose)\n",
    "2. Design a temporal convolutional network for action recognition\n",
    "3. Train and optimize the model on PoseTrack\n",
    "4. Develop a system for real-time pose estimation and action recognition in videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Unsupervised Anomaly Detection in Industrial Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/anomalies.png)\n",
    "\n",
    "[Image source: Kaggle](https://www.kaggle.com/datasets/ipythonx/mvtec-ad)\n",
    "\n",
    "__Description__: \n",
    "\n",
    "__Dataset to use__: [MVTec Anomaly Detection Dataset](https://www.kaggle.com/datasets/ipythonx/mvtec-ad)\n",
    "\n",
    "__High-level implementation steps__: \n",
    "\n",
    "1. Implement an autoencoder architecture for normal sample reconstruction\n",
    "2. Train the model on normal samples only\n",
    "3. Develop an anomaly scoring mechanism based on reconstruction error\n",
    "4. Create a demo for uploading industrial images and highlighting anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
