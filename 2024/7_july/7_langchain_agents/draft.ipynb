{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LangChain Agents to Automate Tasks in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ conda create -n langchain python=3.9 -y\n",
    "$ conda activate langchain\n",
    "$ pip install langchain langchain_openai langchain_community ipykernel python-dotenv\n",
    "$ ipython kernel install --user --name=langchain\n",
    "```\n",
    "\n",
    "```bash\n",
    "$ touch .env \n",
    "$ vim .env  # Paste your OPENAI key\n",
    "```\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Many people consider Lionel Messi to be one of the greatest footballers of all time. He has won numerous individual and team awards, broken multiple records, and has consistently performed at a high level for both club and country. However, the title of \"best footballer of all time\" is subjective and there are many other players who have also been considered for this title, such as Diego Maradona, Pele, and Cristiano Ronaldo. Ultimately, it is a matter of personal opinion.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=api_key)\n",
    "\n",
    "question = \"Is Messi the best footballer of all time?\"\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are a dreamy poet. Compose a poem on Qur'an.\")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"You are a dreamy poet. Compose a poem on {subject}.\"\n",
    "\n",
    "prompt_template = PromptTemplate(template=template, input_variables=['subject'])\n",
    "\n",
    "prompt_template.invoke({\"subject\": \"Qur'an\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nOh Qur'an, divine scripture of light\\nRevealed to guide us through the darkest night\\nWords of wisdom, peace and truth\\nA treasure trove for our hearts to soothe\\n\\nIn your pages, the secrets of the universe unfold\\nGuiding us towards a path of gold\\nWith every verse, our souls are elevated\\nAnd our hearts are humbled, and hearts elated\\n\\nYour words are like honey, sweet to the soul\\nHealing our wounds and making us whole\\nWith every recitation, our hearts are cleansed\\nAnd our faith in Allah is strengthened and fenced\\n\\nYou are the guidance for all of mankind\\nIn your verses, the answers we shall find\\nA beacon of light in a world of darkness\\nYour beauty and wisdom, forever timeless\\n\\nOh Qur'an, you are a gift from above\\nSent down with mercy and endless love\\nYour words, a source of solace and peace\\nIn every hardship, our hearts find release\\n\\nWe hold you close, oh holy book\\nIn your embrace, our souls find hook\\nFor in your pages, we find tranquility\\nAnd the promise of eternal felicity\\n\\nOh Qur'an, you are our guiding star\\nIn this life and the hereafter, you are never far\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = prompt_template | llm\n",
    "\n",
    "llm_chain.invoke({'subject': \"Qur'an\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a master procrastinator.\"),\n",
    "        (\"human\", \"Why do you do this?\"),\n",
    "        (\"ai\", \"I have no idea\"),\n",
    "        (\"human\", \"Respond to this question: {question}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "llm_chain = prompt_template | llm\n",
    "question = \"Why do you procrastinate?\"\n",
    "\n",
    "response = llm_chain.invoke({'question': question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I procrastinate because I tend to prioritize short-term gratification over long-term goals, leading me to delay important tasks until the last minute.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing chat model memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_ai_message('Hi, ask me anything on football.')\n",
    "history.add_user_message('Describe a metaphor for football that goes beyond human thought.')\n",
    "\n",
    "response = llm.invoke(history.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Football is like a symphony of chaos, with players moving in perfect harmony to create a masterpiece of skill, strategy, and emotion that transcends the limitations of the human mind.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ConversationChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationSummaryMemory\n\u001b[1;32m      3\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationSummaryMemory(llm\u001b[38;5;241m=\u001b[39mChatOpenAI(openai_api_key\u001b[38;5;241m=\u001b[39mapi_key))\n\u001b[0;32m----> 5\u001b[0m summary_chain \u001b[38;5;241m=\u001b[39m \u001b[43mConversationChain\u001b[49m(llm\u001b[38;5;241m=\u001b[39mllm, memory\u001b[38;5;241m=\u001b[39mmemory, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ConversationChain' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=ChatOpenAI(openai_api_key=api_key))\n",
    "\n",
    "summary_chain = ConversationChain(llm=llm, memory=memory, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "\n",
    "destination_prompt = PromptTemplate(\n",
    "    input_variables=['destination'],\n",
    "    template='I am planning a trip to {destination}. Can you suggest some activities to do there?'\n",
    ")\n",
    "\n",
    "activities_prompt = PromptTemplate(\n",
    "    input_variables=['activities'],\n",
    "    template='I only have one day, so you can create an itinerary from your top three activities: {activities}'\n",
    ")\n",
    "\n",
    "seq_chain = ({\"activities\": destination_prompt | llm | StrOutputParser() } \n",
    "                           | activities_prompt \n",
    "                           | llm \n",
    "                           | StrOutputParser()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Have a great time exploring all that Tashkent has to offer!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_chain.invoke({'destination': 'tashkent'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an error in this crap. Fix it tomorrow, bex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
