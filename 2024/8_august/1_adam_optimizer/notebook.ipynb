{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAM Optimizer Tutorial: Intuition And Implementation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever tried navigating your way down a hilly area blindfolded? That's somewhat analogous to what machine learning models do when they are trying to improve. They continually search for the lowest point (best solution) without really seeing the whole picture. This is where optimization algorithms come in handy, and ADAM is like the smart flashlight in this journey. \n",
    "\n",
    "ADAM, short for Adaptive Moment Estimation, is a popular optimization technique, especially in deep learning. In this article, you'll see why this is the case. We will cover the intuition behind it, dive into some math (don't worry, we will keep it friendly), its Python implementation and how to use it in PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is ADAM Optimizer? The Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Optimization in Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
