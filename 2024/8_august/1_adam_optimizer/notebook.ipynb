{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADAM Optimizer Tutorial: Intuition And Implementation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever tried navigating your way down a hilly area blindfolded? That's somewhat similar to what machine learning models do when they are trying to improve. They continually search for the lowest point (best solution) without really seeing the whole picture. This is where optimization algorithms come in handy, and ADAM is like a smart flashlight in this journey. \n",
    "\n",
    "ADAM, short for Adaptive Moment Estimation, is a popular optimization technique, especially in deep learning. In this article, you'll see why this is the case. We will cover the intuition behind it, dive into some math (don't worry, we will keep it friendly), its Python implementation and how to use it in PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is ADAM Optimizer? The Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The popular optimization algorithm used in machine learning and, most often, in deep learning is called ADAM, which stands for Adaptive Moment Estimation. \n",
    "\n",
    "ADAM combines ideas from two other robust optimization techniques: momentum and RMSprop. It is named _adaptive_ as it adjusts the learning rate for each parameter. \n",
    "\n",
    "Here are its key features and advantages:\n",
    "\n",
    "- Adaptivity: ADAM adapts the learning rate for each parameter, which can speed up learning in many cases.\n",
    "- Momentum: It uses a form of momentum, helping it navigate complex surfaces such as ravines and saddle points more effectively.\n",
    "- Bias correction: ADAM includes bias correction terms, which help it perform well even in the initial stages of training.\n",
    "- Computational efficiency: It's relatively computationally efficient and has low memory requirements.\n",
    "- Hyperparameter robustness: While the learning rate may need tuning, ADAM is often less sensitive to hyperparameter choices than some other optimizers.\n",
    "\n",
    "To summarize, ADAM makes models learn more efficiently by continuously adjusting the learning rate of each parameter and, as a consequence, tends to converge much more quickly than standard stochastic gradient descent. For many deep learning applications, it is therefore a strong default choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADAM unifies key ideas from a few other critical optimization algorithms, strengthening their advantages while also addressing their shortcomings. We will need to review them before we can grasp the intuition behind ADAM and implement it in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Analogy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the intuition of these optimization algorithms, let's continue our analogy from the introduction. Imagine you are blindfolded in a complicated, hilly region. You have been tasked to find the lowest point in this terrain. The hilliness of the terrain represents the loss function of a machine learning model. The overall \"lowest\" (global minimum) point is the optimal solution to the system. \n",
    "\n",
    "Now let's connect some dots: Your current position in the terrain represents the current state of the model's parameters. The height at any point represents the loss value for those parameters. The way you are navigating also corresponds to adjusting the model's parameters in the mathematical sense.\n",
    "\n",
    "Every optimization algorithm functions like a strategy to navigate the landscape of this problem successfully, guiding the solver on where to step next and how large those steps should be. Some algorithms scan the entire area before deciding on a next move, while others rely on limited information to be faster. Still other algorithms use tools like momentum and step-size adaptation: a good solver knows when to push its way through a problem and when to ease up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent is the holy grail of optimization in machine learning, as it sets the foundation many algorithms build upon. \n",
    "\n",
    "If you use Gradient Descent (GD), at each step, you carefully feel the entire area around you (using the full dataset). This thorough examination allows you to make very accurate decisions about which way is downhill, but it takes a lot of time. You always move in the direction of steepest descent, which means you'll consistently move towards lower ground. However, if you reach a small depression (local minimum), you might get stuck there, unable to detect that there's an even lower point elsewhere.\n",
    "\n",
    "Key features of GD:\n",
    "- Uses the entire dataset for each step\n",
    "- Consistent, but potentially slow\n",
    "- Can get stuck in local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It Starts With SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This article assumes you are familiar with the fundamental optimization algorithm, Gradient Descent (GD) and its more popular variant, Stochastic Gradient Descent (SGD). Both play crucial roles in understanding ADAM, the reason for its invention and how to implement it in Python. If you are completely new, we have written a [separate article](https://www.datacamp.com/tutorial/stochastic-gradient-descent) explaining both regular and stochastic gradient descent.\n",
    "\n",
    "In any case, in this section, we will go through a basic Python implementation of SGD as a kind of background for what we will do in the next sections. \n",
    "\n",
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the Diamonds dataset from Seaborn, take a sample from it and build the feature and target arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "dataset_size = 10_000\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "\n",
    "# Extract the target and the feature\n",
    "xy = diamonds[[\"carat\", \"price\"]].values\n",
    "np.random.shuffle(xy)  # Shuffle the data\n",
    "xy = xy[:dataset_size]\n",
    "\n",
    "xy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are setting up a basic regression problem - given diamond carats (their weight), predict their price. \n",
    "\n",
    "Now, let's split the data to create training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "np.random.shuffle(xy)\n",
    "\n",
    "train_size = int(0.8 * dataset_size)\n",
    "train_xy, test_xy = xy[:train_size], xy[train_size:]\n",
    "\n",
    "train_xy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the task, we have a range of models at our disposal, but to keep things simple, we will chose Linear Regression and define it as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(m, x, b):\n",
    "    \"\"\"\n",
    "    Simple Linear Regression: f(x) = m * x + b, where\n",
    "    - x: diamond carat\n",
    "    - m: price increase per carat\n",
    "    - b: base diamond price\n",
    "    - f(x): predicted diamond price\n",
    "    \"\"\"\n",
    "    \n",
    "    return m * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Linear Regression model has only two parameters, `m` and `b`, so the task for SGD (and later, for ADAM) is to find optimal values for them. \n",
    "\n",
    "We should also define the loss function, Mean Squared Error, which will be used by SGD for optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    MSE as a loss function. It is defined as:\n",
    "\n",
    "    Loss = (1/n) * Σ((y - f(x))²), where:\n",
    "    - n: the length of the dataset\n",
    "    - y: the true diamond price\n",
    "    - f(x): predicted diamond price, i.e. m*x + b\n",
    "    \"\"\"\n",
    "\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a function called `stochastic_gradient_descent` that accepts six arguments:\n",
    "\n",
    "- `x` and `y` represent the single feature and target in our problem\n",
    "- `epochs` denotes how many times we want to perform the descent (more on this later)\n",
    "- `learning_rate` is the step size\n",
    "- `batch_size` to control how frequently we make parameter updates\n",
    "- `stopping_threshold` sets the minimum value the loss should decrease at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(\n",
    "    x, y, epochs=100, learning_rate=0.01, batch_size=32, stopping_threshold=1e-6\n",
    "):\n",
    "    \"\"\"\n",
    "    SGD with support for mini-batches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the model parameters randomly\n",
    "    m = np.random.randn()\n",
    "    b = np.random.randn()\n",
    "    n = len(x)  # The number of data points\n",
    "    previous_loss = np.inf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the function, we first initialize the parameters we want to optimize with random values. We also set initial loss to infinity, representing the unsolved state of our problem.\n",
    "\n",
    "Then, we start a `for` loop that runs for `epochs` iterations. Inside the loop, we shuffle the data to prevent learning order-dependent patters in the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        # Shuffle the data\n",
    "        indices = np.random.permutation(n)\n",
    "        x = x[indices]\n",
    "        y = y[indices]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we start another loop controlled by the `batch_size` parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        ...\n",
    "        for j in range(0, n, batch_size):\n",
    "            # Extract the current batch\n",
    "            x_batch = x[j:j + batch_size]\n",
    "            y_batch = y[j:j + batch_size]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside this inner loop, we calculate the gradients (partial derivatives) for both parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        ...\n",
    "        for j in range(0, n, batch_size):\n",
    "            # Extract the current batch\n",
    "            ...\n",
    "            # Compute the negative gradients\n",
    "            y_pred = model(m, x_batch, b)  # Make predictions with current m and b\n",
    "            m_gradient = -2 * np.mean(x_batch * (y_batch - y_pred))\n",
    "            b_gradient = -2 * np.mean(y_batch - y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have the gradients, we update the parameters using the learning rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        ...\n",
    "        for j in range(0, n, batch_size):\n",
    "            # Extract the current batch\n",
    "            ...\n",
    "            # Compute the negative gradients\n",
    "            ...\n",
    "            # Update the model parameters\n",
    "            m -= learning_rate * m_gradient\n",
    "            b -= learning_rate * b_gradient\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, under the parent loop, we calculate the loss for the current epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        ...\n",
    "        for j in range(0, n, batch_size):\n",
    "            # Extract the current batch\n",
    "            ...\n",
    "            # Compute the negative gradients\n",
    "            ...\n",
    "            # Update the model parameters\n",
    "            ...\n",
    "        # Compute the epoch loss\n",
    "        y_pred = model(m, x, b)\n",
    "        current_loss = loss(y, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the epoch loss is smaller than the `stopping_threshold`, we stop the entire process:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        ...\n",
    "        for j in range(0, n, batch_size):\n",
    "            # Extract the current batch\n",
    "            ...\n",
    "            # Compute the negative gradients\n",
    "            ...\n",
    "            # Update the model parameters\n",
    "            ...\n",
    "        # Compute the epoch loss\n",
    "        ...\n",
    "        # Check against the stopping threshold\n",
    "        if previous_loss - current_loss < stopping_threshold:\n",
    "            break\n",
    "        previous_loss = current_loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end (after epochs run out or the stopping threshold is met), we return `m` and `b` which are now optimized:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def stochastic_gradient_descent(...):\n",
    "    ...\n",
    "    for i in range(epochs):\n",
    "        ...\n",
    "        for j in range(0, n, batch_size):\n",
    "            # Extract the current batch\n",
    "            ...\n",
    "            # Compute the negative gradients\n",
    "            ...\n",
    "            # Update the model parameters\n",
    "            ...\n",
    "        # Compute the epoch loss\n",
    "        ...\n",
    "        # Check against the stopping threshold\n",
    "        ...\n",
    "    return m, b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I’ve pasted the entire code into [this GitHub gist](https://gist.github.com/BexTuychiev/645dcd35ef12dad323b6c0182f29be74) so that you can look at the whole picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD With Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, ADAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
