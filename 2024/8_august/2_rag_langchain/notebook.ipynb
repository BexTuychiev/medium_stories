{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Tutorial on Building a RAG Application Using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the amount of information today's LLMs have access is growing constantly, there are mounds of private data not included in their training. For this reason, one of the most popular applications of LLMs in enterprise settings is retrieval-augmented generation (RAG). When you design a RAG system, you retrieve information from a private data source and feed it to a language model to generate contextually relevant responses. \n",
    "\n",
    "In this tutorial, you will learn how to develop RAG applications using a massively popular framework - LangChain. I'll guide you through the process step-by-step, from setting up your environment to implementing the core components of a RAG system. By the end of this tutorial, you'll have created your own chatbot capable of answering questions using any outside source, opening up a world of possibilities for leveraging private data in your AI applications.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is RAG?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clarify what RAG is, let's consider a simle example.\n",
    "\n",
    "A first-year college student, Chandler, is consider to skip a few classes but wants to ensure he isn't violating the university attendance policy. Like with anything these days, he asks ChatGPT the question.\n",
    "\n",
    "Of course, ChatGPT can't answer it. The chatbot isn't dumb - it just doesn't have access to Chandler's university documents. So, Chandler finds the policy document himself and discovers that it is a long, technical read he doesn't want to wade through.\n",
    "\n",
    "Instead, he gives the entire document to ChatGPT this time and asks the question again. This time, he gets his answer. \n",
    "\n",
    "This is an individual case of retrieval augmented generation. The language model's answer (generation) is augmented (enriched) by context retrieved from a source not part of its original training. \n",
    "\n",
    "A scalable version of a RAG system would be able to answer any student question by searching university documents itself, finding the relevant ones and retrieving chunks of text that most likely contain the answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of a RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Workflow to Building a RAG App in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
