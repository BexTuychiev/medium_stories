{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started With OpenAI Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In August, 2024, OpenAI announced a powerful new feature in their APIâ€”Structured Outputs. With this feature, as the name suggests, you can ensure LLMs will generate responses only in a format you specify. This capability will make it significantly easier to build applications that require precise data formatting. In this tutorial, you will learn how to get started with this Structured Outputs, understand its new syntax and explore its key applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Structured Outputs in AI Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deterministic responses, or in other words, responses in consistent formatting is crucial for a lot of tasks such as data entry, information retrieval, question answering, multi-step workflows and so on. I am sure you must know how LLMs can generate outputs in wildly different formats even if the prompt is the same. \n",
    "\n",
    "For example, consider this simple `classify_sentiment` function powered by OpenAI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# List of hotel reviews\n",
    "reviews = [\n",
    "    \"The room was clean and the staff was friendly.\",\n",
    "    \"The location was terrible and the service was slow.\",\n",
    "    \"The food was amazing but the room was too small.\",\n",
    "]\n",
    "\n",
    "# Classify sentiment for each review and print the results\n",
    "for review in reviews:\n",
    "    sentiment = classify_sentiment(review)\n",
    "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```python\n",
    "Review: The room was clean and the staff was friendly.\n",
    "Sentiment: Positive\n",
    "\n",
    "Review: The location was terrible and the service was slow.\n",
    "Sentiment: Negative\n",
    "\n",
    "Review: The food was amazing but the room was too small.\n",
    "Sentiment: The sentiment of the review is neutral.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the first two responses were in the same single-word format, the last one is an entire sentence. If some other downstream application depended on the output of the above code, it would have crashed as it would have been expecting a single-word response.\n",
    "\n",
    "We can fix this problem with some prompt engineering but it is a time-consuming, iterative process. Even with a perfect prompt, we can't be 100% sure the responses will conform to our format in future requests. Unless, of course, we use Structured Outputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def classify_sentiment_with_structured_outputs(review):\n",
    "    \"\"\"Sentiment classifier with Structured Outputs\"\"\"\n",
    "    ...\n",
    "\n",
    "# Classify sentiment for each review with Structured Outputs\n",
    "for review in reviews:\n",
    "    sentiment = classify_sentiment_with_structured_outputs(review)\n",
    "    print(f\"Review: {review}\\nSentiment: {sentiment}\\n\")\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```python\n",
    "Review: The room was clean and the staff was friendly.\n",
    "Sentiment: {\"sentiment\":\"positive\"}\n",
    "\n",
    "Review: The location was terrible and the service was slow.\n",
    "Sentiment: {\"sentiment\":\"negative\"}\n",
    "\n",
    "Review: The food was amazing but the room was too small.\n",
    "Sentiment: {\"sentiment\":\"neutral\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a new function, `classify_sentiment_with_structured_outputs`, the responses are all in the same format. \n",
    "\n",
    "This capability of forcing language models in a rigid format is significant, saving you countless hours of prompt engineering or reliance on other open-source tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started  With Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will break down Structured Outputs through the example of the sentiment analyzer function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Your Environment\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "Before you begin, ensure you have the following:\n",
    "\n",
    "- Python 3.7 or later installed on your system.\n",
    "- An OpenAI API key. You can obtain this by signing up on the [OpenAI website](https://openai.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up the OpenAI API\n",
    "\n",
    "1. **Install the OpenAI Python package**:\n",
    "   Open your terminal and run the following command to install or update the OpenAI Python package to the latest version:\n",
    "   \n",
    "   ```bash\n",
    "   $ pip install -U openai\n",
    "   ```\n",
    "\n",
    "2. **Set up your API key**:\n",
    "   You can set your API key as an environment variable or directly in your code. To set it as an environment variable, run:\n",
    "   \n",
    "   ```bash\n",
    "   $ export OPENAI_API_KEY='your-api-key'\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Verify the installation**:\n",
    "   Create a simple Python script to verify the installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say hello!\"}\n",
    "    ],\n",
    "    max_tokens=5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script to ensure everything is set up correctly. You should see the model's response printed in the terminal.\n",
    "\n",
    "In addition to the OpenAI package, you will need the Pydantic library to define and validate JSON schemas for Structured Outputs. Install it using pip:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install pydantic\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these steps, your environment is now set up to use OpenAI's Structured Outputs feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining an output schema using Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Structured Outputs, you need to define the expected output structure using Pydantic models. Pydantic is a data validation and settings management library for Python, which allows you to define data models using Python type annotations. These models can then be used to enforce the structure of the outputs generated by OpenAI's models.\n",
    "\n",
    "Here is an example Pydantic model for specifying the format for our review sentiment classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "- `SentimentResponse` is a Pydantic model that defines the expected structure of the output.\n",
    "- The model has a single field `sentiment`, which can only take one of three literal values: \"positive\", \"negative\", or \"neutral\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass this model as part of our OpenAI API requests, the outputs will be only one of the words we provided. \n",
    "\n",
    "Let's see how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `parse` helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enforce our Pydantic schema in OpenAI requests, all we have to do is pass it to the `response_format` parameter of the chat completions API. Roughly, here is what it looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=[...],\n",
    "    response_format=SentimentResponse\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you notice, instead of using `client.chat.completions.create`, we are using `client.beta.chat.completions.parse` method. `.parse()` is a new method in the Chat Completions API specifically written for Structured Outputs. \n",
    "\n",
    "Now, let's put everything together by rewriting the reviews sentiment classifier with Structured Outputs. First, we make the necessary imports, define the Pydantic model, the system prompt and a prompt template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class SentimentResponse(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a sentiment classifier assistant.\"\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "    Classify the sentiment of the following hotel review as positive, negative, or neutral:\\n\\n{review}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we write a new function that uses the `.parse()` helper method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify sentiment using OpenAI's chat completions API with structured outputs\n",
    "def classify_sentiment_with_structured_outputs(review):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(review=review)},\n",
    "        ],\n",
    "        response_format=SentimentResponse\n",
    "    )\n",
    "    return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important line in the function is `response_format=SentimentResponse`, which is what actually enables Structured Outputs. \n",
    "\n",
    "Let's test it on one of the reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentiment\":\"positive\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of hotel reviews\n",
    "reviews = [\n",
    "    \"The room was clean and the staff was friendly.\",\n",
    "    \"The location was terrible and the service was slow.\",\n",
    "    \"The food was amazing but the room was too small.\",\n",
    "]\n",
    "\n",
    "result = classify_sentiment_with_structured_outputs(reviews[0])\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `result` is a message object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.parsed_chat_completion.ParsedChatCompletionMessage[SentimentResponse]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from its `.content` attribute which retrieves the response, it has a `.parsed` attribute that returns the parsed information as a class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentResponse(sentiment='positive')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have got an instance of the `SentimentResponse` class. This means, we can access the sentiment as a string instead of a dictionary using the `.sentiment` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.parsed.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting Pydantic Models For Defining Complex Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, you may need to define more complex output structures that involve nested data. Pydantic allows you to nest models within each other, enabling you to create intricate schemas that can handle a variety of use cases. This is particularly useful when dealing with hierarchical data or when you need to enforce a specific structure for complex outputs.\n",
    "\n",
    "Let's consider an example where we need to extract detailed user information, including their name, contact details, and a list of addresses. Each address should include fields for the street, city, state, and zip code. This requires more than one Pydantic model to build the correct schema.\n",
    "\n",
    "__Step 1: Define the Pydantic Models__\n",
    "\n",
    "First, we define the Pydantic models for the address and user information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Define the Pydantic model for an address\n",
    "class Address(BaseModel): \n",
    "    street: str \n",
    "    city: str \n",
    "    state: str \n",
    "    zip_code: str\n",
    "\n",
    "# Define the Pydantic model for user information\n",
    "class UserInfo(BaseModel): \n",
    "    name: str \n",
    "    email: str \n",
    "    phone: str \n",
    "    addresses: List[Address]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example:\n",
    "    \n",
    "- `Address` is a Pydantic model that defines the structure of an address.\n",
    "- `UserInfo` is a Pydantic model that includes a list of `Address` objects, along with fields for the user's name, email, and phone number.\n",
    "\n",
    "__Step 2: Use the Nested Pydantic Models in API Calls__\n",
    "\n",
    "Next, we use these nested Pydantic models to enforce the output structure in an OpenAI API call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"You are a user information extraction assistant.\"\n",
    "PROMPT_TEMPLATE = \"\"\" Extract the user information from the following text:\\n\\n{text}\"\"\"\n",
    "\n",
    "\n",
    "# Function to extract user information using OpenAI's chat completions API with structured outputs\n",
    "def extract_user_info(text):\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": PROMPT_TEMPLATE.format(text=text)},\n",
    "        ],\n",
    "        response_format=UserInfo\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "\n",
    "# Example text containing user information\n",
    "text = \"\"\"John DoeEmail: john.doe@example.comPhone: 123-456-7890Addresses:- 123 Main St, Springfield, IL, 62701- 456 Elm St, Shelbyville, IL, 62702\"\"\"\n",
    "\n",
    "# Extract user information and print the results\n",
    "user_info = extract_user_info(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample text is totally unreadable and lacks spaces between kep pieces of information. Let's see if the model succeeds. We will use the `json` library to prettify the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"John Doe\",\n",
      "  \"email\": \"john.doe@example.com\",\n",
      "  \"phone\": \"123-456-7890\",\n",
      "  \"addresses\": [\n",
      "    {\n",
      "      \"street\": \"123 Main St\",\n",
      "      \"city\": \"Springfield\",\n",
      "      \"state\": \"IL\",\n",
      "      \"zip_code\": \"62701\"\n",
      "    },\n",
      "    {\n",
      "      \"street\": \"456 Elm St\",\n",
      "      \"city\": \"Shelbyville\",\n",
      "      \"state\": \"IL\",\n",
      "      \"zip_code\": \"62702\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(user_info.content)\n",
    "\n",
    "pretty_response = json.dumps(data, indent=2)\n",
    "print(pretty_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model correctly captured a single user's information along with their two separate addresses based on our provided schema. \n",
    "\n",
    "In short, by nesting Pydantic models, you can define complex schemas that handle hierarchical data and enforce specific structures for intricate outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling with Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the widespread features of newer language models is function calling (also called _tool calling_). This capability allows you to connect language models to user defined functions, effectively giving them (models) access to outside world. \n",
    "\n",
    "Some common examples are:\n",
    "- Retrieving real-time data (e.g. weather, stock prices, sports scores)\n",
    "- Performing calculations or data analysis\n",
    "- Querying databases or APIs\n",
    "- Generating images or other media\n",
    "- Translating text between languages\n",
    "- Controlling smart home devices or IoT systems\n",
    "- Executing custom business logic or workflows\n",
    "\n",
    "We won't go into the details of how function calling works here, but you can read our [OpenAI Function Calling tutorial](https://www.datacamp.com/tutorial/open-ai-function-calling-tutorial).\n",
    "\n",
    "What's important to know is that with Structured Outputs, using function calling with OpenAI models becomes so much easier. In the past, the functions you would pass to OpenAI models would require writing complex JSON schemas, outlining every function parameter with type hints. Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"format\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"location\", \"format\"],\n",
    "        },\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though `get_current_weather` function has two parameters, its JSON schema becomes enormous and error-prone to write manually. \n",
    "\n",
    "This is solved in Structured Outputs by using Pydantic models again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "def get_weather(location: str, unit: str, condition: str):\n",
    "    # Implementation details...\n",
    "    pass\n",
    "\n",
    "class WeatherData(BaseModel):\n",
    "    location: str\n",
    "    unit: Literal[\"celsius\", \"fahrenheit\"]\n",
    "    condition: Literal[\"sunny\", \"cloudy\", \"rainy\", \"snowy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you write the function itself and its logic. Then, you define it again with a Pydantic model specifying the expected input parameters.\n",
    "\n",
    "Then, to convert the Pydantic model into a compatible JSON schema, you call `pydantic_function_tool`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'WeatherData',\n",
       "  'strict': True,\n",
       "  'parameters': {'properties': {'location': {'title': 'Location',\n",
       "     'type': 'string'},\n",
       "    'unit': {'enum': ['celsius', 'fahrenheit'],\n",
       "     'title': 'Unit',\n",
       "     'type': 'string'},\n",
       "    'condition': {'enum': ['sunny', 'cloudy', 'rainy', 'snowy'],\n",
       "     'title': 'Condition',\n",
       "     'type': 'string'}},\n",
       "   'required': ['location', 'unit', 'condition'],\n",
       "   'title': 'WeatherData',\n",
       "   'type': 'object',\n",
       "   'additionalProperties': False}}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.pydantic_function_tool(WeatherData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to use this tool as part of a request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessageToolCall(id='call_QnZZ0DmNN2cxw3bN433JQNIC', function=Function(arguments='{\"location\":\"Tokyo\",\"unit\":\"celsius\",\"condition\":\"sunny\"}', name='WeatherData'), type='function')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = OpenAI()\n",
    "tools = [openai.pydantic_function_tool(WeatherData)]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What is the weather in Tokyo?\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL, messages=messages, tools=tools\n",
    ")\n",
    "\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the Pydantic model in a compatible JSON format to the `tools` parameter of the Chat Completions API. Then, depending on our query, the model decides whether to call the tool or not. \n",
    "\n",
    "Since our query in the above example is \"What is the weather in Tokyo?\", we see a call in the `tool_calls` of the returned message object. \n",
    "\n",
    "Remember, the model doesn't call the `get_weather` function but generates arguments for it based on the Pydantic schema we provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Tokyo', 'unit': 'celsius', 'condition': 'sunny'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is up to us to call the function with the provided arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_result = get_weather(**arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want the model to generate the arguments for the function and call it at the same time, you are looking for an AI agent. We have a separate [LangChain Agents tutorial](https://www.datacamp.com/tutorial/building-langchain-agents-to-automate-tasks-in-python) if you are interested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices When Using Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While using Structured Outputs, there are a number of best practices and recommendations you have to keep in mind. In this section, we will outline some of them.\n",
    "\n",
    "1. Use Pydantic models to define output schemas as they provide a clean and type-safe way to define expected output structures.\n",
    "\n",
    "2. Keep schemas simple and specific to get the most accurate results.\n",
    "\n",
    "3. Use appropriate data types (`str`, `int`, `float`, `bool`, `List`, `Dict`) to accurately represent your data.\n",
    "\n",
    "4. Use `Literal` types for enums to define specific allowed values for fields.\n",
    "\n",
    "5. Handle model refusals. When using the new `.parse()` method, the message objects has a new `.refusal` attribute to indicate a refusal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\":\"John Doe\",\"email\":\"john.doe@example.com\",\"phone\":\"123-456-7890\",\"addresses\":[{\"street\":\"123 Main St\",\"city\":\"Springfield\",\"state\":\"IL\",\"zip_code\":\"62701\"},{\"street\":\"456 Elm St\",\"city\":\"Shelbyville\",\"state\":\"IL\",\"zip_code\":\"62702\"}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"John DoeEmail: john.doe@example.comPhone: 123-456-7890Addresses:- 123 Main St, Springfield, IL, 62701- 456 Elm St, Shelbyville, IL, 62702\"\"\"\n",
    "\n",
    "user_info = extract_user_info(text)\n",
    "\n",
    "if user_info.refusal:\n",
    "    print(user_info.refusal)\n",
    "else:\n",
    "    print(user_info.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Provide clear and concise descriptions for each field in your Pydantic models to improve the model output precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(..., description=\"The person's full name\")\n",
    "    age: int = Field(..., description=\"The person's age in years\")\n",
    "    occupation: str = Field(..., description=\"The person's current job or profession\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These practices will go a long way in making the most effective use of Structured Outputs in your applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we have learned how to get started with a new OpenAI API feature: Structured Outputs. We have seen how this feature forces language models to produce outputs in a format we specify. We have learned how to use it in combination with function calling and explore some best practices to make the most of out of the feature.\n",
    "\n",
    "Here are some related sources to enhance your understanding:\n",
    "- https://platform.openai.com/docs/guides/structured-outputs\n",
    "- https://platform.openai.com/docs/guides/function-calling\n",
    "- https://cookbook.openai.com/examples/structured_outputs_intro\n",
    "- https://www.datacamp.com/courses/working-with-the-openai-api\n",
    "- https://www.datacamp.com/tracks/openai-fundamentals\n",
    "- https://www.datacamp.com/courses/developing-llm-applications-with-langchain\n",
    "- https://www.datacamp.com/blog/langchain-vs-llamaindex\n",
    "\n",
    "Thank you for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "articles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
