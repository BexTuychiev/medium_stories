{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Perform Fuzzy Dataframe Row Matching With RecordLinkage\n",
    "## An elite skill for hardest of the problems\n",
    "<img src='images/chain.jpg'></img>\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@joey-kyber-31917?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Joey Kyber</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/sea-nature-sunset-water-119562/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Unsplash</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction <small id='intro'></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one of my previous articles, I wrote about how to perform string similarity to clean text data using `fuzzywuzzy` package. Learning about the package and performing it in practice was really awesome. But wouldn't be even greater if we could perform the same process between rows of dataframes? \n",
    "\n",
    "Actually, the question should be why would we even need it? Today data is never collected in the same place but across several locations. A common challenge in this process is to convert all the little pieces of data into the same format so that when you merge them they work smoothly with data manipulation softwares such as SQL or `pandas`. \n",
    "\n",
    "But it is just not always possible. Consider these two fake tables:\n",
    "<img src='images/1.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume they are schedules for NBA games and they were scraped from different sites. If we want to merge them together, the merge would result in duplicates because even though not exact, there are fuzzy duplicates:\n",
    "<img src='images/3.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge them you would have to perform serious data cleaning operations to get the merge working. However, this dataset could have easily been thousands of rows and you would not be able to find all the edge cases. \n",
    "\n",
    "Real-world cases will be much more complex. Fuzzy row matching helps to remove duplicates and introduces consistency to your data. \n",
    "\n",
    "With that goal in mind, let me introduce you to `recordlinkage` package. It provides all the tools needed for record linkage and deduplication. In the next sections, we will see case studies to perform record linkage and will build a solid foundation for your future data cleaning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Installation <small id='setup'></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`recordlinkage` can be installed using `pip`:\n",
    "\n",
    "```pip install recordlinkage```\n",
    "\n",
    "For it to work, you need to import it with `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import pandas as pd\n",
    "import recordlinkage as rl\n",
    "import time\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Linkage, Indexing <small id='indexing'></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next examples, we will load one of the built-in datasets of `recordlinkage` to showcase its powers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recordlinkage.datasets import load_febrl4\n",
    "\n",
    "census_a, census_b = load_febrl4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above two datasets contain census data generated by [Febrl](https://sourceforge.net/projects/febrl/) project. It was divided into two with 5k rows in each and each are suited to perform record linkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easy illustration, I will just take a random sample from both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_a = census_a.sample(5)\n",
    "rand_b = census_b.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-4916-org</th>\n",
       "      <td>india</td>\n",
       "      <td>nicoll</td>\n",
       "      <td>432</td>\n",
       "      <td>buckmaster crescent</td>\n",
       "      <td>kurrajong</td>\n",
       "      <td>moree</td>\n",
       "      <td>4812</td>\n",
       "      <td>qld</td>\n",
       "      <td>19111101</td>\n",
       "      <td>5165691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2323-org</th>\n",
       "      <td>rachael</td>\n",
       "      <td>yallop</td>\n",
       "      <td>15</td>\n",
       "      <td>fullagar crescent</td>\n",
       "      <td>rsde 668</td>\n",
       "      <td>beenleigh</td>\n",
       "      <td>4860</td>\n",
       "      <td>qld</td>\n",
       "      <td>19760214</td>\n",
       "      <td>1296128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4544-org</th>\n",
       "      <td>kiera</td>\n",
       "      <td>everett</td>\n",
       "      <td>4</td>\n",
       "      <td>rohan rivett crescent</td>\n",
       "      <td>brindabella specialist centre</td>\n",
       "      <td>alice springs</td>\n",
       "      <td>5558</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19371021</td>\n",
       "      <td>2315324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1632-org</th>\n",
       "      <td>jasmine</td>\n",
       "      <td>stancombe</td>\n",
       "      <td>41</td>\n",
       "      <td>roseby street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dulwich hill</td>\n",
       "      <td>2086</td>\n",
       "      <td>wa</td>\n",
       "      <td>19980319</td>\n",
       "      <td>8947188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4449-org</th>\n",
       "      <td>olivia</td>\n",
       "      <td>boyle</td>\n",
       "      <td>37</td>\n",
       "      <td>chauncy crescent</td>\n",
       "      <td>cygnet river schoolhouse</td>\n",
       "      <td>plumpton</td>\n",
       "      <td>2460</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19581017</td>\n",
       "      <td>8738461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             given_name    surname street_number              address_1  \\\n",
       "rec_id                                                                    \n",
       "rec-4916-org      india     nicoll           432    buckmaster crescent   \n",
       "rec-2323-org    rachael     yallop            15      fullagar crescent   \n",
       "rec-4544-org      kiera    everett             4  rohan rivett crescent   \n",
       "rec-1632-org    jasmine  stancombe            41          roseby street   \n",
       "rec-4449-org     olivia      boyle            37       chauncy crescent   \n",
       "\n",
       "                                  address_2         suburb postcode state  \\\n",
       "rec_id                                                                      \n",
       "rec-4916-org                      kurrajong          moree     4812   qld   \n",
       "rec-2323-org                       rsde 668      beenleigh     4860   qld   \n",
       "rec-4544-org  brindabella specialist centre  alice springs     5558   nsw   \n",
       "rec-1632-org                            NaN   dulwich hill     2086    wa   \n",
       "rec-4449-org       cygnet river schoolhouse       plumpton     2460   nsw   \n",
       "\n",
       "             date_of_birth soc_sec_id  \n",
       "rec_id                                 \n",
       "rec-4916-org      19111101    5165691  \n",
       "rec-2323-org      19760214    1296128  \n",
       "rec-4544-org      19371021    2315324  \n",
       "rec-1632-org      19980319    8947188  \n",
       "rec-4449-org      19581017    8738461  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-917-dup-0</th>\n",
       "      <td>carly</td>\n",
       "      <td>georgetti</td>\n",
       "      <td>155</td>\n",
       "      <td>lockyer street</td>\n",
       "      <td>langi</td>\n",
       "      <td>rowviille</td>\n",
       "      <td>2087</td>\n",
       "      <td>qld</td>\n",
       "      <td>19740602</td>\n",
       "      <td>7008776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4618-dup-0</th>\n",
       "      <td>chloe</td>\n",
       "      <td>musoilno</td>\n",
       "      <td>4</td>\n",
       "      <td>warrumbmul street</td>\n",
       "      <td>gordoivale</td>\n",
       "      <td>brighton</td>\n",
       "      <td>3728</td>\n",
       "      <td>ni</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7147784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3700-dup-0</th>\n",
       "      <td>steven</td>\n",
       "      <td>pokkias</td>\n",
       "      <td>407</td>\n",
       "      <td>may maxwell crescent</td>\n",
       "      <td>ardonachie</td>\n",
       "      <td>dalveen</td>\n",
       "      <td>5046</td>\n",
       "      <td>wa</td>\n",
       "      <td>19350305</td>\n",
       "      <td>2928326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-309-dup-0</th>\n",
       "      <td>eliza</td>\n",
       "      <td>campbell</td>\n",
       "      <td>113</td>\n",
       "      <td>dines place</td>\n",
       "      <td>villa 74 village glen</td>\n",
       "      <td>figtree</td>\n",
       "      <td>3550</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19651205</td>\n",
       "      <td>4509107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-85-dup-0</th>\n",
       "      <td>dakin</td>\n",
       "      <td>joselyn</td>\n",
       "      <td>57</td>\n",
       "      <td>aberneth ystreet</td>\n",
       "      <td>kanangra hostel</td>\n",
       "      <td>manundza</td>\n",
       "      <td>3028</td>\n",
       "      <td>wa</td>\n",
       "      <td>19261205</td>\n",
       "      <td>4852063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               given_name    surname street_number             address_1  \\\n",
       "rec_id                                                                     \n",
       "rec-917-dup-0       carly  georgetti           155        lockyer street   \n",
       "rec-4618-dup-0      chloe   musoilno             4     warrumbmul street   \n",
       "rec-3700-dup-0     steven    pokkias           407  may maxwell crescent   \n",
       "rec-309-dup-0       eliza   campbell           113           dines place   \n",
       "rec-85-dup-0        dakin    joselyn            57      aberneth ystreet   \n",
       "\n",
       "                            address_2     suburb postcode state date_of_birth  \\\n",
       "rec_id                                                                          \n",
       "rec-917-dup-0                   langi  rowviille     2087   qld      19740602   \n",
       "rec-4618-dup-0             gordoivale   brighton     3728    ni           NaN   \n",
       "rec-3700-dup-0             ardonachie    dalveen     5046    wa      19350305   \n",
       "rec-309-dup-0   villa 74 village glen    figtree     3550   nsw      19651205   \n",
       "rec-85-dup-0          kanangra hostel   manundza     3028    wa      19261205   \n",
       "\n",
       "               soc_sec_id  \n",
       "rec_id                     \n",
       "rec-917-dup-0     7008776  \n",
       "rec-4618-dup-0    7147784  \n",
       "rec-3700-dup-0    2928326  \n",
       "rec-309-dup-0     4509107  \n",
       "rec-85-dup-0      4852063  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we want to link the records of the two datasets without introducing duplication. To start the process, we would have to generate pairs for possible matches. Obviously, we cannot know which rows match so we would have to take all the possible pairs. Generating pairs to calculate similarity is done using the indexes of the two datasets. That's why it is also called `indexing`. `recordlinkage` package makes this process very easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexing object\n",
    "indexer = rl.Index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the process, we will create an indexing object. Next, we should specify the mode of generating the pairs. Since we need to generate all the possible combinations of indexes, we will use `.full()` method on the indexing object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Index>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the mode of generation to full\n",
    "indexer.full()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will input the datasets to generate the pairs, also called candidates and assign the result to a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-4916-org',  'rec-917-dup-0'),\n",
       "            ('rec-4916-org', 'rec-4618-dup-0'),\n",
       "            ('rec-4916-org', 'rec-3700-dup-0'),\n",
       "            ('rec-4916-org',  'rec-309-dup-0'),\n",
       "            ('rec-4916-org',   'rec-85-dup-0'),\n",
       "            ('rec-2323-org',  'rec-917-dup-0'),\n",
       "            ('rec-2323-org', 'rec-4618-dup-0'),\n",
       "            ('rec-2323-org', 'rec-3700-dup-0'),\n",
       "            ('rec-2323-org',  'rec-309-dup-0'),\n",
       "            ('rec-2323-org',   'rec-85-dup-0'),\n",
       "            ('rec-4544-org',  'rec-917-dup-0'),\n",
       "            ('rec-4544-org', 'rec-4618-dup-0'),\n",
       "            ('rec-4544-org', 'rec-3700-dup-0'),\n",
       "            ('rec-4544-org',  'rec-309-dup-0'),\n",
       "            ('rec-4544-org',   'rec-85-dup-0'),\n",
       "            ('rec-1632-org',  'rec-917-dup-0'),\n",
       "            ('rec-1632-org', 'rec-4618-dup-0'),\n",
       "            ('rec-1632-org', 'rec-3700-dup-0'),\n",
       "            ('rec-1632-org',  'rec-309-dup-0'),\n",
       "            ('rec-1632-org',   'rec-85-dup-0'),\n",
       "            ('rec-4449-org',  'rec-917-dup-0'),\n",
       "            ('rec-4449-org', 'rec-4618-dup-0'),\n",
       "            ('rec-4449-org', 'rec-3700-dup-0'),\n",
       "            ('rec-4449-org',  'rec-309-dup-0'),\n",
       "            ('rec-4449-org',   'rec-85-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = indexer.index(rand_a, rand_b)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result will be a `pandas.MultiIndex` object. The first level contains the indexes from the first dataset and similarly, the second level indexes contain the indexes for the second dataset.\n",
    "\n",
    "The length of the resulting `series` will always be the product of the lengths of datasets. Because for our 5-row datasets, each index from the first table will have 5 pairs of indexes from the second:\n",
    "<img src='images/4.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if our datasets are large, generating all the possible pairs will be very computationally expensive. To avoid generating all the possible pairs, we should choose one column which has consistent values from both datasets. For our small datasets, there is a state column:\n",
    "```\n",
    ">>> rand_a[['state']], rand_b[['state']]\n",
    "```\n",
    "<img src='images/5.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pay attention, the unique values of `state` is consistent in both datasets. Meaning, one state name is not different in the other. This helps us very much because now we can exclude all the pairs that does not have a matching state value. To do this with `recordlinkage`, we have to change the mode from `full` to `blocking`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('rec-4916-org',  'rec-917-dup-0'),\n",
       "            ('rec-2323-org',  'rec-917-dup-0'),\n",
       "            ('rec-4544-org',  'rec-309-dup-0'),\n",
       "            ('rec-4449-org',  'rec-309-dup-0'),\n",
       "            ('rec-1632-org', 'rec-3700-dup-0'),\n",
       "            ('rec-1632-org',   'rec-85-dup-0')],\n",
       "           names=['rec_id_1', 'rec_id_2'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From scratch\n",
    "indexer = rl.Index()\n",
    "# Set the mode to blocking with `state`\n",
    "indexer.block('state')\n",
    "# Generate pairs\n",
    "pairs = indexer.index(rand_a, rand_b)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember, the logic behind blocking on a certain column is that we expect duplicate values to have the same or similar values across the columns of both datasets and if the rows do not match on some certain column, we can exclude that pair. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, the number of pairs (6) got reduced significantly. These index pairs are also the ones that have the same values for `state`. Let's check some of the pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qld', 'qld')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_a.loc['rec-4916-org']['state'], rand_b.loc['rec-917-dup-0']['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nsw', 'nsw')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_a.loc['rec-4449-org']['state'], rand_b.loc['rec-309-dup-0']['state']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use blocking on a consistent common column, the number of pairs will be much less. We can even use multiple columns to block as long as the unique values of those columns are inconsistent in both tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Linkage, Case Study <small id='case1'></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have an understanding of indexing, we can start record linkage with the full datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5458951\n"
     ]
    }
   ],
   "source": [
    "# Create an indexing object\n",
    "indexer = rl.Index()\n",
    "# Block on state\n",
    "indexer.block('state')\n",
    "# Generate candidate pairs\n",
    "pairs = indexer.index(census_a, census_b)\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full datasets, almost 5.5 million pairs are returned. Remember, if we used full indexing, it would have been 25 million. \n",
    "Now, using these candidate pairs, we will perform comparison of each column values. To start comparing, we should create a comparing object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparing object\n",
    "compare = rl.Compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This object has many useful functions to match exact or fuzzy values of the columns. First, let's start by matching exact matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compare>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the exact matches of state\n",
    "compare.exact('state', 'state', label='state')\n",
    "# Query the exact matches of date of birth\n",
    "compare.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "# Query the exact matches of date of birth\n",
    "compare.exact('soc_sec_id', 'soc_sec_id', label='soc_sec_id')\n",
    "# Query the exact matches of date of birth\n",
    "compare.exact('postcode', 'postcode', label='postcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use `exact` for certain fields, we expect row pairs have exactly the same values for these fields. The parameters of `exact`:\n",
    "- `left_on`:  the column name of the left dataset\n",
    "- `right_on`: the column name of the right dataset\n",
    "- `label`: the column name of the resulting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we perform all the comparisons, the result will be a `pandas` dataframe and `label` controls the name of the appropriate column name in the resulting dataframe. \n",
    "\n",
    "Why did we choose exact matching? Because the postcode, social security ID, the date of birth and the state columns have to be an exact match to be a duplicate. This also depends on the values of those columns. If the unique values are consistent among the datasets, we should use `exact`.\n",
    "\n",
    "Now, for fuzzy matching. The given name, surname, address columns will probably have typos and inconsistencies, so we will use fuzzy string matching for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compare>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the fuzzy matches for given name\n",
    "compare.string('given_name', 'given_name', threshold=0.75, method='levenshtein', label='given_name')\n",
    "# Query the fuzzy matches for surname\n",
    "compare.string('surname', 'surname', threshold=0.75, method='levenshtein', label='surname')\n",
    "# Query the fuzzy matches for address\n",
    "compare.string('address_1', 'address_1', threshold=0.75, method='levenshtein', label='address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fuzzy `string` matching, we will use `.string` method. The parameters for column names are the same. Other parameters:\n",
    "- `method`: controls the algorithm used to calculate string similarity\n",
    "- `threshold`: the similarity score threshold. If similarity is higher than the given score, it is a match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are other methods of matching values depending on the data type: `.numeric` and `.date`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the methods in place, it is time to compute them and assign the result to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the matches, this will take a while\n",
    "matches = compare.compute(pairs, census_a, census_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.compute` takes three arguments. First one is the `MultiIndex` object of potential indexes. The next two are the two data frames we are using. Note that the order of their input should be the same as `indexer.index()`.\n",
    "\n",
    "After the computation is done, we will have a dataset of this sort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>postcode</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-3348-org</th>\n",
       "      <th>rec-4246-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3420-org</th>\n",
       "      <th>rec-656-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-830-org</th>\n",
       "      <th>rec-2840-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1472-org</th>\n",
       "      <th>rec-461-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-824-org</th>\n",
       "      <th>rec-2005-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             state  date_of_birth  soc_sec_id  postcode  \\\n",
       "rec_id_1     rec_id_2                                                     \n",
       "rec-3348-org rec-4246-dup-0      1              0           0         0   \n",
       "rec-3420-org rec-656-dup-0       1              0           0         0   \n",
       "rec-830-org  rec-2840-dup-0      1              0           0         0   \n",
       "rec-1472-org rec-461-dup-0       1              0           0         0   \n",
       "rec-824-org  rec-2005-dup-0      1              0           0         0   \n",
       "\n",
       "                             given_name  surname  address  \n",
       "rec_id_1     rec_id_2                                      \n",
       "rec-3348-org rec-4246-dup-0         0.0      0.0      0.0  \n",
       "rec-3420-org rec-656-dup-0          0.0      0.0      0.0  \n",
       "rec-830-org  rec-2840-dup-0         0.0      0.0      0.0  \n",
       "rec-1472-org rec-461-dup-0          0.0      0.0      0.0  \n",
       "rec-824-org  rec-2005-dup-0         0.0      0.0      0.0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting data frame also has multi-level index, first one being `census_a`, second one being `census_b`. The rest of the columns will have either 1 for a match or 0 for not a match. Let's interpret the first row of the above sample:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows with indexes `rec-3254-org` and `rec-1416-dup-0` only matched on the `state` column because there is 1 in that field. These rows failed to match in other fields.\n",
    "\n",
    "Now, let's set when we decide that two rows are duplicate. For our dataset, I think if the rows match on at least 4 columns, there is pretty high chance that they are duplicates. We can easily subset for rows with overall matching score of at least 4 with `sum` and boolean indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "      <th>postcode</th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-3823-org</th>\n",
       "      <th>rec-3823-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1176-org</th>\n",
       "      <th>rec-1176-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-866-org</th>\n",
       "      <th>rec-866-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1655-org</th>\n",
       "      <th>rec-1655-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4915-org</th>\n",
       "      <th>rec-4915-dup-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             state  date_of_birth  soc_sec_id  postcode  \\\n",
       "rec_id_1     rec_id_2                                                     \n",
       "rec-3823-org rec-3823-dup-0      1              1           1         1   \n",
       "rec-1176-org rec-1176-dup-0      1              1           1         0   \n",
       "rec-866-org  rec-866-dup-0       1              1           1         1   \n",
       "rec-1655-org rec-1655-dup-0      1              1           1         1   \n",
       "rec-4915-org rec-4915-dup-0      1              1           1         1   \n",
       "\n",
       "                             given_name  surname  address  \n",
       "rec_id_1     rec_id_2                                      \n",
       "rec-3823-org rec-3823-dup-0         1.0      1.0      1.0  \n",
       "rec-1176-org rec-1176-dup-0         1.0      1.0      1.0  \n",
       "rec-866-org  rec-866-dup-0          1.0      1.0      1.0  \n",
       "rec-1655-org rec-1655-dup-0         1.0      1.0      1.0  \n",
       "rec-4915-org rec-4915-dup-0         1.0      1.0      1.0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query matches with score over 4\n",
    "full_matches = matches[matches.sum(axis='columns') >= 4]\n",
    "full_matches.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4676, 7)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matches.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you use `.sum()` with `axis` set to 1 or `columns`, it will take the sum of numeric values across columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, almost 4676 rows matched out of 5.5 million possible pairs. Now before merging our original tables together, we have to make sure that we do not include these 4676 rows. To do this, we will do a little bit of manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rec-4405-dup-0', 'rec-1985-dup-0', 'rec-4302-dup-0', 'rec-4641-dup-0',\n",
      "       'rec-1300-dup-0', 'rec-4178-dup-0', 'rec-1280-dup-0', 'rec-780-dup-0',\n",
      "       'rec-4098-dup-0', 'rec-4663-dup-0'],\n",
      "      dtype='object', name='rec_id_2')\n"
     ]
    }
   ],
   "source": [
    "# Get the indexes from either of index levels\n",
    "duplicates = full_matches.index.get_level_values('rec_id_2')\n",
    "print(duplicates[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get indexes of some level from multi-level indexes, we use `.get_level_values` on `df.index`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we chose the second level index, we should exclude them from `census_b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 10)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude the indexes of duplicates from census_b\n",
    "unique_b = census_b[~census_b.index.isin(duplicates)]\n",
    "unique_b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the `unique_b` is ready to be appended to the first dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5324, 10)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append deduplicated census_b to census_a\n",
    "full_census = census_a.append(unique_b)\n",
    "full_census.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-3254-org</th>\n",
       "      <td>xanthe</td>\n",
       "      <td>hipkiss</td>\n",
       "      <td>33</td>\n",
       "      <td>luke street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>port lincoln</td>\n",
       "      <td>2122</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19890508</td>\n",
       "      <td>5654602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-18-dup-0</th>\n",
       "      <td>riley</td>\n",
       "      <td>kerr-sullivan</td>\n",
       "      <td>166</td>\n",
       "      <td>clem hill street</td>\n",
       "      <td>mindaree</td>\n",
       "      <td>oyster bay</td>\n",
       "      <td>7325</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19991104</td>\n",
       "      <td>7355856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-61-dup-0</th>\n",
       "      <td>kynan</td>\n",
       "      <td>sincovich</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>barrack heights</td>\n",
       "      <td>4222</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19470922</td>\n",
       "      <td>4440480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2243-org</th>\n",
       "      <td>ned</td>\n",
       "      <td>herbert</td>\n",
       "      <td>6</td>\n",
       "      <td>vonwiller crescent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>albury east</td>\n",
       "      <td>3163</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19310822</td>\n",
       "      <td>6246038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1202-org</th>\n",
       "      <td>zachary</td>\n",
       "      <td>dixon</td>\n",
       "      <td>18</td>\n",
       "      <td>couchman crescent</td>\n",
       "      <td>yarrimbah</td>\n",
       "      <td>wantirna</td>\n",
       "      <td>2132</td>\n",
       "      <td>vic</td>\n",
       "      <td>19400312</td>\n",
       "      <td>6746706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             given_name        surname street_number           address_1  \\\n",
       "rec_id                                                                     \n",
       "rec-3254-org     xanthe        hipkiss            33         luke street   \n",
       "rec-18-dup-0      riley  kerr-sullivan           166    clem hill street   \n",
       "rec-61-dup-0      kynan      sincovich            95                 NaN   \n",
       "rec-2243-org        ned        herbert             6  vonwiller crescent   \n",
       "rec-1202-org    zachary          dixon            18   couchman crescent   \n",
       "\n",
       "              address_2           suburb postcode state date_of_birth  \\\n",
       "rec_id                                                                  \n",
       "rec-3254-org        NaN     port lincoln     2122   nsw      19890508   \n",
       "rec-18-dup-0   mindaree       oyster bay     7325   nsw      19991104   \n",
       "rec-61-dup-0        NaN  barrack heights     4222   nsw      19470922   \n",
       "rec-2243-org        NaN      albury east     3163   nsw      19310822   \n",
       "rec-1202-org  yarrimbah         wantirna     2132   vic      19400312   \n",
       "\n",
       "             soc_sec_id  \n",
       "rec_id                   \n",
       "rec-3254-org    5654602  \n",
       "rec-18-dup-0    7355856  \n",
       "rec-61-dup-0    4440480  \n",
       "rec-2243-org    6246038  \n",
       "rec-1202-org    6746706  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_census.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go. From 10k rows full of duplicates, we got it to 5324 unique rows. Here is the full code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set a time\n",
    "start = time.time()\n",
    "# Create an indexing object\n",
    "indexer = rl.Index()\n",
    "# Block on state\n",
    "indexer.block('state')\n",
    "# Generate candidate pairs\n",
    "pairs = indexer.index(census_a, census_b)\n",
    "\n",
    "# Create a comparing object\n",
    "compare = rl.Compare()\n",
    "\n",
    "# Query the exact matches of state\n",
    "compare.exact('state', 'state', label='state')\n",
    "# Query the exact matches of date of birth\n",
    "compare.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\n",
    "# Query the exact matches of date of birth\n",
    "compare.exact('soc_sec_id', 'soc_sec_id', label='soc_sec_id')\n",
    "# Query the exact matches of date of birth\n",
    "compare.exact('postcode', 'postcode', label='postcode')\n",
    "# Query the fuzzy matches for given name\n",
    "compare.string('given_name', 'given_name', threshold=0.75, method='levenshtein', label='given_name')\n",
    "# Query the fuzzy matches for surname\n",
    "compare.string('surname', 'surname', threshold=0.75, method='levenshtein', label='surname')\n",
    "# Query the fuzzy matches for address\n",
    "compare.string('address_1', 'address_1', threshold=0.75, method='levenshtein', label='address')\n",
    "\n",
    "# Compute the matches, this will take a while\n",
    "matches = compare.compute(pairs, census_a, census_b)\n",
    "# Query matches with score over 4\n",
    "full_matches = matches[matches.sum(axis='columns') >= 4]\n",
    "\n",
    "# Get the indexes from either of index levels\n",
    "duplicates = full_matches.index.get_level_values('rec_id_2')\n",
    "# Exclude the indexes of duplicates from census_b\n",
    "unique_b = census_b[~census_b.index.isin(duplicates)]\n",
    "\n",
    "# Append deduplicated census_b to census_a\n",
    "full_census = census_a.append(unique_b)\n",
    "\n",
    "# end timer\n",
    "end = time.time()\n",
    "end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Linkage, Case Study 2 <small id='case2'></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solidify your knowledge, we will perform record linkage with two other datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load restaurants data\n",
    "restaurants_1 = pd.read_csv('data/restaurants1.csv', index_col=0)\n",
    "restaurants_2 = pd.read_csv('data/restaurants2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>la</td>\n",
       "      <td>10506 little santa monica blvd.</td>\n",
       "      <td>century city</td>\n",
       "      <td>3104704992</td>\n",
       "      <td>french ( new )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>baja</td>\n",
       "      <td>3345 kimber dr.</td>\n",
       "      <td>westlake village</td>\n",
       "      <td>8054984049</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>carrmine's</td>\n",
       "      <td>2450 broadway between 90th and 91st sts .</td>\n",
       "      <td>new york</td>\n",
       "      <td>2123622200</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>restaurant katsui</td>\n",
       "      <td>1972 n. hillhurst ave.</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>2136651891</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>koo</td>\n",
       "      <td>8393 w. beverly blvd.</td>\n",
       "      <td>la</td>\n",
       "      <td>2136559045</td>\n",
       "      <td>chicken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name                                         addr  \\\n",
       "64                 la              10506 little santa monica blvd.   \n",
       "24               baja                              3345 kimber dr.   \n",
       "57         carrmine's   2450 broadway between 90th and 91st sts .    \n",
       "65  restaurant katsui                      1972 n. hillhurst ave.    \n",
       "44                koo                        8393 w. beverly blvd.   \n",
       "\n",
       "                city       phone            type  \n",
       "64      century city  3104704992  french ( new )  \n",
       "24  westlake village  8054984049         mexican  \n",
       "57          new york  2123622200         italian  \n",
       "65       los angeles  2136651891           asian  \n",
       "44                la  2136559045         chicken  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 5)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>sundown cafe</td>\n",
       "      <td>2165 cheshire bridge rd.</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>4043211118</td>\n",
       "      <td>american</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>barbetta</td>\n",
       "      <td>321 w. 46th st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>2122469171</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>newsbar</td>\n",
       "      <td>2 w. 19th st.</td>\n",
       "      <td>new york</td>\n",
       "      <td>2122553996</td>\n",
       "      <td>coffeebar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>hyde street bistro</td>\n",
       "      <td>1521 hyde st.</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>4154417778</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>kabuto sushi</td>\n",
       "      <td>5116 geary blvd.</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>4157525652</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                        addr           city  \\\n",
       "270        sundown cafe   2165 cheshire bridge rd.         atlanta   \n",
       "112            barbetta            321 w. 46th st.        new york   \n",
       "201             newsbar              2 w. 19th st.        new york   \n",
       "306  hyde street bistro              1521 hyde st.   san francisco   \n",
       "309        kabuto sushi           5116 geary blvd.   san francisco   \n",
       "\n",
       "          phone       type  \n",
       "270  4043211118   american  \n",
       "112  2122469171    italian  \n",
       "201  2122553996  coffeebar  \n",
       "306  4154417778    italian  \n",
       "309  4157525652      asian  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 5)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to merge these two datasets without duplication. Since they have long names and addresses, they will probably be full of typos and inconsistencies, so `.merge` won't work as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = restaurants_1.merge(restaurants_2, on='name')\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None matched! This definitely suggests we use record linkage. I will perform the process without too much details, because the steps will be the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all restaurants: 396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2184154987335205"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a timer\n",
    "start = time.time()\n",
    "# Create an indexer object\n",
    "indexer = rl.Index()\n",
    "# Block on restaurant type because it has consistent values across datasets\n",
    "indexer.block('type')\n",
    "# Create candidate pairs\n",
    "pairs = indexer.index(restaurants_1, restaurants_2)\n",
    "\n",
    "# Creat a comparion object\n",
    "compare = rl.Compare()\n",
    "# Fuzzy string matches\n",
    "compare.string('name', 'name', label='name', threshold=0.75, method='levenshtein')\n",
    "compare.string('addr', 'addr', label='address', threshold=0.75, method='levenshtein')\n",
    "compare.string('city', 'city', label='city', threshold=0.75, method='levenshtein')\n",
    "# Fuzzy numeric matches\n",
    "compare.numeric('phone', 'phone', label='phone')\n",
    "\n",
    "# Create matches\n",
    "matches = compare.compute(pairs, restaurants_1, restaurants_2)\n",
    "# Query matches of score over 3\n",
    "full_matches = matches[matches.sum(axis='columns') >= 3]\n",
    "\n",
    "# Get the indexes from either of index levels\n",
    "duplicates = full_matches.index.get_level_values(1)\n",
    "# Exclude the indexes of duplicates from census_b\n",
    "res_unique = restaurants_2[~restaurants_2.index.isin(duplicates)]\n",
    "\n",
    "# Append deduplicated census_b to census_a\n",
    "full_restaurants = restaurants_1.append(res_unique)\n",
    "print(\"Number of all restaurants: \" + str(full_restaurants.shape[0]))\n",
    "# end timer\n",
    "end = time.time()\n",
    "end - start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
