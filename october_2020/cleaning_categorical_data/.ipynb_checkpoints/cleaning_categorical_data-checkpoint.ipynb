{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master the Most Hated Task in DS/ML\n",
    "## Cleaning categorical data with Pandas\n",
    "<img src='images/mop.jpg'></img>\n",
    "<figcaption style=\"text-align: center;\">\n",
    "    <strong>\n",
    "        Photo by \n",
    "        <a href='https://www.pexels.com/@pixabay?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pixabay</a>\n",
    "        on \n",
    "        <a href='https://www.pexels.com/photo/brown-wooden-floor-48889/?utm_content=attributionCopyText&utm_medium=referral&utm_source=pexels'>Pexels</a>\n",
    "    </strong>\n",
    "</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight from [Forbes](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#718bbc696f63):\n",
    "> â€œData scientists spend 60% of their time on cleaning and organizing data. Collecting data sets comes second at 19% of their time, meaning data scientists spend around 80% of their time on preparing and managing data for analysis. 57% of data scientists regard cleaning and organizing data as the least enjoyable part of their work and 19% say this about collecting data setsâ€.\n",
    "\n",
    "Data cleaning is full of frustration, disgusting surprises that take hours to deal with, always new problems with new datasets, you name it. The process is never enjoyable and always considered as a dirty side of data science. \n",
    "\n",
    "Even though it is often hated, it might be the most import step before any data project. Without properly addressing issues with your data, you might compromise all the other stages in the data science workflow.\n",
    "\n",
    "Without much intro in this second part of my Data Cleaning Series, let's get right to the point. This post is about categorical data cleaning. I will be discussing some common and uncommon methods to deal with some intermediate level categorical data problems. Here is the general overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data, Understanding And Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formal definition of categorical data would be:\n",
    "> A predefined set of possible categories or groups an observation can fall into.\n",
    "\n",
    "You can see examples of categorical data in almost all the datasets you have worked on. Nearly any type of data can be turned into categorical. For example:\n",
    "- Survey responses:\n",
    "    * `Yes` or `No`\n",
    "    * `male` or `female`\n",
    "    * `employed` or `unemployed`\n",
    "- Numeric data:\n",
    "    * Annual income in groups: `0-40k`, `40-100k`, ...\n",
    "    * Ages: child, teenager, adult ...\n",
    "\n",
    "As we are learning data cleaning using `panads` library, it is important to understand that `pandas` will never import categorical data as categorical. It is mostly imported as strings or integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat      float64\n",
       "cut         object\n",
       "color       object\n",
       "clarity     object\n",
       "depth      float64\n",
       "table      float64\n",
       "price        int64\n",
       "x          float64\n",
       "y          float64\n",
       "z          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.read_csv('data/diamonds.csv', index_col=0)\n",
    "diamonds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that `cut`, `color` and `clarity` are imported as strings rather than as categorical. We could have used the `dtype` parameter of `read_csv` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "carat       float64\n",
       "cut        category\n",
       "color      category\n",
       "clarity    category\n",
       "depth       float64\n",
       "table       float64\n",
       "price         int64\n",
       "x           float64\n",
       "y           float64\n",
       "z           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds = pd.read_csv('data/diamonds.csv',\n",
    "                       dtype={\n",
    "                           'cut': 'category',\n",
    "                           'color': 'category',\n",
    "                           'clarity': 'category'\n",
    "                       }, index_col=0)\n",
    "\n",
    "diamonds.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But with real-world datasets, you often do not have this luxury because the data you will be working probably will have many categorical variables and often, you will be completely unfamiliar with the data at first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right after you identify the categorical variables, there are some checks and cleaning to be done before you convert the columns to categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing With Categorical Data Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you work with real-world data, it will be filled with cleaning problems.\n",
    "\n",
    "As I wrote in the [first part](https://towardsdatascience.com/data-type-constraints-data-range-constraints-duplicate-data-with-pandas-44897a350b1e) of the series, people collecting data won't take into account the cleanliness of the data and do what it takes to record the necessary information in an easy manner as possible. \n",
    "\n",
    "Also, problems will arise because of free text during the collection process which leads to typos, many representations of the same value, etc. It is also possible that errors are introduced because of data parsing errors or bad database design.\n",
    "\n",
    "For example, consider this worst-case scenario: you are working on a survey data conducted across USA and there is a `state` column for the state of each observation in the dataset. There are 50 states in the USA and imagine all the damn variations of state names people can come up with. You are in even bigger problem if data collectors decide to use abbreviations:\n",
    "- CA, ca, Ca, Caliphornia, Californa, Calfornia, calipornia, CAL, CALI, ...\n",
    "\n",
    "Such columns will always be filled with typos, errors, inconsistencies. Never imagine that you will have a smooth one-to-one mapping of categories. \n",
    "\n",
    "Before moving on to analysis, you have to establish what is called membership constraints which clearly defines the number of categories and how they are represented in a single format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membership Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 ways you can treat categorical data problems:\n",
    "- dropping \n",
    "- remapping categories\n",
    "- inferring categories\n",
    "\n",
    "First, we will focus on isolating inconsistent observations and dropping them. I have created a fake data to illustrate how it is done in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create possible values for the fake date\n",
    "first_names = [\n",
    "    'Lane', 'Ivor', 'Roary', 'Shannon', 'Abdul', 'Mary', 'Cole', 'Desirae'\n",
    "]\n",
    "\n",
    "last_names = ['Reese', 'Pierce', 'Gibson', 'Little', 'Fry', 'Colon', 'Palmer']\n",
    "\n",
    "blood_types = ['O+', 'O-', 'B+', 'B-', 'A+', 'A-', 'AB+', 'AB-', 'C+', 'D-']\n",
    "probabilites = [0.12, 0.13, 0.13, 0.12, 0.13, 0.12, 0.12, 0.12, 0.005, 0.005]\n",
    "marriage_status = [\n",
    "    ' married', 'married', 'unmarried ', 'unmarried', 'MARRIED', 'UNMARRIED',\n",
    "    'divorced', 'separated'\n",
    "]\n",
    "devices = ['iOS', 'AndroidOS', 'MacOS', 'Windows', 'Linux']\n",
    "size = 10000\n",
    "\n",
    "dirty_dict = {\n",
    "    'first_name': np.random.choice(first_names, size),\n",
    "    'last_name': np.random.choice(last_names, size),\n",
    "    'blood_type': np.random.choice(blood_types, size, p=probabilites),\n",
    "    'marriage_status': np.random.choice(marriage_status, size),\n",
    "    'income': np.random.choice(np.arange(40000, 200000, 15000), size),\n",
    "    'device': np.random.choice(devices, size)\n",
    "}\n",
    "\n",
    "# Data frame from dirty dict with size 10k\n",
    "sample = pd.DataFrame(dirty_dict)\n",
    "sample.to_csv('data/demographics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>income</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdul</td>\n",
       "      <td>Colon</td>\n",
       "      <td>A+</td>\n",
       "      <td>married</td>\n",
       "      <td>145000</td>\n",
       "      <td>AndroidOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdul</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>B+</td>\n",
       "      <td>married</td>\n",
       "      <td>85000</td>\n",
       "      <td>MacOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Desirae</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>B+</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>130000</td>\n",
       "      <td>iOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shannon</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>A+</td>\n",
       "      <td>married</td>\n",
       "      <td>175000</td>\n",
       "      <td>MacOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desirae</td>\n",
       "      <td>Little</td>\n",
       "      <td>B+</td>\n",
       "      <td>unmarried</td>\n",
       "      <td>130000</td>\n",
       "      <td>MacOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name blood_type marriage_status  income     device\n",
       "0      Abdul     Colon         A+         married  145000  AndroidOS\n",
       "1      Abdul    Pierce         B+         married   85000      MacOS\n",
       "2    Desirae    Pierce         B+         MARRIED  130000        iOS\n",
       "3    Shannon    Gibson         A+         married  175000      MacOS\n",
       "4    Desirae    Little         B+      unmarried   130000      MacOS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = pd.read_csv('data/demographics.csv')\n",
    "demographics.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often the case that you will have some background information about your data. For example, let's say you want to check for inconsistencies in the `blood_type` column of the above data frame. You find out beforehand that `blood_type`  can only have these categories: **\\[A+, A-, B+, B-, O+, O-, AB+, AB-\\]**. So, you have to make sure that the column in the data source only includes these values. \n",
    "\n",
    "In our case, there are 10k rows and visual search for inconsistencies is not an option, which is also the case for many other real-world data. Here is how can implement the best solution for such problems:\n",
    "\n",
    "First, you should create a new data frame which holds all the possible values for a categorical column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blood_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AB+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AB-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  blood_type\n",
       "0         O+\n",
       "1         O-\n",
       "2         B+\n",
       "3         B-\n",
       "4         A+\n",
       "5         A-\n",
       "6        AB+\n",
       "7        AB-"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.DataFrame(\n",
    "    {'blood_type': ['O+', 'O-', 'B+', 'B-', 'A+', 'A-', 'AB+', 'AB-']})\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It is a good practice to create such data frames which hold category mappings for each categorical column in the main data.\n",
    "\n",
    "As we now have the correct categories in a separate data frame, we can use a basic set operation which gives us the difference of unique values in the two columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C+', 'D-'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a set of unique blood types of the main data frame\n",
    "unique_types_main = set(demographics['blood_type'].unique())\n",
    "inconsistent_cats = unique_types_main.difference(categories['blood_type'])\n",
    "inconsistent_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the difference of two sets, we use `.difference` function. It basically returns all the values from the left set that are not in the right set. Here is a very simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_1 = {'A', 'B', 'C', 'D'}\n",
    "set_2 = {'C', 'D', 'E'}\n",
    "set_1.difference(set_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attentive readers may have noticed that inside the `set` function, I also called `.unique()` on the `blood_type`. From what I have read from one StackOverflow thread, it seems that the time it takes to get the unique values will be much shorter if you use both `set` and `unique` for larger datasets. \n",
    "\n",
    "Now, we will filter our main data for the blood types 'C+' and 'D-':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "9995    False\n",
       "9996    False\n",
       "9997    False\n",
       "9998    False\n",
       "9999    False\n",
       "Name: blood_type, Length: 10000, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inconsistent = demographics['blood_type'].isin(inconsistent_cats)\n",
    "inconsistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `isin` on `blood_type` will return a boolean series which we can use to index the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>income</th>\n",
       "      <th>device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Lane</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>C+</td>\n",
       "      <td>divorced</td>\n",
       "      <td>55000</td>\n",
       "      <td>iOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Ivor</td>\n",
       "      <td>Little</td>\n",
       "      <td>C+</td>\n",
       "      <td>separated</td>\n",
       "      <td>175000</td>\n",
       "      <td>AndroidOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Shannon</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>D-</td>\n",
       "      <td>divorced</td>\n",
       "      <td>100000</td>\n",
       "      <td>AndroidOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>Cole</td>\n",
       "      <td>Little</td>\n",
       "      <td>D-</td>\n",
       "      <td>UNMARRIED</td>\n",
       "      <td>70000</td>\n",
       "      <td>AndroidOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Shannon</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>D-</td>\n",
       "      <td>married</td>\n",
       "      <td>100000</td>\n",
       "      <td>AndroidOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9246</th>\n",
       "      <td>Ivor</td>\n",
       "      <td>Little</td>\n",
       "      <td>D-</td>\n",
       "      <td>divorced</td>\n",
       "      <td>85000</td>\n",
       "      <td>iOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9517</th>\n",
       "      <td>Roary</td>\n",
       "      <td>Little</td>\n",
       "      <td>D-</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>145000</td>\n",
       "      <td>MacOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9618</th>\n",
       "      <td>Desirae</td>\n",
       "      <td>Fry</td>\n",
       "      <td>C+</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>115000</td>\n",
       "      <td>AndroidOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9619</th>\n",
       "      <td>Desirae</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>D-</td>\n",
       "      <td>unmarried</td>\n",
       "      <td>160000</td>\n",
       "      <td>Linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>Ivor</td>\n",
       "      <td>Pierce</td>\n",
       "      <td>D-</td>\n",
       "      <td>separated</td>\n",
       "      <td>160000</td>\n",
       "      <td>Linux</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_name last_name blood_type marriage_status  income     device\n",
       "84         Lane    Pierce         C+        divorced   55000        iOS\n",
       "90         Ivor    Little         C+       separated  175000  AndroidOS\n",
       "234     Shannon    Palmer         D-        divorced  100000  AndroidOS\n",
       "458        Cole    Little         D-       UNMARRIED   70000  AndroidOS\n",
       "480     Shannon    Pierce         D-         married  100000  AndroidOS\n",
       "...         ...       ...        ...             ...     ...        ...\n",
       "9246       Ivor    Little         D-        divorced   85000        iOS\n",
       "9517      Roary    Little         D-         MARRIED  145000      MacOS\n",
       "9618    Desirae       Fry         C+         MARRIED  115000  AndroidOS\n",
       "9619    Desirae    Gibson         D-      unmarried   160000      Linux\n",
       "9912       Ivor    Pierce         D-       separated  160000      Linux\n",
       "\n",
       "[90 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inconsistent_rows = demographics[inconsistent]\n",
    "inconsistent_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 90 individuals with incorrect blood types. Since we don't have any clue of how these errors occurred (I did itðŸ˜ðŸ˜ðŸ˜), we have to drop them. It can be done in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using drop\n",
    "demographics = demographics.drop(inconsistent_rows.index)\n",
    "# Using negative conditioning\n",
    "demographics = demographics[~inconsistent]\n",
    "# Check the results\n",
    "assert set(demographics['blood_type'].unique()) == set(\n",
    "    categories['blood_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our column is clean now, it is safe to set it as a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set blood_type as a categorical variable\n",
    "demographics['blood_type'] = demographics['blood_type'].astype('category')\n",
    "# Check that the results are in effect\n",
    "assert demographics['blood_type'].dtype == 'category'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Definitely check out the [first part](https://towardsdatascience.com/data-type-constraints-data-range-constraints-duplicate-data-with-pandas-44897a350b1e) of this series. There, I covered basic and common data problems. You will also familiarize yourself with some of the functions I will be using here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Inconsistency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we talked in the second section, there may be many representations of the same category in the data set. These errors may occur just because simple typos, random capitalization, you name it. Continuing cleaning our data, the turn has come to the `marriage_status` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " married      1321\n",
       "unmarried     1276\n",
       "UNMARRIED     1253\n",
       "married       1244\n",
       "separated     1227\n",
       "divorced      1223\n",
       "MARRIED       1210\n",
       "unmarried     1156\n",
       "Name: marriage_status, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics['marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `value_counts` on a data frame column returns the count of unique values in that column. If you look at the result, you can immediately see the issues. The values should be either lower-case or upper-case. I prefer lower-case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "married       2454\n",
       "unmarried     2409\n",
       " married      1321\n",
       "unmarried     1276\n",
       "separated     1227\n",
       "divorced      1223\n",
       "Name: marriage_status, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics['marriage_status'] = demographics['marriage_status'].str.lower()\n",
    "demographics['marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `.str` on a data frame column enables us to use all the Python string functions on each value of the column. Here, we are using `.lower()` which converts strings to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`value_counts` is still returning 6 unique values, why? After paying close attention, you can see that one of the categories has an extra leading whitespace. That's why it is being treated as an individual category. The same can be true for one of the `unmarried`, it might have a trailing whitespace. We can use the string `strip` function to get rid of trailing whitespace from a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "married      3775\n",
       "unmarried    3685\n",
       "separated    1227\n",
       "divorced     1223\n",
       "Name: marriage_status, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics['marriage_status'] = demographics['marriage_status'].str.strip()\n",
    "demographics['marriage_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the columns is clean. All is left is to convert this column into a category data type too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert marriage_status to categorical\n",
    "demographics['marriage_status'] = demographics['marriage_status'].astype(\n",
    "    'category')\n",
    "# Check the results\n",
    "assert demographics['marriage_status'].dtype == 'category'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapsing Data Into Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you may want to take already existing data, often numerical, and generate categories from it. This can be useful in a number of cases. \n",
    "\n",
    "In our `demographics` dataset, we have an annual income column. It can be useful to cut this column into different income groups because doing so might give some extra insight into the data. \n",
    "\n",
    "`pandas` has a perfect function for this: `cut`. It enables us to cut numerical ranges like data frame columns into bins and give them custom labels. Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>blood_type</th>\n",
       "      <th>marriage_status</th>\n",
       "      <th>income</th>\n",
       "      <th>device</th>\n",
       "      <th>income_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4122</th>\n",
       "      <td>Roary</td>\n",
       "      <td>Reese</td>\n",
       "      <td>AB+</td>\n",
       "      <td>married</td>\n",
       "      <td>100000</td>\n",
       "      <td>iOS</td>\n",
       "      <td>75k-100k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>Desirae</td>\n",
       "      <td>Fry</td>\n",
       "      <td>AB+</td>\n",
       "      <td>unmarried</td>\n",
       "      <td>70000</td>\n",
       "      <td>Linux</td>\n",
       "      <td>40k-75k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>Mary</td>\n",
       "      <td>Little</td>\n",
       "      <td>AB-</td>\n",
       "      <td>separated</td>\n",
       "      <td>145000</td>\n",
       "      <td>Windows</td>\n",
       "      <td>140k-170k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>Lane</td>\n",
       "      <td>Colon</td>\n",
       "      <td>AB-</td>\n",
       "      <td>unmarried</td>\n",
       "      <td>130000</td>\n",
       "      <td>MacOS</td>\n",
       "      <td>100k-140k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7542</th>\n",
       "      <td>Mary</td>\n",
       "      <td>Little</td>\n",
       "      <td>O+</td>\n",
       "      <td>unmarried</td>\n",
       "      <td>175000</td>\n",
       "      <td>Linux</td>\n",
       "      <td>170k+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     first_name last_name blood_type marriage_status  income   device  \\\n",
       "4122      Roary     Reese        AB+         married  100000      iOS   \n",
       "4367    Desirae       Fry        AB+       unmarried   70000    Linux   \n",
       "8982       Mary    Little        AB-       separated  145000  Windows   \n",
       "7101       Lane     Colon        AB-       unmarried  130000    MacOS   \n",
       "7542       Mary    Little         O+       unmarried  175000    Linux   \n",
       "\n",
       "     income_groups  \n",
       "4122      75k-100k  \n",
       "4367       40k-75k  \n",
       "8982     140k-170k  \n",
       "7101     100k-140k  \n",
       "7542         170k+  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = [40000, 75000, 100000, 140000, 170000, np.inf]\n",
    "labels = ['40k-75k', '75k-100k', '100k-140k', '140k-170k', '170k+']\n",
    "demographics['income_groups'] = pd.cut(demographics['income'], bins=ranges, labels=labels)\n",
    "demographics.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use functions like `value_counts` to get more insight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40k-75k      1860\n",
       "75k-100k     1808\n",
       "100k-140k    1805\n",
       "140k-170k    1845\n",
       "170k+        1754\n",
       "Name: income_groups, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics['income_groups'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot a count plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(demographics['income_groups']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the Number of Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, there may be unnecessary categories. In such cases, you can collapse smaller categories into a general and bigger categories which might suit your needs better. Consider the `device` column of our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MacOS        2029\n",
       "Windows      2009\n",
       "iOS          1960\n",
       "Linux        1959\n",
       "AndroidOS    1953\n",
       "Name: device, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics['device'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not much useful to compare a phone operating system to a computer's. What would be better is to reduce the categories into `mobileOS` and `desktopOS`. To do this, first, we need to create a dictionary which maps each category to the new one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'Linux': 'desktopOS', 'iOS': 'mobileOS',\n",
    "    'MacOS': 'desktopOS', 'Windows': 'desktopOS',\n",
    "    'AndroidOS': 'mobileOS'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use `replace` function of `pandas` which maps out the new categories dynamically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desktopOS    5997\n",
       "mobileOS     3913\n",
       "Name: device, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics['device'] = demographics['device'].replace(mappings)\n",
    "demographics['device'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium_articles",
   "language": "python",
   "name": "medium_articles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
